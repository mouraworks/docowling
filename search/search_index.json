{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docowling","text":"<p>Docling parses documents and exports them to the desired format with ease and speed.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\uddc2\ufe0f Reads popular document formats (PDF, DOCX, PPTX, XLSX, Images, HTML, AsciiDoc &amp; Markdown) and exports to HTML, Markdown and JSON (with embedded and referenced images)</li> <li>\ud83d\udcd1 Advanced PDF document understanding incl. page layout, reading order &amp; table structures</li> <li>\ud83e\udde9 Unified, expressive DoclingDocument representation format</li> <li>\ud83e\udd16 Easy integration with \ud83e\udd99 LlamaIndex &amp; \ud83e\udd9c\ud83d\udd17 LangChain for powerful RAG / QA applications</li> <li>\ud83d\udd0d OCR support for scanned PDFs</li> <li>\ud83d\udcbb Simple and convenient CLI</li> </ul>"},{"location":"#coming-soon","title":"Coming soon","text":"<ul> <li>\u267e\ufe0f Equation &amp; code extraction</li> <li>\ud83d\udcdd Metadata extraction, including title, authors, references &amp; language</li> <li>\ud83e\udd9c\ud83d\udd17 Native LangChain extension</li> </ul>"},{"location":"#ibm-open-source-ai","title":"IBM \u2764\ufe0f Open Source AI","text":"<p>Docling has been brought to you by IBM.</p>"},{"location":"faq/","title":"FAQ","text":"<p>This is a collection of FAQ collected from the user questions on https://github.com/DS4SD/docling/discussions.</p> Is Python 3.13 supported? Install conflicts with numpy (python 3.13) Are text styles (bold, underline, etc) supported? How do I run completely offline?  Which model weights are needed to run Docling? SSL error downloading model weights Which OCR languages are supported?"},{"location":"faq/#is-python-313-supported","title":"Is Python 3.13 supported?","text":"<p>Full support for Python 3.13 is currently waiting for pytorch.</p> <p>At the moment, no release has full support, but nightly builds are available. Docling was tested on Python 3.13 with the following steps:</p> <pre><code># Create a python 3.13 virtualenv\npython3.13 -m venv venv\nsource ./venv/bin/activate\n\n# Install torch nightly builds, see https://pytorch.org/\npip3 install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cpu\n\n# Install docling\npip3 install docling\n\n# Run docling\ndocling --no-ocr https://arxiv.org/pdf/2408.09869\n</code></pre> <p>Note: we are disabling OCR since easyocr and the nightly torch builds have some conflicts.</p> <p>Source: Issue #136</p>"},{"location":"faq/#install-conflicts-with-numpy-python-313","title":"Install conflicts with numpy (python 3.13)","text":"<p>When using <code>docling-ibm-models&gt;=2.0.7</code> and <code>deepsearch-glm&gt;=0.26.2</code> these issues should not show up anymore. Docling supports numpy versions <code>&gt;=1.24.4,&lt;3.0.0</code> which should match all usages.</p> <p>For older versions</p> <p>This has been observed installing docling and langchain via poetry.</p> <pre><code>...\nThus, docling (&gt;=2.7.0,&lt;3.0.0) requires numpy (&gt;=1.26.4,&lt;2.0.0).\nSo, because ... depends on both numpy (&gt;=2.0.2,&lt;3.0.0) and docling (^2.7.0), version solving failed.\n</code></pre> <p>Numpy is only adding Python 3.13 support starting in some 2.x.y version. In order to prepare for 3.13, Docling depends on a 2.x.y for 3.13, otherwise depending an 1.x.y version. If you are allowing 3.13 in your pyproject.toml, Poetry will try to find some way to reconcile Docling's numpy version for 3.13 (some 2.x.y) with LangChain's version for that (some 1.x.y) \u2014 leading to the error above.</p> <p>Check if Python 3.13 is among the Python versions allowed by your pyproject.toml and if so, remove it and try again. E.g., if you have python = \"^3.10\", use python = \"&gt;=3.10,&lt;3.13\" instead.</p> <p>If you want to retain compatibility with python 3.9-3.13, you can also use a selector in pyproject.toml similar to the following</p> <pre><code>numpy = [\n    { version = \"^2.1.0\", markers = 'python_version &gt;= \"3.13\"' },\n    { version = \"^1.24.4\", markers = 'python_version &lt; \"3.13\"' },\n]\n</code></pre> <p>Source: Issue #283</p>"},{"location":"faq/#are-text-styles-bold-underline-etc-supported","title":"Are text styles (bold, underline, etc) supported?","text":"<p>Currently text styles are not supported in the <code>DoclingDocument</code> format. If you are interest in contributing this feature, please open a discussion topic to brainstorm on the design.</p> <p>Note: this is not a simple topic</p>"},{"location":"faq/#how-do-i-run-completely-offline","title":"How do I run completely offline?","text":"<p>Docling is not using any remote service, hence it can run in completely isolated air-gapped environments.</p> <p>The only requirement is pointing the Docling runtime to the location where the model artifacts have been stored.</p> <p>For example</p> <pre><code>pipeline_options = PdfPipelineOptions(artifacts_path=\"your location\")\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n</code></pre> <p>Source: Issue #326</p>"},{"location":"faq/#which-model-weights-are-needed-to-run-docling","title":"Which model weights are needed to run Docling?","text":"<p>Model weights are needed for the AI models used in the PDF pipeline. Other document types (docx, pptx, etc) do not have any such requirement.</p> <p>For processing PDF documents, Docling requires the model weights from https://huggingface.co/ds4sd/docling-models.</p> <p>When OCR is enabled, some engines also require model artifacts. For example EasyOCR, for which Docling has special pipeline options to control the runtime behavior.</p>"},{"location":"faq/#ssl-error-downloading-model-weights","title":"SSL error downloading model weights","text":"<pre><code>URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)&gt;\n</code></pre> <p>Similar SSL download errors have been observed by some users. This happens when model weights are fetched from Hugging Face. The error could happen when the python environment doesn't have an up-to-date list of trusted certificates.</p> <p>Possible solutions were</p> <ul> <li>Update to the latest version of certifi, i.e. <code>pip install --upgrade certifi</code></li> <li>Use pip-system-certs to use the latest trusted certificates on your system.</li> </ul>"},{"location":"faq/#which-ocr-languages-are-supported","title":"Which OCR languages are supported?","text":"<p>Docling supports multiple OCR engine, each one has its own list of supported languages. Here is a collection of links to the original OCR engine's documentation listing the OCR languages.</p> <ul> <li>EasyOCR</li> <li>Tesseract</li> <li>RapidOCR</li> <li>Mac OCR</li> </ul> <p>Setting the OCR language in Docling is done via the OCR pipeline options:</p> <pre><code>from docowling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\npipeline_options.ocr_options.lang = [\"fr\", \"de\", \"es\", \"en\"]  # example of languages for EasyOCR\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>To use Docling, simply install <code>docling</code> from your Python package manager, e.g. pip: <pre><code>pip install docling\n</code></pre></p> <p>Works on macOS, Linux, and Windows, with support for both x86_64 and arm64 architectures.</p> Alternative PyTorch distributions <p>The Docling models depend on the PyTorch library. Depending on your architecture, you might want to use a different distribution of <code>torch</code>. For example, you might want support for different accelerator or for a cpu-only version. All the different ways for installing <code>torch</code> are listed on their website https://pytorch.org/.</p> <p>One common situation is the installation on Linux systems with cpu-only support. In this case, we suggest the installation of Docling with the following options</p> <pre><code># Example for installing on the Linux cpu-only version\npip install docling --extra-index-url https://download.pytorch.org/whl/cpu\n</code></pre> Alternative OCR engines <p>Docling supports multiple OCR engines for processing scanned documents. The current version provides the following engines.</p> Engine Installation Usage EasyOCR Default in Docling or via <code>pip install easyocr</code>. <code>EasyOcrOptions</code> Tesseract System dependency. See description for Tesseract and Tesserocr below. <code>TesseractOcrOptions</code> Tesseract CLI System dependency. See description below. <code>TesseractCliOcrOptions</code> OcrMac System dependency. See description below. <code>OcrMacOptions</code> RapidOCR Extra feature not included in Default Docling installation can be installed via <code>pip install rapidocr_onnxruntime</code> <code>RapidOcrOptions</code> <p>The Docling <code>DocumentConverter</code> allows to choose the OCR engine with the <code>ocr_options</code> settings. For example</p> <pre><code>from docowling.datamodel.base_models import ConversionStatus, PipelineOptions\nfrom docowling.datamodel.pipeline_options import PipelineOptions, EasyOcrOptions, TesseractOcrOptions\nfrom docowling.document_converter import DocumentConverter\n\npipeline_options = PipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractOcrOptions()  # Use Tesseract\n\ndoc_converter = DocumentConverter(\n    pipeline_options=pipeline_options,\n)\n</code></pre> <p>Tesseract installation</p> <p>Tesseract is a popular OCR engine which is available on most operating systems. For using this engine with Docling, Tesseract must be installed on your system, using the packaging tool of your choice. Below we provide example commands. After installing Tesseract you are expected to provide the path to its language files using the <code>TESSDATA_PREFIX</code> environment variable (note that it must terminate with a slash <code>/</code>).</p> macOS (via Homebrew)Debian-basedRHEL <pre><code>brew install tesseract leptonica pkg-config\nTESSDATA_PREFIX=/opt/homebrew/share/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <pre><code>apt-get install tesseract-ocr tesseract-ocr-eng libtesseract-dev libleptonica-dev pkg-config\nTESSDATA_PREFIX=$(dpkg -L tesseract-ocr-eng | grep tessdata$)\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <pre><code>dnf install tesseract tesseract-devel tesseract-langpack-eng leptonica-devel\nTESSDATA_PREFIX=/usr/share/tesseract/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <p>Linking to Tesseract The most efficient usage of the Tesseract library is via linking. Docling is using the Tesserocr package for this.</p> <p>If you get into installation issues of Tesserocr, we suggest using the following installation options:</p> <pre><code>pip uninstall tesserocr\npip install --no-binary :all: tesserocr\n</code></pre> <p>ocrmac installation</p> <p>ocrmac is using Apple's vision(or livetext) framework as OCR backend. For using this engine with Docling, ocrmac must be installed on your system. This only works on macOS systems with newer macOS versions (10.15+).</p> <pre><code>pip install ocrmac\n</code></pre>"},{"location":"installation/#development-setup","title":"Development setup","text":"<p>To develop Docling features, bugfixes etc., install as follows from your local clone's root dir:</p> <pre><code>poetry install --all-extras\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#conversion","title":"Conversion","text":""},{"location":"usage/#convert-a-single-document","title":"Convert a single document","text":"<p>To convert individual PDF documents, use <code>convert()</code>, for example:</p> <pre><code>from docowling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"  # PDF path or URL\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())  # output: \"### Docling Technical Report[...]\"\n</code></pre>"},{"location":"usage/#cli","title":"CLI","text":"<p>You can also use Docling directly from your command line to convert individual files \u2014be it local or by URL\u2014 or whole directories.</p> <p>A simple example would look like this: <pre><code>docling https://arxiv.org/pdf/2206.01062\n</code></pre></p> <p>To see all available options (export formats etc.) run <code>docling --help</code>. More details in the CLI reference page.</p>"},{"location":"usage/#advanced-options","title":"Advanced options","text":""},{"location":"usage/#adjust-pipeline-features","title":"Adjust pipeline features","text":"<p>The example file custom_convert.py contains multiple ways one can adjust the conversion pipeline and features.</p>"},{"location":"usage/#control-pdf-table-extraction-options","title":"Control PDF table extraction options","text":"<p>You can control if table structure recognition should map the recognized structure back to PDF cells (default) or use text cells from the structure prediction itself. This can improve output quality if you find that multiple columns in extracted tables are erroneously merged into one.</p> <pre><code>from docowling.datamodel.base_models import InputFormat\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions(do_table_structure=True)\npipeline_options.table_structure_options.do_cell_matching = False  # uses text cells predicted from table structure model\n\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n</code></pre> <p>Since docling 1.16.0: You can control which TableFormer mode you want to use. Choose between <code>TableFormerMode.FAST</code> (default) and <code>TableFormerMode.ACCURATE</code> (better, but slower) to receive better quality with difficult table structures.</p> <pre><code>from docowling.datamodel.base_models import InputFormat\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n\npipeline_options = PdfPipelineOptions(do_table_structure=True)\npipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # use more accurate TableFormer model\n\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n</code></pre>"},{"location":"usage/#provide-specific-artifacts-path","title":"Provide specific artifacts path","text":"<p>By default, artifacts such as models are downloaded automatically upon first usage. If you would prefer to use a local path where the artifacts have been explicitly prefetched, you can do that as follows:</p> <pre><code>from docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n\n# # to explicitly prefetch:\n# artifacts_path = StandardPdfPipeline.download_models_hf()\n\nartifacts_path = \"/local/path/to/artifacts\"\n\npipeline_options = PdfPipelineOptions(artifacts_path=artifacts_path)\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n</code></pre>"},{"location":"usage/#impose-limits-on-the-document-size","title":"Impose limits on the document size","text":"<p>You can limit the file size and number of pages which should be allowed to process per document:</p> <pre><code>from pathlib import Path\nfrom docowling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"\nconverter = DocumentConverter()\nresult = converter.convert(source, max_num_pages=100, max_file_size=20971520)\n</code></pre>"},{"location":"usage/#convert-from-binary-pdf-streams","title":"Convert from binary PDF streams","text":"<p>You can convert PDFs from a binary stream instead of from the filesystem as follows:</p> <pre><code>from io import BytesIO\nfrom docowling.datamodel.base_models import DocumentStream\nfrom docowling.document_converter import DocumentConverter\n\nbuf = BytesIO(your_binary_stream)\nsource = DocumentStream(name=\"my_doc.pdf\", stream=buf)\nconverter = DocumentConverter()\nresult = converter.convert(source)\n</code></pre>"},{"location":"usage/#limit-resource-usage","title":"Limit resource usage","text":"<p>You can limit the CPU threads used by Docling by setting the environment variable <code>OMP_NUM_THREADS</code> accordingly. The default setting is using 4 CPU threads.</p>"},{"location":"usage/#chunking","title":"Chunking","text":"<p>You can chunk a Docling document using a chunker, such as a <code>HybridChunker</code>, as shown below (for more details check out this example):</p> <pre><code>from docowling.document_converter import DocumentConverter\nfrom docowling.chunking import HybridChunker\n\nconv_res = DocumentConverter().convert(\"https://arxiv.org/pdf/2206.01062\")\ndoc = conv_res.document\n\nchunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")  # set tokenizer as needed\nchunk_iter = chunker.chunk(doc)\n</code></pre> <p>An example chunk would look like this:</p> <pre><code>print(list(chunk_iter)[11])\n# {\n#   \"text\": \"In this paper, we present the DocLayNet dataset. [...]\",\n#   \"meta\": {\n#     \"doc_items\": [{\n#       \"self_ref\": \"#/texts/28\",\n#       \"label\": \"text\",\n#       \"prov\": [{\n#         \"page_no\": 2,\n#         \"bbox\": {\"l\": 53.29, \"t\": 287.14, \"r\": 295.56, \"b\": 212.37, ...},\n#       }], ...,\n#     }, ...],\n#     \"headings\": [\"1 INTRODUCTION\"],\n#   }\n# }\n</code></pre>"},{"location":"v2/","title":"Docowling v2","text":""},{"location":"v2/#whats-new","title":"What's new","text":"<p>Docling v2 introduces several new features:</p> <ul> <li>Understands and converts PDF, MS Word, MS Powerpoint, HTML and several image formats</li> <li>Produces a new, universal document representation which can encapsulate document hierarchy</li> <li>Comes with a fresh new API and CLI</li> </ul>"},{"location":"v2/#changes-in-docling-v2","title":"Changes in Docling v2","text":""},{"location":"v2/#cli","title":"CLI","text":"<p>We updated the command line syntax of Docling v2 to support many formats. Examples are seen below. <pre><code># Convert a single file to Markdown (default)\ndocling myfile.pdf\n\n# Convert a single file to Markdown and JSON, without OCR\ndocling myfile.pdf --to json --to md --no-ocr\n\n# Convert PDF files in input directory to Markdown (default)\ndocling ./input/dir --from pdf\n\n# Convert PDF and Word files in input directory to Markdown and JSON\ndocling ./input/dir --from pdf --from docx --to md --to json --output ./scratch\n\n# Convert all supported files in input directory to Markdown, but abort on first error\ndocling ./input/dir --output ./scratch --abort-on-error\n</code></pre></p> <p>Notable changes from Docling v1:</p> <ul> <li>The standalone switches for different export formats are removed, and replaced with <code>--from</code> and <code>--to</code> arguments, to define input and output formats respectively.</li> <li>The new <code>--abort-on-error</code> will abort any batch conversion as soon an error is encountered</li> <li>The <code>--backend</code> option for PDFs was removed</li> </ul>"},{"location":"v2/#setting-up-a-documentconverter","title":"Setting up a <code>DocumentConverter</code>","text":"<p>To accomodate many input formats, we changed the way you need to set up your <code>DocumentConverter</code> object. You can now define a list of allowed formats on the <code>DocumentConverter</code> initialization, and specify custom options per-format if desired. By default, all supported formats are allowed. If you don't provide <code>format_options</code>, defaults will be used for all <code>allowed_formats</code>.</p> <p>Format options can include the pipeline class to use, the options to provide to the pipeline, and the document backend. They are provided as format-specific types, such as <code>PdfFormatOption</code> or <code>WordFormatOption</code>, as seen below.</p> <pre><code>from docowling.document_converter import DocumentConverter\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.document_converter import (\n    DocumentConverter,\n    PdfFormatOption,\n    WordFormatOption,\n)\nfrom docowling.pipeline.simple_pipeline import SimplePipeline\nfrom docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n\n## Default initialization still works as before:\n# doc_converter = DocumentConverter()\n\n\n# previous `PipelineOptions` is now `PdfPipelineOptions`\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = False\npipeline_options.do_table_structure = True\n#...\n\n## Custom options are now defined per format.\ndoc_converter = (\n    DocumentConverter(  # all of the below is optional, has internal defaults.\n        allowed_formats=[\n            InputFormat.PDF,\n            InputFormat.IMAGE,\n            InputFormat.DOCX,\n            InputFormat.HTML,\n            InputFormat.PPTX,\n        ],  # whitelist formats, non-matching files are ignored.\n        format_options={\n            InputFormat.PDF: PdfFormatOption(\n                pipeline_options=pipeline_options, # pipeline options go here.\n                backend=PyPdfiumDocumentBackend # optional: pick an alternative backend\n            ),\n            InputFormat.DOCX: WordFormatOption(\n                pipeline_cls=SimplePipeline # default for office formats and HTML\n            ),\n        },\n    )\n)\n</code></pre> <p>Note: If you work only with defaults, all remains the same as in Docling v1.</p> <p>More options are shown in the following example units:</p> <ul> <li>run_with_formats.py</li> <li>custom_convert.py</li> </ul>"},{"location":"v2/#converting-documents","title":"Converting documents","text":"<p>We have simplified the way you can feed input to the <code>DocumentConverter</code> and renamed the conversion methods for better semantics. You can now call the conversion directly with a single file, or a list of input files, or <code>DocumentStream</code> objects, without constructing a <code>DocumentConversionInput</code> object first.</p> <ul> <li><code>DocumentConverter.convert</code> now converts a single file input (previously <code>DocumentConverter.convert_single</code>).</li> <li><code>DocumentConverter.convert_all</code> now converts many files at once (previously <code>DocumentConverter.convert</code>).</li> </ul> <p><pre><code>...\nfrom docowling.datamodel.document import ConversionResult\n## Convert a single file (from URL or local path)\nconv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Convert several files at once:\n\ninput_files = [\n    \"tests/data/wiki_duck.html\",\n    \"tests/data/word_sample.docx\",\n    \"tests/data/lorem_ipsum.docx\",\n    \"tests/data/powerpoint_sample.pptx\",\n    \"tests/data/2305.03393v1-pg9-img.png\",\n    \"tests/data/2206.01062.pdf\",\n]\n\n# Directly pass list of files or streams to `convert_all`\nconv_results_iter = doc_converter.convert_all(input_files) # previously `convert`\n</code></pre> Through the <code>raises_on_error</code> argument, you can also control if the conversion should raise exceptions when first encountering a problem, or resiliently convert all files first and reflect errors in each file's conversion status. By default, any error is immediately raised and the conversion aborts (previously, exceptions were swallowed).</p> <pre><code>...\nconv_results_iter = doc_converter.convert_all(input_files, raises_on_error=False) # previously `convert`\n</code></pre>"},{"location":"v2/#access-document-structures","title":"Access document structures","text":"<p>We have simplified how you can access and export the converted document data, too. Our universal document representation is now available in conversion results as a <code>DoclingDocument</code> object. <code>DoclingDocument</code> provides a neat set of APIs to construct, iterate and export content in the document, as shown below.</p> <pre><code>conv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Inspect the converted document:\nconv_result.document.print_element_tree()\n\n## Iterate the elements in reading order, including hierachy level:\nfor item, level in conv_result.document.iterate_items():\n    if isinstance(item, TextItem):\n        print(item.text)\n    elif isinstance(item, TableItem):\n        table_df: pd.DataFrame = item.export_to_dataframe()\n        print(table_df.to_markdown())\n    elif ...:\n        #...\n</code></pre> <p>Note: While it is deprecated, you can still work with the Docling v1 document representation, it is available as: <pre><code>conv_result.legacy_document # provides the representation in previous ExportedCCSDocument type\n</code></pre></p>"},{"location":"v2/#export-into-json-markdown-doctags","title":"Export into JSON, Markdown, Doctags","text":"<p>Note: All <code>render_...</code> methods in <code>ConversionResult</code> have been removed in Docling v2, and are now available on <code>DoclingDocument</code> as:</p> <ul> <li><code>DoclingDocument.export_to_dict</code></li> <li><code>DoclingDocument.export_to_markdown</code></li> <li><code>DoclingDocument.export_to_document_tokens</code></li> </ul> <pre><code>conv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Export to desired format:\nprint(json.dumps(conv_res.document.export_to_dict()))\nprint(conv_res.document.export_to_markdown())\nprint(conv_res.document.export_to_document_tokens())\n</code></pre> <p>Note: While it is deprecated, you can still export Docling v1 JSON format. This is available through the same methods as on the <code>DoclingDocument</code> type: <pre><code>## Export legacy document representation to desired format, for v1 compatibility:\nprint(json.dumps(conv_res.legacy_document.export_to_dict()))\nprint(conv_res.legacy_document.export_to_markdown())\nprint(conv_res.legacy_document.export_to_document_tokens())\n</code></pre></p>"},{"location":"v2/#reload-a-doclingdocument-stored-as-json","title":"Reload a <code>DoclingDocument</code> stored as JSON","text":"<p>You can save and reload a <code>DoclingDocument</code> to disk in JSON format using the following codes:</p> <pre><code># Save to disk:\ndoc: DoclingDocument = conv_res.document # produced from conversion result...\n\nwith Path(\"./doc.json\").open(\"w\") as fp:\n    fp.write(json.dumps(doc.export_to_dict())) # use `export_to_dict` to ensure consistency\n\n# Load from disk:\nwith Path(\"./doc.json\").open(\"r\") as fp:\n    doc_dict = json.loads(fp.read())\n    doc = DoclingDocument.model_validate(doc_dict) # use standard pydantic API to populate doc\n</code></pre>"},{"location":"v2/#chunking","title":"Chunking","text":"<p>Docling v2 defines new base classes for chunking:</p> <ul> <li><code>BaseMeta</code> for chunk metadata</li> <li><code>BaseChunk</code> containing the chunk text and metadata, and</li> <li><code>BaseChunker</code> for chunkers, producing chunks out of a <code>DoclingDocument</code>.</li> </ul> <p>Additionally, it provides an updated <code>HierarchicalChunker</code> implementation, which leverages the new <code>DoclingDocument</code> and provides a new, richer chunk output format, including:</p> <ul> <li>the respective doc items for grounding</li> <li>any applicable headings for context</li> <li>any applicable captions for context</li> </ul> <p>For an example, check out Chunking usage.</p>"},{"location":"concepts/","title":"Concepts","text":"<p>Use the navigation on the left to browse through some core Docling concepts.</p>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>In a nutshell, Docling's architecture is outlined in the diagram above.</p> <p>For each document format, the document converter knows which format-specific backend to employ for parsing the document and which pipeline to use for orchestrating the execution, along with any relevant options.</p> <p>Tip</p> <p>While the document converter holds a default mapping, this configuration is parametrizable, so e.g. for the PDF format, different backends and different pipeline options can be used \u2014 see Usage.</p> <p>The conversion result contains the Docling document, Docling's fundamental document representation.</p> <p>Some typical scenarios for using a Docling document include directly calling its export methods, such as for markdown, dictionary etc., or having it chunked by a chunker.</p> <p>For more details on Docling's architecture, check out the Docling Technical Report.</p> <p>Note</p> <p>The components illustrated with dashed outline indicate base classes that can be subclassed for specialized implementations.</p>"},{"location":"concepts/chunking/","title":"Chunking","text":""},{"location":"concepts/chunking/#introduction","title":"Introduction","text":"<p>A chunker is a Docling abstraction that, given a <code>DoclingDocument</code>, returns a stream of chunks, each of which captures some part of the document as a string accompanied by respective metadata.</p> <p>To enable both flexibility for downstream applications and out-of-the-box utility, Docling defines a chunker class hierarchy, providing a base type, <code>BaseChunker</code>, as well as specific subclasses.</p> <p>Docling integration with gen AI frameworks like LlamaIndex is done using the <code>BaseChunker</code> interface, so users can easily plug in any built-in, self-defined, or third-party <code>BaseChunker</code> implementation.</p>"},{"location":"concepts/chunking/#base-chunker","title":"Base Chunker","text":"<p>The <code>BaseChunker</code> base class API defines that any chunker should provide the following:</p> <ul> <li><code>def chunk(self, dl_doc: DoclingDocument, **kwargs) -&gt; Iterator[BaseChunk]</code>:   Returning the chunks for the provided document.</li> <li><code>def serialize(self, chunk: BaseChunk) -&gt; str</code>:   Returning the potentially metadata-enriched serialization of the chunk, typically   used to feed an embedding model (or generation model).</li> </ul>"},{"location":"concepts/chunking/#hybrid-chunker","title":"Hybrid Chunker","text":"<p>To access <code>HybridChunker</code></p> <ul> <li>If you are using the <code>docling</code> package, you can import as follows:     <pre><code>from docowling.chunking import HybridChunker\n</code></pre></li> <li>If you are only using the <code>docling-core</code> package, you must ensure to install     the <code>chunking</code> extra, e.g.     <pre><code>pip install 'docling-core[chunking]'\n</code></pre>     and then you     can import as follows:     <pre><code>from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n</code></pre></li> </ul> <p>The <code>HybridChunker</code> implementation uses a hybrid approach, applying tokenization-aware refinements on top of document-based hierarchical chunking.</p> <p>More precisely:</p> <ul> <li>it starts from the result of the hierarchical chunker and, based on the user-provided   tokenizer (typically to be aligned to the embedding model tokenizer), it:</li> <li>does one pass where it splits chunks only when needed (i.e. oversized w.r.t. tokens), &amp;</li> <li>another pass where it merges chunks only when possible (i.e. undersized successive chunks with same headings &amp; captions) \u2014 users can opt out of this step via param <code>merge_peers</code> (by default <code>True</code>)</li> </ul> <p>\ud83d\udc49 Example: see  here.</p>"},{"location":"concepts/chunking/#hierarchical-chunker","title":"Hierarchical Chunker","text":"<p>The <code>HierarchicalChunker</code> implementation uses the document structure information from the <code>DoclingDocument</code> to create one chunk for each individual detected document element, by default only merging together list items (can be opted out via param <code>merge_list_items</code>). It also takes care of attaching all relevant document metadata, including headers and captions.</p>"},{"location":"concepts/docling_document/","title":"Docowling Document","text":"<p>With Docling v2, we introduce a unified document representation format called <code>DoclingDocument</code>. It is defined as a pydantic datatype, which can express several features common to documents, such as:</p> <ul> <li>Text, Tables, Pictures, and more</li> <li>Document hierarchy with sections and groups</li> <li>Disambiguation between main body and headers, footers (furniture)</li> <li>Layout information (i.e. bounding boxes) for all items, if available</li> <li>Provenance information</li> </ul> <p>The definition of the Pydantic types is implemented in the module <code>docling_core.types.doc</code>, more details in source code definitions.</p> <p>It also brings a set of document construction APIs to build up a <code>DoclingDocument</code> from scratch.</p>"},{"location":"concepts/docling_document/#example-document-structures","title":"Example document structures","text":"<p>To illustrate the features of the <code>DoclingDocument</code> format, in the subsections below we consider the <code>DoclingDocument</code> converted from <code>tests/data/word_sample.docx</code> and we present some side-by-side comparisons, where the left side shows snippets from the converted document serialized as YAML and the right one shows the corresponding parts of the original MS Word.</p>"},{"location":"concepts/docling_document/#basic-structure","title":"Basic structure","text":"<p>A <code>DoclingDocument</code> exposes top-level fields for the document content, organized in two categories. The first category is the content items, which are stored in these fields:</p> <ul> <li><code>texts</code>: All items that have a text representation (paragraph, section heading, equation, ...). Base class is <code>TextItem</code>.</li> <li><code>tables</code>: All tables, type <code>TableItem</code>. Can carry structure annotations.</li> <li><code>pictures</code>: All pictures, type <code>PictureItem</code>. Can carry structure annotations.</li> <li><code>key_value_items</code>: All key-value items.</li> </ul> <p>All of the above fields are lists and store items inheriting from the <code>DocItem</code> type. They can express different data structures depending on their type, and reference parents and children through JSON pointers.</p> <p>The second category is content structure, which is encapsualted in:</p> <ul> <li><code>body</code>: The root node of a tree-structure for the main document body</li> <li><code>furniture</code>: The root node of a tree-structure for all items that don't belong into the body (headers, footers, ...)</li> <li><code>groups</code>: A set of items that don't represent content, but act as containers for other content items (e.g. a list, a chapter)</li> </ul> <p>All of the above fields are only storing <code>NodeItem</code> instances, which reference children and parents through JSON pointers.</p> <p>The reading order of the document is encapsulated through the <code>body</code> tree and the order of children in each item in the tree.</p> <p>Below example shows how all items in the first page are nested below the <code>title</code> item (<code>#/texts/1</code>).</p> <p></p>"},{"location":"concepts/docling_document/#grouping","title":"Grouping","text":"<p>Below example shows how all items under the heading \"Let's swim\" (<code>#/texts/5</code>) are nested as chilrden. The children of \"Let's swim\" are both text items and groups, which contain the list elements. The group items are stored in the top-level <code>groups</code> field.</p> <p></p>"},{"location":"examples/","title":"Examples","text":"<p>Use the navigation on the left to browse through examples covering a range of possible workflows and use cases.</p>"},{"location":"examples/batch_convert/","title":"Batch conversion","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nimport time\nfrom pathlib import Path\nfrom typing import Iterable\n</pre> import json import logging import time from pathlib import Path from typing import Iterable In\u00a0[\u00a0]: Copied! <pre>import yaml\n</pre> import yaml In\u00a0[\u00a0]: Copied! <pre>from docowling.datamodel.base_models import ConversionStatus\nfrom docowling.datamodel.document import ConversionResult\nfrom docowling.datamodel.settings import settings\nfrom docowling.document_converter import DocumentConverter\n</pre> from docowling.datamodel.base_models import ConversionStatus from docowling.datamodel.document import ConversionResult from docowling.datamodel.settings import settings from docowling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>USE_V2 = True\nUSE_LEGACY = True\n</pre> USE_V2 = True USE_LEGACY = True In\u00a0[\u00a0]: Copied! <pre>def export_documents(\n    conv_results: Iterable[ConversionResult],\n    output_dir: Path,\n):\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    success_count = 0\n    failure_count = 0\n    partial_success_count = 0\n\n    for conv_res in conv_results:\n        if conv_res.status == ConversionStatus.SUCCESS:\n            success_count += 1\n            doc_filename = conv_res.input.file.stem\n\n            if USE_V2:\n                # Export Docling document format to JSON:\n                with (output_dir / f\"{doc_filename}.json\").open(\"w\") as fp:\n                    fp.write(json.dumps(conv_res.document.export_to_dict()))\n\n                # Export Docling document format to YAML:\n                with (output_dir / f\"{doc_filename}.yaml\").open(\"w\") as fp:\n                    fp.write(yaml.safe_dump(conv_res.document.export_to_dict()))\n\n                # Export Docling document format to doctags:\n                with (output_dir / f\"{doc_filename}.doctags.txt\").open(\"w\") as fp:\n                    fp.write(conv_res.document.export_to_document_tokens())\n\n                # Export Docling document format to markdown:\n                with (output_dir / f\"{doc_filename}.md\").open(\"w\") as fp:\n                    fp.write(conv_res.document.export_to_markdown())\n\n                # Export Docling document format to text:\n                with (output_dir / f\"{doc_filename}.txt\").open(\"w\") as fp:\n                    fp.write(conv_res.document.export_to_markdown(strict_text=True))\n\n            if USE_LEGACY:\n                # Export Deep Search document JSON format:\n                with (output_dir / f\"{doc_filename}.legacy.json\").open(\n                    \"w\", encoding=\"utf-8\"\n                ) as fp:\n                    fp.write(json.dumps(conv_res.legacy_document.export_to_dict()))\n\n                # Export Text format:\n                with (output_dir / f\"{doc_filename}.legacy.txt\").open(\n                    \"w\", encoding=\"utf-8\"\n                ) as fp:\n                    fp.write(\n                        conv_res.legacy_document.export_to_markdown(strict_text=True)\n                    )\n\n                # Export Markdown format:\n                with (output_dir / f\"{doc_filename}.legacy.md\").open(\n                    \"w\", encoding=\"utf-8\"\n                ) as fp:\n                    fp.write(conv_res.legacy_document.export_to_markdown())\n\n                # Export Document Tags format:\n                with (output_dir / f\"{doc_filename}.legacy.doctags.txt\").open(\n                    \"w\", encoding=\"utf-8\"\n                ) as fp:\n                    fp.write(conv_res.legacy_document.export_to_document_tokens())\n\n        elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:\n            _log.info(\n                f\"Document {conv_res.input.file} was partially converted with the following errors:\"\n            )\n            for item in conv_res.errors:\n                _log.info(f\"\\t{item.error_message}\")\n            partial_success_count += 1\n        else:\n            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n            failure_count += 1\n\n    _log.info(\n        f\"Processed {success_count + partial_success_count + failure_count} docs, \"\n        f\"of which {failure_count} failed \"\n        f\"and {partial_success_count} were partially converted.\"\n    )\n    return success_count, partial_success_count, failure_count\n</pre> def export_documents(     conv_results: Iterable[ConversionResult],     output_dir: Path, ):     output_dir.mkdir(parents=True, exist_ok=True)      success_count = 0     failure_count = 0     partial_success_count = 0      for conv_res in conv_results:         if conv_res.status == ConversionStatus.SUCCESS:             success_count += 1             doc_filename = conv_res.input.file.stem              if USE_V2:                 # Export Docling document format to JSON:                 with (output_dir / f\"{doc_filename}.json\").open(\"w\") as fp:                     fp.write(json.dumps(conv_res.document.export_to_dict()))                  # Export Docling document format to YAML:                 with (output_dir / f\"{doc_filename}.yaml\").open(\"w\") as fp:                     fp.write(yaml.safe_dump(conv_res.document.export_to_dict()))                  # Export Docling document format to doctags:                 with (output_dir / f\"{doc_filename}.doctags.txt\").open(\"w\") as fp:                     fp.write(conv_res.document.export_to_document_tokens())                  # Export Docling document format to markdown:                 with (output_dir / f\"{doc_filename}.md\").open(\"w\") as fp:                     fp.write(conv_res.document.export_to_markdown())                  # Export Docling document format to text:                 with (output_dir / f\"{doc_filename}.txt\").open(\"w\") as fp:                     fp.write(conv_res.document.export_to_markdown(strict_text=True))              if USE_LEGACY:                 # Export Deep Search document JSON format:                 with (output_dir / f\"{doc_filename}.legacy.json\").open(                     \"w\", encoding=\"utf-8\"                 ) as fp:                     fp.write(json.dumps(conv_res.legacy_document.export_to_dict()))                  # Export Text format:                 with (output_dir / f\"{doc_filename}.legacy.txt\").open(                     \"w\", encoding=\"utf-8\"                 ) as fp:                     fp.write(                         conv_res.legacy_document.export_to_markdown(strict_text=True)                     )                  # Export Markdown format:                 with (output_dir / f\"{doc_filename}.legacy.md\").open(                     \"w\", encoding=\"utf-8\"                 ) as fp:                     fp.write(conv_res.legacy_document.export_to_markdown())                  # Export Document Tags format:                 with (output_dir / f\"{doc_filename}.legacy.doctags.txt\").open(                     \"w\", encoding=\"utf-8\"                 ) as fp:                     fp.write(conv_res.legacy_document.export_to_document_tokens())          elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:             _log.info(                 f\"Document {conv_res.input.file} was partially converted with the following errors:\"             )             for item in conv_res.errors:                 _log.info(f\"\\t{item.error_message}\")             partial_success_count += 1         else:             _log.info(f\"Document {conv_res.input.file} failed to convert.\")             failure_count += 1      _log.info(         f\"Processed {success_count + partial_success_count + failure_count} docs, \"         f\"of which {failure_count} failed \"         f\"and {partial_success_count} were partially converted.\"     )     return success_count, partial_success_count, failure_count In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n        Path(\"./tests/data/2203.01017v2.pdf\"),\n        Path(\"./tests/data/2305.03393v1.pdf\"),\n        Path(\"./tests/data/redp5110_sampled.pdf\"),\n    ]\n\n    # buf = BytesIO(Path(\"./test/data/2206.01062.pdf\").open(\"rb\").read())\n    # docs = [DocumentStream(name=\"my_doc.pdf\", stream=buf)]\n    # input = DocumentConversionInput.from_streams(docs)\n\n    # # Turn on inline debug visualizations:\n    # settings.debug.visualize_layout = True\n    # settings.debug.visualize_ocr = True\n    # settings.debug.visualize_tables = True\n    # settings.debug.visualize_cells = True\n\n    doc_converter = DocumentConverter()\n\n    start_time = time.time()\n\n    conv_results = doc_converter.convert_all(\n        input_doc_paths,\n        raises_on_error=False,  # to let conversion run through all and examine results at the end\n    )\n    success_count, partial_success_count, failure_count = export_documents(\n        conv_results, output_dir=Path(\"scratch\")\n    )\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"Document conversion complete in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),         Path(\"./tests/data/2203.01017v2.pdf\"),         Path(\"./tests/data/2305.03393v1.pdf\"),         Path(\"./tests/data/redp5110_sampled.pdf\"),     ]      # buf = BytesIO(Path(\"./test/data/2206.01062.pdf\").open(\"rb\").read())     # docs = [DocumentStream(name=\"my_doc.pdf\", stream=buf)]     # input = DocumentConversionInput.from_streams(docs)      # # Turn on inline debug visualizations:     # settings.debug.visualize_layout = True     # settings.debug.visualize_ocr = True     # settings.debug.visualize_tables = True     # settings.debug.visualize_cells = True      doc_converter = DocumentConverter()      start_time = time.time()      conv_results = doc_converter.convert_all(         input_doc_paths,         raises_on_error=False,  # to let conversion run through all and examine results at the end     )     success_count, partial_success_count, failure_count = export_documents(         conv_results, output_dir=Path(\"scratch\")     )      end_time = time.time() - start_time      _log.info(f\"Document conversion complete in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/custom_convert/","title":"Custom conversion","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nimport time\nfrom pathlib import Path\n</pre> import json import logging import time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>from docowling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.models.ocr_mac_model import OcrMacOptions\nfrom docowling.models.tesseract_ocr_cli_model import TesseractCliOcrOptions\nfrom docowling.models.tesseract_ocr_model import TesseractOcrOptions\n</pre> from docowling.backend.pypdfium2_backend import PyPdfiumDocumentBackend from docowling.datamodel.base_models import InputFormat from docowling.datamodel.pipeline_options import PdfPipelineOptions from docowling.document_converter import DocumentConverter, PdfFormatOption from docowling.models.ocr_mac_model import OcrMacOptions from docowling.models.tesseract_ocr_cli_model import TesseractCliOcrOptions from docowling.models.tesseract_ocr_model import TesseractOcrOptions In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_path = Path(\"./tests/data/2206.01062.pdf\")\n\n    ###########################################################################\n\n    # The following sections contain a combination of PipelineOptions\n    # and PDF Backends for various configurations.\n    # Uncomment one section at the time to see the differences in the output.\n\n    # PyPdfium without EasyOCR\n    # --------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = False\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = False\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(\n    #             pipeline_options=pipeline_options, backend=PyPdfiumDocumentBackend\n    #         )\n    #     }\n    # )\n\n    # PyPdfium with EasyOCR\n    # -----------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(\n    #             pipeline_options=pipeline_options, backend=PyPdfiumDocumentBackend\n    #         )\n    #     }\n    # )\n\n    # Docling Parse without EasyOCR\n    # -------------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = False\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    #     }\n    # )\n\n    # Docling Parse with EasyOCR\n    # ----------------------\n    pipeline_options = PdfPipelineOptions()\n    pipeline_options.do_ocr = True\n    pipeline_options.do_table_structure = True\n    pipeline_options.table_structure_options.do_cell_matching = True\n    pipeline_options.ocr_options.lang = [\"es\"]\n    pipeline_options.accelerator_options = AcceleratorOptions(\n        num_threads=4, device=Device.AUTO\n    )\n\n    doc_converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n        }\n    )\n\n    # Docling Parse with EasyOCR (CPU only)\n    # ----------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.ocr_options.use_gpu = False  # &lt;-- set this.\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    #     }\n    # )\n\n    # Docling Parse with Tesseract\n    # ----------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n    # pipeline_options.ocr_options = TesseractOcrOptions()\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    #     }\n    # )\n\n    # Docling Parse with Tesseract CLI\n    # ----------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n    # pipeline_options.ocr_options = TesseractCliOcrOptions()\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    #     }\n    # )\n\n    # Docling Parse with ocrmac(Mac only)\n    # ----------------------\n    # pipeline_options = PdfPipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n    # pipeline_options.ocr_options = OcrMacOptions()\n\n    # doc_converter = DocumentConverter(\n    #     format_options={\n    #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    #     }\n    # )\n\n    ###########################################################################\n\n    start_time = time.time()\n    conv_result = doc_converter.convert(input_doc_path)\n    end_time = time.time() - start_time\n\n    _log.info(f\"Document converted in {end_time:.2f} seconds.\")\n\n    ## Export results\n    output_dir = Path(\"scratch\")\n    output_dir.mkdir(parents=True, exist_ok=True)\n    doc_filename = conv_result.input.file.stem\n\n    # Export Deep Search document JSON format:\n    with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n        fp.write(json.dumps(conv_result.document.export_to_dict()))\n\n    # Export Text format:\n    with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n        fp.write(conv_result.document.export_to_text())\n\n    # Export Markdown format:\n    with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n        fp.write(conv_result.document.export_to_markdown())\n\n    # Export Document Tags format:\n    with (output_dir / f\"{doc_filename}.doctags\").open(\"w\", encoding=\"utf-8\") as fp:\n        fp.write(conv_result.document.export_to_document_tokens())\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_path = Path(\"./tests/data/2206.01062.pdf\")      ###########################################################################      # The following sections contain a combination of PipelineOptions     # and PDF Backends for various configurations.     # Uncomment one section at the time to see the differences in the output.      # PyPdfium without EasyOCR     # --------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = False     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = False      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(     #             pipeline_options=pipeline_options, backend=PyPdfiumDocumentBackend     #         )     #     }     # )      # PyPdfium with EasyOCR     # -----------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(     #             pipeline_options=pipeline_options, backend=PyPdfiumDocumentBackend     #         )     #     }     # )      # Docling Parse without EasyOCR     # -------------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = False     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)     #     }     # )      # Docling Parse with EasyOCR     # ----------------------     pipeline_options = PdfPipelineOptions()     pipeline_options.do_ocr = True     pipeline_options.do_table_structure = True     pipeline_options.table_structure_options.do_cell_matching = True     pipeline_options.ocr_options.lang = [\"es\"]     pipeline_options.accelerator_options = AcceleratorOptions(         num_threads=4, device=Device.AUTO     )      doc_converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)         }     )      # Docling Parse with EasyOCR (CPU only)     # ----------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.ocr_options.use_gpu = False  # &lt;-- set this.     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)     #     }     # )      # Docling Parse with Tesseract     # ----------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True     # pipeline_options.ocr_options = TesseractOcrOptions()      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)     #     }     # )      # Docling Parse with Tesseract CLI     # ----------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True     # pipeline_options.ocr_options = TesseractCliOcrOptions()      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)     #     }     # )      # Docling Parse with ocrmac(Mac only)     # ----------------------     # pipeline_options = PdfPipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True     # pipeline_options.ocr_options = OcrMacOptions()      # doc_converter = DocumentConverter(     #     format_options={     #         InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)     #     }     # )      ###########################################################################      start_time = time.time()     conv_result = doc_converter.convert(input_doc_path)     end_time = time.time() - start_time      _log.info(f\"Document converted in {end_time:.2f} seconds.\")      ## Export results     output_dir = Path(\"scratch\")     output_dir.mkdir(parents=True, exist_ok=True)     doc_filename = conv_result.input.file.stem      # Export Deep Search document JSON format:     with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:         fp.write(json.dumps(conv_result.document.export_to_dict()))      # Export Text format:     with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:         fp.write(conv_result.document.export_to_text())      # Export Markdown format:     with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:         fp.write(conv_result.document.export_to_markdown())      # Export Document Tags format:     with (output_dir / f\"{doc_filename}.doctags\").open(\"w\", encoding=\"utf-8\") as fp:         fp.write(conv_result.document.export_to_document_tokens()) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/develop_picture_enrichment/","title":"Figure enrichment","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nfrom pathlib import Path\nfrom typing import Any, Iterable\n</pre> import logging from pathlib import Path from typing import Any, Iterable In\u00a0[\u00a0]: Copied! <pre>from docling_core.types.doc import (\n    DoclingDocument,\n    NodeItem,\n    PictureClassificationClass,\n    PictureClassificationData,\n    PictureItem,\n)\n</pre> from docling_core.types.doc import (     DoclingDocument,     NodeItem,     PictureClassificationClass,     PictureClassificationData,     PictureItem, ) In\u00a0[\u00a0]: Copied! <pre>from docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.models.base_model import BaseEnrichmentModel\nfrom docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n</pre> from docowling.datamodel.base_models import InputFormat from docowling.datamodel.pipeline_options import PdfPipelineOptions from docowling.document_converter import DocumentConverter, PdfFormatOption from docowling.models.base_model import BaseEnrichmentModel from docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline In\u00a0[\u00a0]: Copied! <pre>class ExamplePictureClassifierPipelineOptions(PdfPipelineOptions):\n    do_picture_classifer: bool = True\n</pre> class ExamplePictureClassifierPipelineOptions(PdfPipelineOptions):     do_picture_classifer: bool = True In\u00a0[\u00a0]: Copied! <pre>class ExamplePictureClassifierEnrichmentModel(BaseEnrichmentModel):\n\n    def __init__(self, enabled: bool):\n        self.enabled = enabled\n\n    def is_processable(self, doc: DoclingDocument, element: NodeItem) -&gt; bool:\n        return self.enabled and isinstance(element, PictureItem)\n\n    def __call__(\n        self, doc: DoclingDocument, element_batch: Iterable[NodeItem]\n    ) -&gt; Iterable[Any]:\n        if not self.enabled:\n            return\n\n        for element in element_batch:\n            assert isinstance(element, PictureItem)\n\n            # uncomment this to interactively visualize the image\n            # element.get_image(doc).show()\n\n            element.annotations.append(\n                PictureClassificationData(\n                    provenance=\"example_classifier-0.0.1\",\n                    predicted_classes=[\n                        PictureClassificationClass(class_name=\"dummy\", confidence=0.42)\n                    ],\n                )\n            )\n\n            yield element\n</pre> class ExamplePictureClassifierEnrichmentModel(BaseEnrichmentModel):      def __init__(self, enabled: bool):         self.enabled = enabled      def is_processable(self, doc: DoclingDocument, element: NodeItem) -&gt; bool:         return self.enabled and isinstance(element, PictureItem)      def __call__(         self, doc: DoclingDocument, element_batch: Iterable[NodeItem]     ) -&gt; Iterable[Any]:         if not self.enabled:             return          for element in element_batch:             assert isinstance(element, PictureItem)              # uncomment this to interactively visualize the image             # element.get_image(doc).show()              element.annotations.append(                 PictureClassificationData(                     provenance=\"example_classifier-0.0.1\",                     predicted_classes=[                         PictureClassificationClass(class_name=\"dummy\", confidence=0.42)                     ],                 )             )              yield element In\u00a0[\u00a0]: Copied! <pre>class ExamplePictureClassifierPipeline(StandardPdfPipeline):\n\n    def __init__(self, pipeline_options: ExamplePictureClassifierPipelineOptions):\n        super().__init__(pipeline_options)\n        self.pipeline_options: ExamplePictureClassifierPipeline\n\n        self.enrichment_pipe = [\n            ExamplePictureClassifierEnrichmentModel(\n                enabled=pipeline_options.do_picture_classifer\n            )\n        ]\n\n    @classmethod\n    def get_default_options(cls) -&gt; ExamplePictureClassifierPipelineOptions:\n        return ExamplePictureClassifierPipelineOptions()\n</pre> class ExamplePictureClassifierPipeline(StandardPdfPipeline):      def __init__(self, pipeline_options: ExamplePictureClassifierPipelineOptions):         super().__init__(pipeline_options)         self.pipeline_options: ExamplePictureClassifierPipeline          self.enrichment_pipe = [             ExamplePictureClassifierEnrichmentModel(                 enabled=pipeline_options.do_picture_classifer             )         ]      @classmethod     def get_default_options(cls) -&gt; ExamplePictureClassifierPipelineOptions:         return ExamplePictureClassifierPipelineOptions() In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_path = Path(\"./tests/data/2206.01062.pdf\")\n\n    pipeline_options = ExamplePictureClassifierPipelineOptions()\n    pipeline_options.images_scale = 2.0\n    pipeline_options.generate_picture_images = True\n\n    doc_converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(\n                pipeline_cls=ExamplePictureClassifierPipeline,\n                pipeline_options=pipeline_options,\n            )\n        }\n    )\n    result = doc_converter.convert(input_doc_path)\n\n    for element, _level in result.document.iterate_items():\n        if isinstance(element, PictureItem):\n            print(\n                f\"The model populated the `data` portion of picture {element.self_ref}:\\n{element.annotations}\"\n            )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_path = Path(\"./tests/data/2206.01062.pdf\")      pipeline_options = ExamplePictureClassifierPipelineOptions()     pipeline_options.images_scale = 2.0     pipeline_options.generate_picture_images = True      doc_converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(                 pipeline_cls=ExamplePictureClassifierPipeline,                 pipeline_options=pipeline_options,             )         }     )     result = doc_converter.convert(input_doc_path)      for element, _level in result.document.iterate_items():         if isinstance(element, PictureItem):             print(                 f\"The model populated the `data` portion of picture {element.self_ref}:\\n{element.annotations}\"             ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_figures/","title":"Figure export","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nimport time\nfrom pathlib import Path\n</pre> import logging import time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n</pre> from docling_core.types.doc import ImageRefMode, PictureItem, TableItem In\u00a0[\u00a0]: Copied! <pre>from docowling.datamodel.base_models import FigureElement, InputFormat, Table\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\n</pre> from docowling.datamodel.base_models import FigureElement, InputFormat, Table from docowling.datamodel.pipeline_options import PdfPipelineOptions from docowling.document_converter import DocumentConverter, PdfFormatOption In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>IMAGE_RESOLUTION_SCALE = 2.0\n</pre> IMAGE_RESOLUTION_SCALE = 2.0 In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_path = Path(\"./tests/data/2206.01062.pdf\")\n    output_dir = Path(\"scratch\")\n\n    # Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n    # will destroy them for cleaning up memory.\n    # This is done by setting PdfPipelineOptions.images_scale, which also defines the scale of images.\n    # scale=1 correspond of a standard 72 DPI image\n    # The PdfPipelineOptions.generate_* are the selectors for the document elements which will be enriched\n    # with the image field\n    pipeline_options = PdfPipelineOptions()\n    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n    pipeline_options.generate_page_images = True\n    pipeline_options.generate_picture_images = True\n\n    doc_converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n        }\n    )\n\n    start_time = time.time()\n\n    conv_res = doc_converter.convert(input_doc_path)\n\n    output_dir.mkdir(parents=True, exist_ok=True)\n    doc_filename = conv_res.input.file.stem\n\n    # Save page images\n    for page_no, page in conv_res.document.pages.items():\n        page_no = page.page_no\n        page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"\n        with page_image_filename.open(\"wb\") as fp:\n            page.image.pil_image.save(fp, format=\"PNG\")\n\n    # Save images of figures and tables\n    table_counter = 0\n    picture_counter = 0\n    for element, _level in conv_res.document.iterate_items():\n        if isinstance(element, TableItem):\n            table_counter += 1\n            element_image_filename = (\n                output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n            )\n            with element_image_filename.open(\"wb\") as fp:\n                element.get_image(conv_res.document).save(fp, \"PNG\")\n\n        if isinstance(element, PictureItem):\n            picture_counter += 1\n            element_image_filename = (\n                output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n            )\n            with element_image_filename.open(\"wb\") as fp:\n                element.get_image(conv_res.document).save(fp, \"PNG\")\n\n    # Save markdown with embedded pictures\n    md_filename = output_dir / f\"{doc_filename}-with-images.md\"\n    conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED)\n\n    # Save markdown with externally referenced pictures\n    md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n    conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n\n    # Save HTML with externally referenced pictures\n    html_filename = output_dir / f\"{doc_filename}-with-image-refs.html\"\n    conv_res.document.save_as_html(html_filename, image_mode=ImageRefMode.REFERENCED)\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_path = Path(\"./tests/data/2206.01062.pdf\")     output_dir = Path(\"scratch\")      # Important: For operating with page images, we must keep them, otherwise the DocumentConverter     # will destroy them for cleaning up memory.     # This is done by setting PdfPipelineOptions.images_scale, which also defines the scale of images.     # scale=1 correspond of a standard 72 DPI image     # The PdfPipelineOptions.generate_* are the selectors for the document elements which will be enriched     # with the image field     pipeline_options = PdfPipelineOptions()     pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE     pipeline_options.generate_page_images = True     pipeline_options.generate_picture_images = True      doc_converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)         }     )      start_time = time.time()      conv_res = doc_converter.convert(input_doc_path)      output_dir.mkdir(parents=True, exist_ok=True)     doc_filename = conv_res.input.file.stem      # Save page images     for page_no, page in conv_res.document.pages.items():         page_no = page.page_no         page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"         with page_image_filename.open(\"wb\") as fp:             page.image.pil_image.save(fp, format=\"PNG\")      # Save images of figures and tables     table_counter = 0     picture_counter = 0     for element, _level in conv_res.document.iterate_items():         if isinstance(element, TableItem):             table_counter += 1             element_image_filename = (                 output_dir / f\"{doc_filename}-table-{table_counter}.png\"             )             with element_image_filename.open(\"wb\") as fp:                 element.get_image(conv_res.document).save(fp, \"PNG\")          if isinstance(element, PictureItem):             picture_counter += 1             element_image_filename = (                 output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"             )             with element_image_filename.open(\"wb\") as fp:                 element.get_image(conv_res.document).save(fp, \"PNG\")      # Save markdown with embedded pictures     md_filename = output_dir / f\"{doc_filename}-with-images.md\"     conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED)      # Save markdown with externally referenced pictures     md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"     conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)      # Save HTML with externally referenced pictures     html_filename = output_dir / f\"{doc_filename}-with-image-refs.html\"     conv_res.document.save_as_html(html_filename, image_mode=ImageRefMode.REFERENCED)      end_time = time.time() - start_time      _log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\") In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_multimodal/","title":"Multimodal export","text":"In\u00a0[\u00a0]: Copied! <pre>import datetime\nimport logging\nimport time\nfrom pathlib import Path\n</pre> import datetime import logging import time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre>from docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\nfrom docowling.utils.export import generate_multimodal_pages\nfrom docowling.utils.utils import create_hash\n</pre> from docowling.datamodel.base_models import InputFormat from docowling.datamodel.pipeline_options import PdfPipelineOptions from docowling.document_converter import DocumentConverter, PdfFormatOption from docowling.utils.export import generate_multimodal_pages from docowling.utils.utils import create_hash In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>IMAGE_RESOLUTION_SCALE = 2.0\n</pre> IMAGE_RESOLUTION_SCALE = 2.0 In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_path = Path(\"./tests/data/2206.01062.pdf\")\n    output_dir = Path(\"scratch\")\n\n    # Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n    # will destroy them for cleaning up memory.\n    # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.\n    # scale=1 correspond of a standard 72 DPI image\n    pipeline_options = PdfPipelineOptions()\n    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n    pipeline_options.generate_page_images = True\n\n    doc_converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n        }\n    )\n\n    start_time = time.time()\n\n    conv_res = doc_converter.convert(input_doc_path)\n\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    rows = []\n    for (\n        content_text,\n        content_md,\n        content_dt,\n        page_cells,\n        page_segments,\n        page,\n    ) in generate_multimodal_pages(conv_res):\n\n        dpi = page._default_image_scale * 72\n\n        rows.append(\n            {\n                \"document\": conv_res.input.file.name,\n                \"hash\": conv_res.input.document_hash,\n                \"page_hash\": create_hash(\n                    conv_res.input.document_hash + \":\" + str(page.page_no - 1)\n                ),\n                \"image\": {\n                    \"width\": page.image.width,\n                    \"height\": page.image.height,\n                    \"bytes\": page.image.tobytes(),\n                },\n                \"cells\": page_cells,\n                \"contents\": content_text,\n                \"contents_md\": content_md,\n                \"contents_dt\": content_dt,\n                \"segments\": page_segments,\n                \"extra\": {\n                    \"page_num\": page.page_no + 1,\n                    \"width_in_points\": page.size.width,\n                    \"height_in_points\": page.size.height,\n                    \"dpi\": dpi,\n                },\n            }\n        )\n\n    # Generate one parquet from all documents\n    df = pd.json_normalize(rows)\n    now = datetime.datetime.now()\n    output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"\n    df.to_parquet(output_filename)\n\n    end_time = time.time() - start_time\n\n    _log.info(\n        f\"Document converted and multimodal pages generated in {end_time:.2f} seconds.\"\n    )\n\n    # This block demonstrates how the file can be opened with the HF datasets library\n    # from datasets import Dataset\n    # from PIL import Image\n    # multimodal_df = pd.read_parquet(output_filename)\n\n    # # Convert pandas DataFrame to Hugging Face Dataset and load bytes into image\n    # dataset = Dataset.from_pandas(multimodal_df)\n    # def transforms(examples):\n    #     examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')\n    #     return examples\n    # dataset = dataset.map(transforms)\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_path = Path(\"./tests/data/2206.01062.pdf\")     output_dir = Path(\"scratch\")      # Important: For operating with page images, we must keep them, otherwise the DocumentConverter     # will destroy them for cleaning up memory.     # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.     # scale=1 correspond of a standard 72 DPI image     pipeline_options = PdfPipelineOptions()     pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE     pipeline_options.generate_page_images = True      doc_converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)         }     )      start_time = time.time()      conv_res = doc_converter.convert(input_doc_path)      output_dir.mkdir(parents=True, exist_ok=True)      rows = []     for (         content_text,         content_md,         content_dt,         page_cells,         page_segments,         page,     ) in generate_multimodal_pages(conv_res):          dpi = page._default_image_scale * 72          rows.append(             {                 \"document\": conv_res.input.file.name,                 \"hash\": conv_res.input.document_hash,                 \"page_hash\": create_hash(                     conv_res.input.document_hash + \":\" + str(page.page_no - 1)                 ),                 \"image\": {                     \"width\": page.image.width,                     \"height\": page.image.height,                     \"bytes\": page.image.tobytes(),                 },                 \"cells\": page_cells,                 \"contents\": content_text,                 \"contents_md\": content_md,                 \"contents_dt\": content_dt,                 \"segments\": page_segments,                 \"extra\": {                     \"page_num\": page.page_no + 1,                     \"width_in_points\": page.size.width,                     \"height_in_points\": page.size.height,                     \"dpi\": dpi,                 },             }         )      # Generate one parquet from all documents     df = pd.json_normalize(rows)     now = datetime.datetime.now()     output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"     df.to_parquet(output_filename)      end_time = time.time() - start_time      _log.info(         f\"Document converted and multimodal pages generated in {end_time:.2f} seconds.\"     )      # This block demonstrates how the file can be opened with the HF datasets library     # from datasets import Dataset     # from PIL import Image     # multimodal_df = pd.read_parquet(output_filename)      # # Convert pandas DataFrame to Hugging Face Dataset and load bytes into image     # dataset = Dataset.from_pandas(multimodal_df)     # def transforms(examples):     #     examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')     #     return examples     # dataset = dataset.map(transforms) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_tables/","title":"Table export","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nimport time\nfrom pathlib import Path\n</pre> import logging import time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre>from docowling.document_converter import DocumentConverter\n</pre> from docowling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_path = Path(\"./tests/data/2206.01062.pdf\")\n    output_dir = Path(\"scratch\")\n\n    doc_converter = DocumentConverter()\n\n    start_time = time.time()\n\n    conv_res = doc_converter.convert(input_doc_path)\n\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    doc_filename = conv_res.input.file.stem\n\n    # Export tables\n    for table_ix, table in enumerate(conv_res.document.tables):\n        table_df: pd.DataFrame = table.export_to_dataframe()\n        print(f\"## Table {table_ix}\")\n        print(table_df.to_markdown())\n\n        # Save the table as csv\n        element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n        _log.info(f\"Saving CSV table to {element_csv_filename}\")\n        table_df.to_csv(element_csv_filename)\n\n        # Save the table as html\n        element_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n        _log.info(f\"Saving HTML table to {element_html_filename}\")\n        with element_html_filename.open(\"w\") as fp:\n            fp.write(table.export_to_html())\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\")\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_path = Path(\"./tests/data/2206.01062.pdf\")     output_dir = Path(\"scratch\")      doc_converter = DocumentConverter()      start_time = time.time()      conv_res = doc_converter.convert(input_doc_path)      output_dir.mkdir(parents=True, exist_ok=True)      doc_filename = conv_res.input.file.stem      # Export tables     for table_ix, table in enumerate(conv_res.document.tables):         table_df: pd.DataFrame = table.export_to_dataframe()         print(f\"## Table {table_ix}\")         print(table_df.to_markdown())          # Save the table as csv         element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"         _log.info(f\"Saving CSV table to {element_csv_filename}\")         table_df.to_csv(element_csv_filename)          # Save the table as html         element_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"         _log.info(f\"Saving HTML table to {element_html_filename}\")         with element_html_filename.open(\"w\") as fp:             fp.write(table.export_to_html())      end_time = time.time() - start_time      _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\") In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/full_page_ocr/","title":"Force full page OCR","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>from docowling.backend.docling_parse_backend import DoclingParseDocumentBackend\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import (\n    EasyOcrOptions,\n    OcrMacOptions,\n    PdfPipelineOptions,\n    RapidOcrOptions,\n    TesseractCliOcrOptions,\n    TesseractOcrOptions,\n)\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\n</pre> from docowling.backend.docling_parse_backend import DoclingParseDocumentBackend from docowling.datamodel.base_models import InputFormat from docowling.datamodel.pipeline_options import (     EasyOcrOptions,     OcrMacOptions,     PdfPipelineOptions,     RapidOcrOptions,     TesseractCliOcrOptions,     TesseractOcrOptions, ) from docowling.document_converter import DocumentConverter, PdfFormatOption In\u00a0[\u00a0]: Copied! <pre>def main():\n    input_doc = Path(\"./tests/data/2206.01062.pdf\")\n\n    pipeline_options = PdfPipelineOptions()\n    pipeline_options.do_ocr = True\n    pipeline_options.do_table_structure = True\n    pipeline_options.table_structure_options.do_cell_matching = True\n\n    # Any of the OCR options can be used:EasyOcrOptions, TesseractOcrOptions, TesseractCliOcrOptions, OcrMacOptions(Mac only), RapidOcrOptions\n    # ocr_options = EasyOcrOptions(force_full_page_ocr=True)\n    # ocr_options = TesseractOcrOptions(force_full_page_ocr=True)\n    # ocr_options = OcrMacOptions(force_full_page_ocr=True)\n    # ocr_options = RapidOcrOptions(force_full_page_ocr=True)\n    ocr_options = TesseractCliOcrOptions(force_full_page_ocr=True)\n    pipeline_options.ocr_options = ocr_options\n\n    converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(\n                pipeline_options=pipeline_options,\n            )\n        }\n    )\n\n    doc = converter.convert(input_doc).document\n    md = doc.export_to_markdown()\n    print(md)\n</pre> def main():     input_doc = Path(\"./tests/data/2206.01062.pdf\")      pipeline_options = PdfPipelineOptions()     pipeline_options.do_ocr = True     pipeline_options.do_table_structure = True     pipeline_options.table_structure_options.do_cell_matching = True      # Any of the OCR options can be used:EasyOcrOptions, TesseractOcrOptions, TesseractCliOcrOptions, OcrMacOptions(Mac only), RapidOcrOptions     # ocr_options = EasyOcrOptions(force_full_page_ocr=True)     # ocr_options = TesseractOcrOptions(force_full_page_ocr=True)     # ocr_options = OcrMacOptions(force_full_page_ocr=True)     # ocr_options = RapidOcrOptions(force_full_page_ocr=True)     ocr_options = TesseractCliOcrOptions(force_full_page_ocr=True)     pipeline_options.ocr_options = ocr_options      converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(                 pipeline_options=pipeline_options,             )         }     )      doc = converter.convert(input_doc).document     md = doc.export_to_markdown()     print(md) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/hybrid_chunking/","title":"Hybrid Chunking","text":"In\u00a0[1]: Copied! <pre>%pip install -qU 'docling-core[chunking]' sentence-transformers transformers lancedb\n</pre> %pip install -qU 'docling-core[chunking]' sentence-transformers transformers lancedb <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>from docowling.document_converter import DocumentConverter\n\nDOC_SOURCE = \"../../tests/data/md/wiki.md\"\n\ndoc = DocumentConverter().convert(source=DOC_SOURCE).document\n</pre> from docowling.document_converter import DocumentConverter  DOC_SOURCE = \"../../tests/data/md/wiki.md\"  doc = DocumentConverter().convert(source=DOC_SOURCE).document <p>Notice how <code>tokenizer</code> and <code>embed_model</code> further below are single-sourced from <code>EMBED_MODEL_ID</code>.</p> <p>This is important for making sure the chunker and the embedding model are using the same tokenizer.</p> In\u00a0[3]: Copied! <pre>from transformers import AutoTokenizer\n\nfrom docowling.chunking import HybridChunker\n\nEMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nMAX_TOKENS = 64\n\ntokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_ID)\n\nchunker = HybridChunker(\n    tokenizer=tokenizer,  # can also just pass model name instead of tokenizer instance\n    max_tokens=MAX_TOKENS,  # optional, by default derived from `tokenizer`\n    # merge_peers=True,  # optional, defaults to True\n)\nchunk_iter = chunker.chunk(dl_doc=doc)\nchunks = list(chunk_iter)\n</pre> from transformers import AutoTokenizer  from docowling.chunking import HybridChunker  EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\" MAX_TOKENS = 64  tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_ID)  chunker = HybridChunker(     tokenizer=tokenizer,  # can also just pass model name instead of tokenizer instance     max_tokens=MAX_TOKENS,  # optional, by default derived from `tokenizer`     # merge_peers=True,  # optional, defaults to True ) chunk_iter = chunker.chunk(dl_doc=doc) chunks = list(chunk_iter) <p>Points to notice:</p> <ul> <li>Where possible, we fit the limit of 64 tokens for the metadata-enriched serialization form (see chunk 2)</li> <li>Where neeeded, we stop before the limit, e.g. see cases of 63 as it would otherwise run into a comma (see chunk 6)</li> <li>Where possible, we merge undersized peer chunks (see chunk 0)</li> <li>\"Tail\" chunks trailing right after merges may still be undersized (see chunk 8)</li> </ul> In\u00a0[4]: Copied! <pre>for i, chunk in enumerate(chunks):\n    print(f\"=== {i} ===\")\n    txt_tokens = len(tokenizer.tokenize(chunk.text, max_length=None))\n    print(f\"chunk.text ({txt_tokens} tokens):\\n{repr(chunk.text)}\")\n\n    ser_txt = chunker.serialize(chunk=chunk)\n    ser_tokens = len(tokenizer.tokenize(ser_txt, max_length=None))\n    print(f\"chunker.serialize(chunk) ({ser_tokens} tokens):\\n{repr(ser_txt)}\")\n\n    print()\n</pre> for i, chunk in enumerate(chunks):     print(f\"=== {i} ===\")     txt_tokens = len(tokenizer.tokenize(chunk.text, max_length=None))     print(f\"chunk.text ({txt_tokens} tokens):\\n{repr(chunk.text)}\")      ser_txt = chunker.serialize(chunk=chunk)     ser_tokens = len(tokenizer.tokenize(ser_txt, max_length=None))     print(f\"chunker.serialize(chunk) ({ser_tokens} tokens):\\n{repr(ser_txt)}\")      print() <pre>=== 0 ===\nchunk.text (55 tokens):\n'International Business Machines Corporation (using the trademark IBM), nicknamed Big Blue, is an American multinational technology company headquartered in Armonk, New York and present in over 175 countries.\\nIt is a publicly traded company and one of the 30 companies in the Dow Jones Industrial Average.'\nchunker.serialize(chunk) (56 tokens):\n'IBM\\nInternational Business Machines Corporation (using the trademark IBM), nicknamed Big Blue, is an American multinational technology company headquartered in Armonk, New York and present in over 175 countries.\\nIt is a publicly traded company and one of the 30 companies in the Dow Jones Industrial Average.'\n\n=== 1 ===\nchunk.text (45 tokens):\n'IBM is the largest industrial research organization in the world, with 19 research facilities across a dozen countries, having held the record for most annual U.S. patents generated by a business for 29 consecutive years from 1993 to 2021.'\nchunker.serialize(chunk) (46 tokens):\n'IBM\\nIBM is the largest industrial research organization in the world, with 19 research facilities across a dozen countries, having held the record for most annual U.S. patents generated by a business for 29 consecutive years from 1993 to 2021.'\n\n=== 2 ===\nchunk.text (63 tokens):\n'IBM was founded in 1911 as the Computing-Tabulating-Recording Company (CTR), a holding company of manufacturers of record-keeping and measuring systems. It was renamed \"International Business Machines\" in 1924 and soon became the leading manufacturer of punch-card tabulating systems. During the 1960s and 1970s, the'\nchunker.serialize(chunk) (64 tokens):\n'IBM\\nIBM was founded in 1911 as the Computing-Tabulating-Recording Company (CTR), a holding company of manufacturers of record-keeping and measuring systems. It was renamed \"International Business Machines\" in 1924 and soon became the leading manufacturer of punch-card tabulating systems. During the 1960s and 1970s, the'\n\n=== 3 ===\nchunk.text (44 tokens):\n\"IBM mainframe, exemplified by the System/360, was the world's dominant computing platform, with the company producing 80 percent of computers in the U.S. and 70 percent of computers worldwide.[11]\"\nchunker.serialize(chunk) (45 tokens):\n\"IBM\\nIBM mainframe, exemplified by the System/360, was the world's dominant computing platform, with the company producing 80 percent of computers in the U.S. and 70 percent of computers worldwide.[11]\"\n\n=== 4 ===\nchunk.text (63 tokens):\n'IBM debuted in the microcomputer market in 1981 with the IBM Personal Computer, \u2014 its DOS software provided by Microsoft, \u2014 which became the basis for the majority of personal computers to the present day.[12] The company later also found success in the portable space with the ThinkPad. Since the 1990s,'\nchunker.serialize(chunk) (64 tokens):\n'IBM\\nIBM debuted in the microcomputer market in 1981 with the IBM Personal Computer, \u2014 its DOS software provided by Microsoft, \u2014 which became the basis for the majority of personal computers to the present day.[12] The company later also found success in the portable space with the ThinkPad. Since the 1990s,'\n\n=== 5 ===\nchunk.text (61 tokens):\n'IBM has concentrated on computer services, software, supercomputers, and scientific research; it sold its microcomputer division to Lenovo in 2005. IBM continues to develop mainframes, and its supercomputers have consistently ranked among the most powerful in the world in the 21st century.'\nchunker.serialize(chunk) (62 tokens):\n'IBM\\nIBM has concentrated on computer services, software, supercomputers, and scientific research; it sold its microcomputer division to Lenovo in 2005. IBM continues to develop mainframes, and its supercomputers have consistently ranked among the most powerful in the world in the 21st century.'\n\n=== 6 ===\nchunk.text (62 tokens):\n\"As one of the world's oldest and largest technology companies, IBM has been responsible for several technological innovations, including the automated teller machine (ATM), dynamic random-access memory (DRAM), the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, the SQL programming\"\nchunker.serialize(chunk) (63 tokens):\n\"IBM\\nAs one of the world's oldest and largest technology companies, IBM has been responsible for several technological innovations, including the automated teller machine (ATM), dynamic random-access memory (DRAM), the floppy disk, the hard disk drive, the magnetic stripe card, the relational database, the SQL programming\"\n\n=== 7 ===\nchunk.text (63 tokens):\n'language, and the UPC barcode. The company has made inroads in advanced computer chips, quantum computing, artificial intelligence, and data infrastructure.[13][14][15] IBM employees and alumni have won various recognitions for their scientific research and inventions, including six Nobel Prizes and six Turing'\nchunker.serialize(chunk) (64 tokens):\n'IBM\\nlanguage, and the UPC barcode. The company has made inroads in advanced computer chips, quantum computing, artificial intelligence, and data infrastructure.[13][14][15] IBM employees and alumni have won various recognitions for their scientific research and inventions, including six Nobel Prizes and six Turing'\n\n=== 8 ===\nchunk.text (5 tokens):\n'Awards.[16]'\nchunker.serialize(chunk) (6 tokens):\n'IBM\\nAwards.[16]'\n\n=== 9 ===\nchunk.text (56 tokens):\n'IBM originated with several technological innovations developed and commercialized in the late 19th century. Julius E. Pitrap patented the computing scale in 1885;[17] Alexander Dey invented the dial recorder (1888);[18] Herman Hollerith patented the Electric Tabulating Machine'\nchunker.serialize(chunk) (60 tokens):\n'IBM\\n1910s\u20131950s\\nIBM originated with several technological innovations developed and commercialized in the late 19th century. Julius E. Pitrap patented the computing scale in 1885;[17] Alexander Dey invented the dial recorder (1888);[18] Herman Hollerith patented the Electric Tabulating Machine'\n\n=== 10 ===\nchunk.text (60 tokens):\n\"(1889);[19] and Willard Bundy invented a time clock to record workers' arrival and departure times on a paper tape (1889).[20] On June 16, 1911, their four companies were amalgamated in New York State by Charles Ranlett Flint forming a fifth company, the\"\nchunker.serialize(chunk) (64 tokens):\n\"IBM\\n1910s\u20131950s\\n(1889);[19] and Willard Bundy invented a time clock to record workers' arrival and departure times on a paper tape (1889).[20] On June 16, 1911, their four companies were amalgamated in New York State by Charles Ranlett Flint forming a fifth company, the\"\n\n=== 11 ===\nchunk.text (59 tokens):\n'Computing-Tabulating-Recording Company (CTR) based in Endicott, New York.[1][21] The five companies had 1,300 employees and offices and plants in Endicott and Binghamton, New York; Dayton, Ohio; Detroit, Michigan; Washington,'\nchunker.serialize(chunk) (63 tokens):\n'IBM\\n1910s\u20131950s\\nComputing-Tabulating-Recording Company (CTR) based in Endicott, New York.[1][21] The five companies had 1,300 employees and offices and plants in Endicott and Binghamton, New York; Dayton, Ohio; Detroit, Michigan; Washington,'\n\n=== 12 ===\nchunk.text (13 tokens):\n'D.C.; and Toronto, Canada.[22]'\nchunker.serialize(chunk) (17 tokens):\n'IBM\\n1910s\u20131950s\\nD.C.; and Toronto, Canada.[22]'\n\n=== 13 ===\nchunk.text (60 tokens):\n'Collectively, the companies manufactured a wide array of machinery for sale and lease, ranging from commercial scales and industrial time recorders, meat and cheese slicers, to tabulators and punched cards. Thomas J. Watson, Sr., fired from the National Cash Register Company by John Henry Patterson, called'\nchunker.serialize(chunk) (64 tokens):\n'IBM\\n1910s\u20131950s\\nCollectively, the companies manufactured a wide array of machinery for sale and lease, ranging from commercial scales and industrial time recorders, meat and cheese slicers, to tabulators and punched cards. Thomas J. Watson, Sr., fired from the National Cash Register Company by John Henry Patterson, called'\n\n=== 14 ===\nchunk.text (59 tokens):\n\"on Flint and, in 1914, was offered a position at CTR.[23] Watson joined CTR as general manager and then, 11 months later, was made President when antitrust cases relating to his time at NCR were resolved.[24] Having learned Patterson's pioneering business\"\nchunker.serialize(chunk) (63 tokens):\n\"IBM\\n1910s\u20131950s\\non Flint and, in 1914, was offered a position at CTR.[23] Watson joined CTR as general manager and then, 11 months later, was made President when antitrust cases relating to his time at NCR were resolved.[24] Having learned Patterson's pioneering business\"\n\n=== 15 ===\nchunk.text (23 tokens):\n\"practices, Watson proceeded to put the stamp of NCR onto CTR's companies.[23]:\\n105\"\nchunker.serialize(chunk) (27 tokens):\n\"IBM\\n1910s\u20131950s\\npractices, Watson proceeded to put the stamp of NCR onto CTR's companies.[23]:\\n105\"\n\n=== 16 ===\nchunk.text (59 tokens):\n'He implemented sales conventions, \"generous sales incentives, a focus on customer service, an insistence on well-groomed, dark-suited salesmen and had an evangelical fervor for instilling company pride and loyalty in every worker\".[25][26] His favorite slogan,'\nchunker.serialize(chunk) (63 tokens):\n'IBM\\n1910s\u20131950s\\nHe implemented sales conventions, \"generous sales incentives, a focus on customer service, an insistence on well-groomed, dark-suited salesmen and had an evangelical fervor for instilling company pride and loyalty in every worker\".[25][26] His favorite slogan,'\n\n=== 17 ===\nchunk.text (60 tokens):\n'\"THINK\", became a mantra for each company\\'s employees.[25] During Watson\\'s first four years, revenues reached $9 million ($158 million today) and the company\\'s operations expanded to Europe, South America, Asia and Australia.[25] Watson never liked the'\nchunker.serialize(chunk) (64 tokens):\n'IBM\\n1910s\u20131950s\\n\"THINK\", became a mantra for each company\\'s employees.[25] During Watson\\'s first four years, revenues reached $9 million ($158 million today) and the company\\'s operations expanded to Europe, South America, Asia and Australia.[25] Watson never liked the'\n\n=== 18 ===\nchunk.text (57 tokens):\n'clumsy hyphenated name \"Computing-Tabulating-Recording Company\" and chose to replace it with the more expansive title \"International Business Machines\" which had previously been used as the name of CTR\\'s Canadian Division;[27] the name was changed on February 14,'\nchunker.serialize(chunk) (61 tokens):\n'IBM\\n1910s\u20131950s\\nclumsy hyphenated name \"Computing-Tabulating-Recording Company\" and chose to replace it with the more expansive title \"International Business Machines\" which had previously been used as the name of CTR\\'s Canadian Division;[27] the name was changed on February 14,'\n\n=== 19 ===\nchunk.text (21 tokens):\n'1924.[28] By 1933, most of the subsidiaries had been merged into one company, IBM.'\nchunker.serialize(chunk) (25 tokens):\n'IBM\\n1910s\u20131950s\\n1924.[28] By 1933, most of the subsidiaries had been merged into one company, IBM.'\n\n=== 20 ===\nchunk.text (22 tokens):\n'In 1961, IBM developed the SABRE reservation system for American Airlines and introduced the highly successful Selectric typewriter.'\nchunker.serialize(chunk) (26 tokens):\n'IBM\\n1960s\u20131980s\\nIn 1961, IBM developed the SABRE reservation system for American Airlines and introduced the highly successful Selectric typewriter.'\n\n</pre> In\u00a0[5]: Copied! <pre>from sentence_transformers import SentenceTransformer\n\nembed_model = SentenceTransformer(EMBED_MODEL_ID)\n</pre> from sentence_transformers import SentenceTransformer  embed_model = SentenceTransformer(EMBED_MODEL_ID) <pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n</pre> In\u00a0[6]: Copied! <pre>from pathlib import Path\nfrom tempfile import mkdtemp\n\nimport lancedb\n\n\ndef make_lancedb_index(db_uri, index_name, chunks, embedding_model):\n    db = lancedb.connect(db_uri)\n    data = []\n    for chunk in chunks:\n        embeddings = embedding_model.encode(chunker.serialize(chunk=chunk))\n        data_item = {\n            \"vector\": embeddings,\n            \"text\": chunk.text,\n            \"headings\": chunk.meta.headings,\n            \"captions\": chunk.meta.captions,\n        }\n        data.append(data_item)\n    tbl = db.create_table(index_name, data=data, exist_ok=True)\n    return tbl\n\n\ndb_uri = str(Path(mkdtemp()) / \"docowling.db\")\nindex = make_lancedb_index(db_uri, doc.name, chunks, embed_model)\n\nsample_query = \"invent\"\nsample_embedding = embed_model.encode(sample_query)\nresults = index.search(sample_embedding).limit(5)\n\nresults.to_pandas()\n</pre> from pathlib import Path from tempfile import mkdtemp  import lancedb   def make_lancedb_index(db_uri, index_name, chunks, embedding_model):     db = lancedb.connect(db_uri)     data = []     for chunk in chunks:         embeddings = embedding_model.encode(chunker.serialize(chunk=chunk))         data_item = {             \"vector\": embeddings,             \"text\": chunk.text,             \"headings\": chunk.meta.headings,             \"captions\": chunk.meta.captions,         }         data.append(data_item)     tbl = db.create_table(index_name, data=data, exist_ok=True)     return tbl   db_uri = str(Path(mkdtemp()) / \"docowling.db\") index = make_lancedb_index(db_uri, doc.name, chunks, embed_model)  sample_query = \"invent\" sample_embedding = embed_model.encode(sample_query) results = index.search(sample_embedding).limit(5)  results.to_pandas() Out[6]: vector text headings captions _distance 0 [-0.1269039, -0.01948185, -0.07718097, -0.1116... language, and the UPC barcode. The company has... [IBM] None 1.164613 1 [-0.10198064, 0.0055981805, -0.05095279, -0.13... IBM originated with several technological inno... [IBM, 1910s\u20131950s] None 1.245144 2 [-0.057121325, -0.034115084, -0.018113216, -0.... As one of the world's oldest and largest techn... [IBM] None 1.355586 3 [-0.04429054, -0.058111433, -0.009330196, -0.0... IBM is the largest industrial research organiz... [IBM] None 1.398617 4 [-0.11920792, 0.053496413, -0.042391937, -0.03... Awards.[16] [IBM] None 1.446295"},{"location":"examples/hybrid_chunking/#hybrid-chunking","title":"Hybrid Chunking\u00b6","text":""},{"location":"examples/hybrid_chunking/#conversion","title":"Conversion\u00b6","text":""},{"location":"examples/hybrid_chunking/#chunking","title":"Chunking\u00b6","text":""},{"location":"examples/hybrid_chunking/#vector-retrieval","title":"Vector Retrieval\u00b6","text":""},{"location":"examples/hybrid_rag_qdrant/","title":"Hybrid RAG with Qdrant","text":"<p>This example demonstrates using Docling with Qdrant to perform a hybrid search across your documents using dense and sparse vectors.</p> <p>We'll chunk the documents using Docling before adding them to a Qdrant collection. By limiting the length of the chunks, we can preserve the meaning in each vector embedding.</p> <ul> <li>\ud83d\udc49 Qdrant client uses FastEmbed to generate vector embeddings. You can install the <code>fastembed-gpu</code> package if you've got the hardware to support it.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>%pip install --no-warn-conflicts -q qdrant-client docling docling-core fastembed\n</pre> %pip install --no-warn-conflicts -q qdrant-client docling docling-core fastembed <pre>\n[notice] A new release of pip is available: 24.2 -&gt; 24.3.1\n[notice] To update, run: pip install --upgrade pip\nNote: you may need to restart the kernel to use updated packages.\n</pre> <p>Let's import all the classes we'll be working with.</p> In\u00a0[1]: Copied! <pre>from docling_core.transforms.chunker import HierarchicalChunker\nfrom qdrant_client import QdrantClient\n\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.document_converter import DocumentConverter\n</pre> from docling_core.transforms.chunker import HierarchicalChunker from qdrant_client import QdrantClient  from docowling.datamodel.base_models import InputFormat from docowling.document_converter import DocumentConverter <ul> <li>For Docling, we'll set the  allowed formats to HTML since we'll only be working with webpages in this tutorial.</li> <li>If we set a sparse model, Qdrant client will fuse the dense and sparse results using RRF. Reference.</li> </ul> In\u00a0[2]: Copied! <pre>COLLECTION_NAME = \"docling\"\n\ndoc_converter = DocumentConverter(allowed_formats=[InputFormat.HTML])\nclient = QdrantClient(location=\":memory:\")\n# The :memory: mode is a Python imitation of Qdrant's APIs for prototyping and CI.\n# For production deployments, use the Docker image: docker run -p 6333:6333 qdrant/qdrant\n# client = QdrantClient(location=\"http://localhost:6333\")\n\nclient.set_model(\"sentence-transformers/all-MiniLM-L6-v2\")\nclient.set_sparse_model(\"Qdrant/bm25\")\n</pre> COLLECTION_NAME = \"docling\"  doc_converter = DocumentConverter(allowed_formats=[InputFormat.HTML]) client = QdrantClient(location=\":memory:\") # The :memory: mode is a Python imitation of Qdrant's APIs for prototyping and CI. # For production deployments, use the Docker image: docker run -p 6333:6333 qdrant/qdrant # client = QdrantClient(location=\"http://localhost:6333\")  client.set_model(\"sentence-transformers/all-MiniLM-L6-v2\") client.set_sparse_model(\"Qdrant/bm25\") <pre>Fetching 5 files:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>Fetching 29 files:   0%|          | 0/29 [00:00&lt;?, ?it/s]</pre> <p>We can now download and chunk the document using Docling. For demonstration, we'll use an article about chunking strategies :)</p> In\u00a0[3]: Copied! <pre>result = doc_converter.convert(\n    \"https://www.sagacify.com/news/a-guide-to-chunking-strategies-for-retrieval-augmented-generation-rag\"\n)\ndocuments, metadatas = [], []\nfor chunk in HierarchicalChunker().chunk(result.document):\n    documents.append(chunk.text)\n    metadatas.append(chunk.meta.export_json_dict())\n</pre> result = doc_converter.convert(     \"https://www.sagacify.com/news/a-guide-to-chunking-strategies-for-retrieval-augmented-generation-rag\" ) documents, metadatas = [], [] for chunk in HierarchicalChunker().chunk(result.document):     documents.append(chunk.text)     metadatas.append(chunk.meta.export_json_dict()) <p>Let's now upload the documents to Qdrant.</p> <ul> <li>The <code>add()</code> method batches the documents and uses FastEmbed to generate vector embeddings on our machine.</li> </ul> In\u00a0[4]: Copied! <pre>client.add(COLLECTION_NAME, documents=documents, metadata=metadatas, batch_size=64)\n</pre> client.add(COLLECTION_NAME, documents=documents, metadata=metadatas, batch_size=64) Out[4]: <pre>['e74ae15be5eb4805858307846318e784',\n 'f83f6125b0fa4a0595ae6a0777c9d90d',\n '9cf63c7f30764715bf3804a19db36d7d',\n '007dbe6d355b4b49af3b736cbd63a4d8',\n 'e5e31f21f2e84aa68beca0dfc532cbe9',\n '69c10816af204bb28630a1f957d8dd3e',\n 'b63546b9b1744063bdb076b234d883ca',\n '90ad15ba8fa6494489e1d3221e30bfcf',\n '13517debb483452ea40fc7aa04c08c50',\n '84ccab5cfab74e27a55acef1c63e3fad',\n 'e8aa2ef46d234c5a8a9da64b701d60b4',\n '190bea5ba43c45e792197c50898d1d90',\n 'a730319ea65645ca81e735ace0bcc72e',\n '415e7f6f15864e30b836e23ae8d71b43',\n '5569bce4e65541868c762d149c6f491e',\n '74d9b234e9c04ebeb8e4e1ca625789ac',\n '308b1c5006a94a679f4c8d6f2396993c',\n 'aaa5ec6d385a418388e660c425bf1dbe',\n '630be8e43e4e4472a9cdb9af9462a43a',\n '643b316224de4770a5349bf69cf93471',\n 'da9265e6f6c2485493d15223eefdf411',\n 'a916e447d52c4084b5ce81a0c5a65b07',\n '2883c620858e4e728b88e127155a4f2c',\n '2a998f0e9c124af99027060b94027874',\n 'be551fbd2b9e42f48ebae0cbf1f481bc',\n '95b7f7608e974ca6847097ee4590fba1',\n '309db4f3863b4e3aaf16d5f346c309f3',\n 'c818383267f64fd68b2237b024bd724e',\n '1f16e78338c94238892171b400051cd4',\n '25c680c3e064462cab071ea9bf1bad8c',\n 'f41ab7e480a248c6bb87019341c7ca74',\n 'd440128bed6d4dcb987152b48ecd9a8a',\n 'c110d5dfdc5849808851788c2404dd15']</pre> In\u00a0[5]: Copied! <pre>points = client.query(COLLECTION_NAME, query_text=\"Can I split documents?\", limit=10)\n\nprint(\"&lt;=== Retrieved documents ===&gt;\")\nfor point in points:\n    print(point.document)\n</pre> points = client.query(COLLECTION_NAME, query_text=\"Can I split documents?\", limit=10)  print(\"&lt;=== Retrieved documents ===&gt;\") for point in points:     print(point.document) <pre>&lt;=== Retrieved documents ===&gt;\nDocument Specific Chunking is a strategy that respects the document's structure. Rather than using a set number of characters or a recursive process, it creates chunks that align with the logical sections of the document, like paragraphs or subsections. This approach maintains the original author's organization of content and helps keep the text coherent. It makes the retrieved information more relevant and useful, particularly for structured documents with clearly defined sections.\nDocument Specific Chunking can handle a variety of document formats, such as:\nConsequently, there are also splitters available for this purpose.\n1. We start at the top of the document, treating the first part as a chunk.\n\u00a0\u00a0\u00a02. We continue down the document, deciding if a new sentence or piece of information belongs with the first chunk or should start a new one.\n \u00a0\u00a0\u00a03. We keep this up until we reach the end of the document.\nHave you ever wondered how we, humans, would chunk? Here's a breakdown of a possible way a human would process a new document:\nThe goal of chunking is, as its name says, to chunk the information into multiple smaller pieces in order to store it in a more efficient and meaningful way. This allows the retrieval to capture pieces of information that are more related to the question at hand, and the generation to be more precise, but also less costly, as only a part of a document will be included in the LLM prompt, instead of the whole document.\nTo put these strategies into action, there's a whole array of tools and libraries at your disposal. For example, llama_index is a fantastic tool that lets you create document indices and retrieve chunked documents. Let's not forget LangChain, another remarkable tool that makes implementing chunking strategies a breeze, particularly when dealing with multi-language data. Diving into these tools and understanding how they can work in harmony with the chunking strategies we've discussed is a crucial part of mastering Retrieval Augmented Generation.\nSemantic chunking involves taking the embeddings of every sentence in the document, comparing the similarity of all sentences with each other, and then grouping sentences with the most similar embeddings together.\nYou can see here that with a chunk size of 105, the Markdown structure of the document is taken into account, and the chunks thus preserve the semantics of the text!\nAnd there you have it! These chunking strategies are like a personal toolbox when it comes to implementing Retrieval Augmented Generation. They're a ton of ways to slice and dice text, each with its unique features and quirks. This variety gives you the freedom to pick the strategy that suits your project best, allowing you to tailor your approach to perfectly fit the unique needs of your work.\n</pre>"},{"location":"examples/hybrid_rag_qdrant/#hybrid-rag-with-qdrant","title":"Hybrid RAG with Qdrant\u00b6","text":""},{"location":"examples/hybrid_rag_qdrant/#overview","title":"Overview\u00b6","text":""},{"location":"examples/hybrid_rag_qdrant/#setup","title":"Setup\u00b6","text":""},{"location":"examples/hybrid_rag_qdrant/#query-documents","title":"Query Documents\u00b6","text":""},{"location":"examples/minimal/","title":"Simple conversion","text":"In\u00a0[\u00a0]: Copied! <pre>from docowling.document_converter import DocumentConverter\n</pre> from docowling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>source = \"https://arxiv.org/pdf/2408.09869\"  # document per local path or URL\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())\n# output: ## Docling Technical Report [...]\"\n</pre> source = \"https://arxiv.org/pdf/2408.09869\"  # document per local path or URL converter = DocumentConverter() result = converter.convert(source) print(result.document.export_to_markdown()) # output: ## Docling Technical Report [...]\""},{"location":"examples/rag_haystack/","title":"RAG with Haystack","text":"<p>This example leverages the Haystack Docling extension, along with Milvus-based document store and retriever instances, as well as sentence-transformers embeddings.</p> <p>The presented <code>DoclingConverter</code> component enables you to:</p> <ul> <li>use various document types in your LLM applications with ease and speed, and</li> <li>leverage Docling's rich format for advanced, document-native grounding.</li> </ul> <p><code>DoclingConverter</code> supports two different export modes:</p> <ul> <li><code>ExportType.MARKDOWN</code>: if you want to capture each input document as a separate Haystack document, or</li> <li><code>ExportType.DOC_CHUNKS</code> (default): if you want to have each input document chunked and to then capture each individual chunk as a separate Haystack document downstream.</li> </ul> <p>The example allows to explore both modes via parameter <code>EXPORT_TYPE</code>; depending on the value set, the ingestion and RAG pipelines are then set up accordingly.</p> <ul> <li>\ud83d\udc49 For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use GPU-enabled runtime.</li> <li>Notebook uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var <code>HF_TOKEN</code>.</li> <li>Requirements can be installed as shown below (<code>--no-warn-conflicts</code> meant for Colab's pre-populated Python env; feel free to remove for stricter usage):</li> </ul> In\u00a0[1]: Copied! <pre>%pip install -q --progress-bar off --no-warn-conflicts docling-haystack haystack-ai docling pymilvus milvus-haystack sentence-transformers python-dotenv\n</pre> %pip install -q --progress-bar off --no-warn-conflicts docling-haystack haystack-ai docling pymilvus milvus-haystack sentence-transformers python-dotenv <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>import os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom docling_haystack.converter import ExportType\nfrom dotenv import load_dotenv\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\nload_dotenv()\nHF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\nPATHS = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\nEMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nGENERATION_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\nEXPORT_TYPE = ExportType.DOC_CHUNKS\nQUESTION = \"Which are the main AI models in Docling?\"\nTOP_K = 3\nMILVUS_URI = str(Path(mkdtemp()) / \"docowling.db\")\n</pre> import os from pathlib import Path from tempfile import mkdtemp  from docling_haystack.converter import ExportType from dotenv import load_dotenv  def _get_env_from_colab_or_os(key):     try:         from google.colab import userdata          try:             return userdata.get(key)         except userdata.SecretNotFoundError:             pass     except ImportError:         pass     return os.getenv(key)  load_dotenv() HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\") PATHS = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\" GENERATION_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" EXPORT_TYPE = ExportType.DOC_CHUNKS QUESTION = \"Which are the main AI models in Docling?\" TOP_K = 3 MILVUS_URI = str(Path(mkdtemp()) / \"docowling.db\") In\u00a0[3]: Copied! <pre>from docling_haystack.converter import DoclingConverter\nfrom haystack import Pipeline\nfrom haystack.components.embedders import (\n    SentenceTransformersDocumentEmbedder,\n    SentenceTransformersTextEmbedder,\n)\nfrom haystack.components.preprocessors import DocumentSplitter\nfrom haystack.components.writers import DocumentWriter\nfrom milvus_haystack import MilvusDocumentStore, MilvusEmbeddingRetriever\n\nfrom docowling.chunking import HybridChunker\n\ndocument_store = MilvusDocumentStore(\n    connection_args={\"uri\": MILVUS_URI},\n    drop_old=True,\n    text_field=\"txt\",  # set for preventing conflict with same-name metadata field\n)\n\nidx_pipe = Pipeline()\nidx_pipe.add_component(\n    \"converter\",\n    DoclingConverter(\n        export_type=EXPORT_TYPE,\n        chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n    ),\n)\nidx_pipe.add_component(\n    \"embedder\",\n    SentenceTransformersDocumentEmbedder(model=EMBED_MODEL_ID),\n)\nidx_pipe.add_component(\"writer\", DocumentWriter(document_store=document_store))\nif EXPORT_TYPE == ExportType.DOC_CHUNKS:\n    idx_pipe.connect(\"converter\", \"embedder\")\nelif EXPORT_TYPE == ExportType.MARKDOWN:\n    idx_pipe.add_component(\n        \"splitter\",\n        DocumentSplitter(split_by=\"sentence\", split_length=1),\n    )\n    idx_pipe.connect(\"converter.documents\", \"splitter.documents\")\n    idx_pipe.connect(\"splitter.documents\", \"embedder.documents\")\nelse:\n    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\nidx_pipe.connect(\"embedder\", \"writer\")\nidx_pipe.run({\"converter\": {\"paths\": PATHS}})\n</pre> from docling_haystack.converter import DoclingConverter from haystack import Pipeline from haystack.components.embedders import (     SentenceTransformersDocumentEmbedder,     SentenceTransformersTextEmbedder, ) from haystack.components.preprocessors import DocumentSplitter from haystack.components.writers import DocumentWriter from milvus_haystack import MilvusDocumentStore, MilvusEmbeddingRetriever  from docowling.chunking import HybridChunker  document_store = MilvusDocumentStore(     connection_args={\"uri\": MILVUS_URI},     drop_old=True,     text_field=\"txt\",  # set for preventing conflict with same-name metadata field )  idx_pipe = Pipeline() idx_pipe.add_component(     \"converter\",     DoclingConverter(         export_type=EXPORT_TYPE,         chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),     ), ) idx_pipe.add_component(     \"embedder\",     SentenceTransformersDocumentEmbedder(model=EMBED_MODEL_ID), ) idx_pipe.add_component(\"writer\", DocumentWriter(document_store=document_store)) if EXPORT_TYPE == ExportType.DOC_CHUNKS:     idx_pipe.connect(\"converter\", \"embedder\") elif EXPORT_TYPE == ExportType.MARKDOWN:     idx_pipe.add_component(         \"splitter\",         DocumentSplitter(split_by=\"sentence\", split_length=1),     )     idx_pipe.connect(\"converter.documents\", \"splitter.documents\")     idx_pipe.connect(\"splitter.documents\", \"embedder.documents\") else:     raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\") idx_pipe.connect(\"embedder\", \"writer\") idx_pipe.run({\"converter\": {\"paths\": PATHS}}) <pre>Token indices sequence length is longer than the specified maximum sequence length for this model (1041 &gt; 512). Running this sequence through the model will result in indexing errors\n</pre> <pre>Batches:   0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> Out[3]: <pre>{'writer': {'documents_written': 54}}</pre> In\u00a0[4]: Copied! <pre>from haystack.components.builders import AnswerBuilder\nfrom haystack.components.builders.prompt_builder import PromptBuilder\nfrom haystack.components.generators import HuggingFaceAPIGenerator\nfrom haystack.utils import Secret\n\nprompt_template = \"\"\"\n    Given these documents, answer the question.\n    Documents:\n    {% for doc in documents %}\n        {{ doc.content }}\n    {% endfor %}\n    Question: {{query}}\n    Answer:\n    \"\"\"\n\nrag_pipe = Pipeline()\nrag_pipe.add_component(\n    \"embedder\",\n    SentenceTransformersTextEmbedder(model=EMBED_MODEL_ID),\n)\nrag_pipe.add_component(\n    \"retriever\",\n    MilvusEmbeddingRetriever(document_store=document_store, top_k=TOP_K),\n)\nrag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\nrag_pipe.add_component(\n    \"llm\",\n    HuggingFaceAPIGenerator(\n        api_type=\"serverless_inference_api\",\n        api_params={\"model\": GENERATION_MODEL_ID},\n        token=Secret.from_token(HF_TOKEN) if HF_TOKEN else None,\n    ),\n)\nrag_pipe.add_component(\"answer_builder\", AnswerBuilder())\nrag_pipe.connect(\"embedder.embedding\", \"retriever\")\nrag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\nrag_pipe.connect(\"prompt_builder\", \"llm\")\nrag_pipe.connect(\"llm.replies\", \"answer_builder.replies\")\nrag_pipe.connect(\"llm.meta\", \"answer_builder.meta\")\nrag_pipe.connect(\"retriever\", \"answer_builder.documents\")\nrag_res = rag_pipe.run(\n    {\n        \"embedder\": {\"text\": QUESTION},\n        \"prompt_builder\": {\"query\": QUESTION},\n        \"answer_builder\": {\"query\": QUESTION},\n    }\n)\n</pre> from haystack.components.builders import AnswerBuilder from haystack.components.builders.prompt_builder import PromptBuilder from haystack.components.generators import HuggingFaceAPIGenerator from haystack.utils import Secret  prompt_template = \"\"\"     Given these documents, answer the question.     Documents:     {% for doc in documents %}         {{ doc.content }}     {% endfor %}     Question: {{query}}     Answer:     \"\"\"  rag_pipe = Pipeline() rag_pipe.add_component(     \"embedder\",     SentenceTransformersTextEmbedder(model=EMBED_MODEL_ID), ) rag_pipe.add_component(     \"retriever\",     MilvusEmbeddingRetriever(document_store=document_store, top_k=TOP_K), ) rag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template)) rag_pipe.add_component(     \"llm\",     HuggingFaceAPIGenerator(         api_type=\"serverless_inference_api\",         api_params={\"model\": GENERATION_MODEL_ID},         token=Secret.from_token(HF_TOKEN) if HF_TOKEN else None,     ), ) rag_pipe.add_component(\"answer_builder\", AnswerBuilder()) rag_pipe.connect(\"embedder.embedding\", \"retriever\") rag_pipe.connect(\"retriever\", \"prompt_builder.documents\") rag_pipe.connect(\"prompt_builder\", \"llm\") rag_pipe.connect(\"llm.replies\", \"answer_builder.replies\") rag_pipe.connect(\"llm.meta\", \"answer_builder.meta\") rag_pipe.connect(\"retriever\", \"answer_builder.documents\") rag_res = rag_pipe.run(     {         \"embedder\": {\"text\": QUESTION},         \"prompt_builder\": {\"query\": QUESTION},         \"answer_builder\": {\"query\": QUESTION},     } ) <pre>Batches:   0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> <pre>/Users/pva/work/github.com/DS4SD/docling/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:2232: FutureWarning: `stop_sequences` is a deprecated argument for `text_generation` task and will be removed in version '0.28.0'. Use `stop` instead.\n  warnings.warn(\n</pre> <p>Below we print out the RAG results. If you have used <code>ExportType.DOC_CHUNKS</code>, notice how the sources contain document-level grounding (e.g. page number or bounding box information):</p> In\u00a0[5]: Copied! <pre>from docowling.chunking import DocChunk\n\nprint(f\"Question:\\n{QUESTION}\\n\")\nprint(f\"Answer:\\n{rag_res['answer_builder']['answers'][0].data.strip()}\\n\")\nprint(\"Sources:\")\nsources = rag_res[\"answer_builder\"][\"answers\"][0].documents\nfor source in sources:\n    if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n        doc_chunk = DocChunk.model_validate(source.meta[\"dl_meta\"])\n        print(f\"- text: {repr(doc_chunk.text)}\")\n        if doc_chunk.meta.origin:\n            print(f\"  file: {doc_chunk.meta.origin.filename}\")\n        if doc_chunk.meta.headings:\n            print(f\"  section: {' / '.join(doc_chunk.meta.headings)}\")\n        bbox = doc_chunk.meta.doc_items[0].prov[0].bbox\n        print(\n            f\"  page: {doc_chunk.meta.doc_items[0].prov[0].page_no}, \"\n            f\"bounding box: [{int(bbox.l)}, {int(bbox.t)}, {int(bbox.r)}, {int(bbox.b)}]\"\n        )\n    elif EXPORT_TYPE == ExportType.MARKDOWN:\n        print(repr(source.content))\n    else:\n        raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\n</pre> from docowling.chunking import DocChunk  print(f\"Question:\\n{QUESTION}\\n\") print(f\"Answer:\\n{rag_res['answer_builder']['answers'][0].data.strip()}\\n\") print(\"Sources:\") sources = rag_res[\"answer_builder\"][\"answers\"][0].documents for source in sources:     if EXPORT_TYPE == ExportType.DOC_CHUNKS:         doc_chunk = DocChunk.model_validate(source.meta[\"dl_meta\"])         print(f\"- text: {repr(doc_chunk.text)}\")         if doc_chunk.meta.origin:             print(f\"  file: {doc_chunk.meta.origin.filename}\")         if doc_chunk.meta.headings:             print(f\"  section: {' / '.join(doc_chunk.meta.headings)}\")         bbox = doc_chunk.meta.doc_items[0].prov[0].bbox         print(             f\"  page: {doc_chunk.meta.doc_items[0].prov[0].page_no}, \"             f\"bounding box: [{int(bbox.l)}, {int(bbox.t)}, {int(bbox.r)}, {int(bbox.b)}]\"         )     elif EXPORT_TYPE == ExportType.MARKDOWN:         print(repr(source.content))     else:         raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\") <pre>Question:\nWhich are the main AI models in Docling?\n\nAnswer:\nThe main AI models in Docling are a layout analysis model and TableFormer. The layout analysis model is an accurate object-detector for page elements, while TableFormer is a state-of-the-art table structure recognition model. These models are provided with pre-trained weights and a separate package for the inference code as docling-ibm-models. They are also used in the open-access deepsearch-experience, a cloud-native service for knowledge exploration tasks. Additionally, Docling plans to extend its model library with a figure-classifier model, an equation-recognition model, a code-recognition model, and more in the future.\n\nSources:\n- text: 'As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.'\n  file: 2408.09869v5.pdf\n  section: 3.2 AI models\n  page: 3, bounding box: [107, 406, 504, 330]\n- text: 'Docling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.'\n  file: 2408.09869v5.pdf\n  section: 3 Processing pipeline\n  page: 2, bounding box: [107, 273, 504, 176]\n- text: 'Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Further investment into testing and optimizing GPU acceleration as well as improving the Docling-native PDF backend are on our roadmap, too.\\nWe encourage everyone to propose or implement additional features and models, and will gladly take your inputs and contributions under review . The codebase of Docling is open for use and contribution, under the MIT license agreement and in alignment with our contributing guidelines included in the Docling repository. If you use Docling in your projects, please consider citing this technical report.'\n  section: 6 Future work and contributions\n  page: 5, bounding box: [106, 323, 504, 258]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/rag_haystack/#rag-with-haystack","title":"RAG with Haystack\u00b6","text":""},{"location":"examples/rag_haystack/#overview","title":"Overview\u00b6","text":""},{"location":"examples/rag_haystack/#setup","title":"Setup\u00b6","text":""},{"location":"examples/rag_haystack/#indexing-pipeline","title":"Indexing pipeline\u00b6","text":""},{"location":"examples/rag_haystack/#rag-pipeline","title":"RAG pipeline\u00b6","text":""},{"location":"examples/rag_langchain/","title":"RAG with LangChain \ud83e\udd9c\ud83d\udd17","text":"In\u00a0[1]: Copied! <pre># requirements for this example:\n%pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus\n</pre> # requirements for this example: %pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>import os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n</pre> import os  from dotenv import load_dotenv  load_dotenv() Out[2]: <pre>True</pre> <p>Below we set up:</p> <ul> <li>a <code>Loader</code> which will be used to create LangChain documents, and</li> <li>a splitter, which will be used to split these documents</li> </ul> In\u00a0[3]: Copied! <pre>from typing import Iterator\n\nfrom langchain_core.document_loaders import BaseLoader\nfrom langchain_core.documents import Document as LCDocument\n\nfrom docowling.document_converter import DocumentConverter\n\nclass DoclingPDFLoader(BaseLoader):\n\n    def __init__(self, file_path: str | list[str]) -&gt; None:\n        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n        self._converter = DocumentConverter()\n\n    def lazy_load(self) -&gt; Iterator[LCDocument]:\n        for source in self._file_paths:\n            dl_doc = self._converter.convert(source).document\n            text = dl_doc.export_to_markdown()\n            yield LCDocument(page_content=text)\n</pre> from typing import Iterator  from langchain_core.document_loaders import BaseLoader from langchain_core.documents import Document as LCDocument  from docowling.document_converter import DocumentConverter  class DoclingPDFLoader(BaseLoader):      def __init__(self, file_path: str | list[str]) -&gt; None:         self._file_paths = file_path if isinstance(file_path, list) else [file_path]         self._converter = DocumentConverter()      def lazy_load(self) -&gt; Iterator[LCDocument]:         for source in self._file_paths:             dl_doc = self._converter.convert(source).document             text = dl_doc.export_to_markdown()             yield LCDocument(page_content=text) In\u00a0[4]: Copied! <pre>FILE_PATH = \"https://raw.githubusercontent.com/DS4SD/docling/main/tests/data/2206.01062.pdf\"  # DocLayNet paper\n</pre> FILE_PATH = \"https://raw.githubusercontent.com/DS4SD/docling/main/tests/data/2206.01062.pdf\"  # DocLayNet paper In\u00a0[5]: Copied! <pre>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\nloader = DoclingPDFLoader(file_path=FILE_PATH)\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n)\n</pre> from langchain_text_splitters import RecursiveCharacterTextSplitter  loader = DoclingPDFLoader(file_path=FILE_PATH) text_splitter = RecursiveCharacterTextSplitter(     chunk_size=1000,     chunk_overlap=200, ) <p>We now used the above-defined objects to get the document splits:</p> In\u00a0[6]: Copied! <pre>docs = loader.load()\nsplits = text_splitter.split_documents(docs)\n</pre> docs = loader.load() splits = text_splitter.split_documents(docs) In\u00a0[7]: Copied! <pre>from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n\nHF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\nembeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)\n</pre> from langchain_huggingface.embeddings import HuggingFaceEmbeddings  HF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\" embeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID) In\u00a0[8]: Copied! <pre>from tempfile import TemporaryDirectory\n\nfrom langchain_milvus import Milvus\n\nMILVUS_URI = os.environ.get(\n    \"MILVUS_URI\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\"\n)\n\nvectorstore = Milvus.from_documents(\n    splits,\n    embeddings,\n    connection_args={\"uri\": MILVUS_URI},\n    drop_old=True,\n)\n</pre> from tempfile import TemporaryDirectory  from langchain_milvus import Milvus  MILVUS_URI = os.environ.get(     \"MILVUS_URI\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\" )  vectorstore = Milvus.from_documents(     splits,     embeddings,     connection_args={\"uri\": MILVUS_URI},     drop_old=True, ) In\u00a0[9]: Copied! <pre>from langchain_huggingface import HuggingFaceEndpoint\n\nHF_API_KEY = os.environ.get(\"HF_API_KEY\")\nHF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\nllm = HuggingFaceEndpoint(\n    repo_id=HF_LLM_MODEL_ID,\n    huggingfacehub_api_token=HF_API_KEY,\n)\n</pre> from langchain_huggingface import HuggingFaceEndpoint  HF_API_KEY = os.environ.get(\"HF_API_KEY\") HF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"  llm = HuggingFaceEndpoint(     repo_id=HF_LLM_MODEL_ID,     huggingfacehub_api_token=HF_API_KEY, ) <pre>The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /Users/pva/.cache/huggingface/token\nLogin successful\n</pre> In\u00a0[10]: Copied! <pre>from typing import Iterable\n\nfrom langchain_core.documents import Document as LCDocument\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n\ndef format_docs(docs: Iterable[LCDocument]):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nretriever = vectorstore.as_retriever()\n\nprompt = PromptTemplate.from_template(\n    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\"\n)\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n</pre> from typing import Iterable  from langchain_core.documents import Document as LCDocument from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnablePassthrough   def format_docs(docs: Iterable[LCDocument]):     return \"\\n\\n\".join(doc.page_content for doc in docs)   retriever = vectorstore.as_retriever()  prompt = PromptTemplate.from_template(     \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\" )  rag_chain = (     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}     | prompt     | llm     | StrOutputParser() ) In\u00a0[11]: Copied! <pre>rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\")\n</pre> rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\") Out[11]: <pre>'- 80,863 pages were human annotated for DocLayNet.'</pre>"},{"location":"examples/rag_langchain/#rag-with-langchain","title":"RAG with LangChain \ud83e\udd9c\ud83d\udd17\u00b6","text":""},{"location":"examples/rag_langchain/#setup","title":"Setup\u00b6","text":""},{"location":"examples/rag_langchain/#loader-and-splitter","title":"Loader and splitter\u00b6","text":""},{"location":"examples/rag_langchain/#embeddings","title":"Embeddings\u00b6","text":""},{"location":"examples/rag_langchain/#vector-store","title":"Vector store\u00b6","text":""},{"location":"examples/rag_langchain/#llm","title":"LLM\u00b6","text":""},{"location":"examples/rag_langchain/#rag","title":"RAG\u00b6","text":""},{"location":"examples/rag_llamaindex/","title":"RAG with LlamaIndex \ud83e\udd99","text":"<p>This example leverages the official LlamaIndex Docling extension.</p> <p>Presented extensions <code>DoclingReader</code> and <code>DoclingNodeParser</code> enable you to:</p> <ul> <li>use various document types in your LLM applications with ease and speed, and</li> <li>leverage Docling's rich format for advanced, document-native grounding.</li> </ul> <ul> <li>\ud83d\udc49 For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use GPU-enabled runtime.</li> <li>Notebook uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var <code>HF_TOKEN</code>.</li> <li>Requirements can be installed as shown below (<code>--no-warn-conflicts</code> meant for Colab's pre-populated Python env; feel free to remove for stricter usage):</li> </ul> In\u00a0[1]: Copied! <pre>%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv\n</pre> %pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>import os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\nfrom warnings import filterwarnings\n\nfrom dotenv import load_dotenv\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\n\nfilterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\")\nfilterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\")\n# https://github.com/huggingface/transformers/issues/5486:\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n</pre> import os from pathlib import Path from tempfile import mkdtemp from warnings import filterwarnings  from dotenv import load_dotenv   def _get_env_from_colab_or_os(key):     try:         from google.colab import userdata          try:             return userdata.get(key)         except userdata.SecretNotFoundError:             pass     except ImportError:         pass     return os.getenv(key)   load_dotenv()  filterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\") filterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\") # https://github.com/huggingface/transformers/issues/5486: os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" <p>We can now define the main parameters:</p> In\u00a0[3]: Copied! <pre>from llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n\nEMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\nMILVUS_URI = str(Path(mkdtemp()) / \"docowling.db\")\nGEN_MODEL = HuggingFaceInferenceAPI(\n    token=_get_env_from_colab_or_os(\"HF_TOKEN\"),\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\nSOURCE = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report\nQUERY = \"Which are the main AI models in Docling?\"\n\nembed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))\n</pre> from llama_index.embeddings.huggingface import HuggingFaceEmbedding from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI  EMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") MILVUS_URI = str(Path(mkdtemp()) / \"docowling.db\") GEN_MODEL = HuggingFaceInferenceAPI(     token=_get_env_from_colab_or_os(\"HF_TOKEN\"),     model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", ) SOURCE = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report QUERY = \"Which are the main AI models in Docling?\"  embed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\")) <p>To create a simple RAG pipeline, we can:</p> <ul> <li>define a <code>DoclingReader</code>, which by default exports to Markdown, and</li> <li>use a standard node parser for these Markdown-based docs, e.g. a <code>MarkdownNodeParser</code></li> </ul> In\u00a0[4]: Copied! <pre>from llama_index.core import StorageContext, VectorStoreIndex\nfrom llama_index.core.node_parser import MarkdownNodeParser\nfrom llama_index.readers.docling import DoclingReader\nfrom llama_index.vector_stores.milvus import MilvusVectorStore\n\nreader = DoclingReader()\nnode_parser = MarkdownNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.core import StorageContext, VectorStoreIndex from llama_index.core.node_parser import MarkdownNodeParser from llama_index.readers.docling import DoclingReader from llama_index.vector_stores.milvus import MilvusVectorStore  reader = DoclingReader() node_parser = MarkdownNodeParser()  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Q: Which are the main AI models in Docling?\nA: The main AI models in Docling are a layout analysis model, which is an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('3.2 AI models\\n\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'Header_2': '3.2 AI models'}),\n (\"5 Applications\\n\\nThanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling's feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.\",\n  {'Header_2': '5 Applications'})]</pre> <p>To leverage Docling's rich native format, we:</p> <ul> <li>create a <code>DoclingReader</code> with JSON export type, and</li> <li>employ a <code>DoclingNodeParser</code> in order to appropriately parse that Docling format.</li> </ul> <p>Notice how the sources now also contain document-level grounding (e.g. page number or bounding box information):</p> In\u00a0[5]: Copied! <pre>from llama_index.node_parser.docling import DoclingNodeParser\n\nreader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\nnode_parser = DoclingNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.node_parser.docling import DoclingNodeParser  reader = DoclingReader(export_type=DoclingReader.ExportType.JSON) node_parser = DoclingNodeParser()  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Q: Which are the main AI models in Docling?\nA: The main AI models in Docling are a layout analysis model and TableFormer. The layout analysis model is an accurate object-detector for page elements, and TableFormer is a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n   'version': '1.0.0',\n   'doc_items': [{'self_ref': '#/texts/34',\n     'parent': {'$ref': '#/body'},\n     'children': [],\n     'label': 'text',\n     'prov': [{'page_no': 3,\n       'bbox': {'l': 107.07593536376953,\n        't': 406.1695251464844,\n        'r': 504.1148681640625,\n        'b': 330.2677307128906,\n        'coord_origin': 'BOTTOMLEFT'},\n       'charspan': [0, 608]}]}],\n   'headings': ['3.2 AI models'],\n   'origin': {'mimetype': 'application/pdf',\n    'binary_hash': 14981478401387673002,\n    'filename': '2408.09869v3.pdf'}}),\n ('With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.',\n  {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n   'version': '1.0.0',\n   'doc_items': [{'self_ref': '#/texts/9',\n     'parent': {'$ref': '#/body'},\n     'children': [],\n     'label': 'text',\n     'prov': [{'page_no': 1,\n       'bbox': {'l': 107.0031967163086,\n        't': 136.7283935546875,\n        'r': 504.04998779296875,\n        'b': 83.30133056640625,\n        'coord_origin': 'BOTTOMLEFT'},\n       'charspan': [0, 488]}]}],\n   'headings': ['1 Introduction'],\n   'origin': {'mimetype': 'application/pdf',\n    'binary_hash': 14981478401387673002,\n    'filename': '2408.09869v3.pdf'}})]</pre> <p>To demonstrate this usage pattern, we first set up a test document directory.</p> In\u00a0[6]: Copied! <pre>from pathlib import Path\nfrom tempfile import mkdtemp\n\nimport requests\n\ntmp_dir_path = Path(mkdtemp())\nr = requests.get(SOURCE)\nwith open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:\n    out_file.write(r.content)\n</pre> from pathlib import Path from tempfile import mkdtemp  import requests  tmp_dir_path = Path(mkdtemp()) r = requests.get(SOURCE) with open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:     out_file.write(r.content) <p>Using the <code>reader</code> and <code>node_parser</code> definitions from any of the above variants, usage with <code>SimpleDirectoryReader</code> then looks as follows:</p> In\u00a0[7]: Copied! <pre>from llama_index.core import SimpleDirectoryReader\n\ndir_reader = SimpleDirectoryReader(\n    input_dir=tmp_dir_path,\n    file_extractor={\".pdf\": reader},\n)\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=dir_reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.core import SimpleDirectoryReader  dir_reader = SimpleDirectoryReader(     input_dir=tmp_dir_path,     file_extractor={\".pdf\": reader}, )  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docowling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=dir_reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Loading files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:11&lt;00:00, 11.27s/file]\n</pre> <pre>Q: Which are the main AI models in Docling?\nA: 1. A layout analysis model, an accurate object-detector for page elements. 2. TableFormer, a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'file_path': '/var/folders/76/4wwfs06x6835kcwj4186c0nc0000gn/T/tmp2ooyusg5/2408.09869.pdf',\n   'file_name': '2408.09869.pdf',\n   'file_type': 'application/pdf',\n   'file_size': 5566574,\n   'creation_date': '2024-10-28',\n   'last_modified_date': '2024-10-28',\n   'schema_name': 'docling_core.transforms.chunker.DocMeta',\n   'version': '1.0.0',\n   'doc_items': [{'self_ref': '#/texts/34',\n     'parent': {'$ref': '#/body'},\n     'children': [],\n     'label': 'text',\n     'prov': [{'page_no': 3,\n       'bbox': {'l': 107.07593536376953,\n        't': 406.1695251464844,\n        'r': 504.1148681640625,\n        'b': 330.2677307128906,\n        'coord_origin': 'BOTTOMLEFT'},\n       'charspan': [0, 608]}]}],\n   'headings': ['3.2 AI models'],\n   'origin': {'mimetype': 'application/pdf',\n    'binary_hash': 14981478401387673002,\n    'filename': '2408.09869.pdf'}}),\n ('With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.',\n  {'file_path': '/var/folders/76/4wwfs06x6835kcwj4186c0nc0000gn/T/tmp2ooyusg5/2408.09869.pdf',\n   'file_name': '2408.09869.pdf',\n   'file_type': 'application/pdf',\n   'file_size': 5566574,\n   'creation_date': '2024-10-28',\n   'last_modified_date': '2024-10-28',\n   'schema_name': 'docling_core.transforms.chunker.DocMeta',\n   'version': '1.0.0',\n   'doc_items': [{'self_ref': '#/texts/9',\n     'parent': {'$ref': '#/body'},\n     'children': [],\n     'label': 'text',\n     'prov': [{'page_no': 1,\n       'bbox': {'l': 107.0031967163086,\n        't': 136.7283935546875,\n        'r': 504.04998779296875,\n        'b': 83.30133056640625,\n        'coord_origin': 'BOTTOMLEFT'},\n       'charspan': [0, 488]}]}],\n   'headings': ['1 Introduction'],\n   'origin': {'mimetype': 'application/pdf',\n    'binary_hash': 14981478401387673002,\n    'filename': '2408.09869.pdf'}})]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/rag_llamaindex/#rag-with-llamaindex","title":"RAG with LlamaIndex \ud83e\udd99\u00b6","text":""},{"location":"examples/rag_llamaindex/#overview","title":"Overview\u00b6","text":""},{"location":"examples/rag_llamaindex/#setup","title":"Setup\u00b6","text":""},{"location":"examples/rag_llamaindex/#using-markdown-export","title":"Using Markdown export\u00b6","text":""},{"location":"examples/rag_llamaindex/#using-docling-format","title":"Using Docling format\u00b6","text":""},{"location":"examples/rag_llamaindex/#with-simple-directory-reader","title":"With Simple Directory Reader\u00b6","text":""},{"location":"examples/rag_weaviate/","title":"Performing RAG over PDFs with Weaviate and Docling","text":"In\u00a0[1]: Copied! <pre>%%capture\n%pip install docling~=\"2.7.0\"\n%pip install -U weaviate-client~=\"4.9.4\"\n%pip install rich\n%pip install torch\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\n\n# Suppress Weaviate client logs\nlogging.getLogger(\"weaviate\").setLevel(logging.ERROR)\n</pre> %%capture %pip install docling~=\"2.7.0\" %pip install -U weaviate-client~=\"4.9.4\" %pip install rich %pip install torch  import warnings  warnings.filterwarnings(\"ignore\")  import logging  # Suppress Weaviate client logs logging.getLogger(\"weaviate\").setLevel(logging.ERROR) In\u00a0[2]: Copied! <pre>import torch\n\n# Check if GPU or MPS is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\")\nelif torch.backends.mps.is_available():\n    device = torch.device(\"mps\")\n    print(\"MPS GPU is enabled.\")\nelse:\n    raise EnvironmentError(\n        \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"\n    )\n</pre> import torch  # Check if GPU or MPS is available if torch.cuda.is_available():     device = torch.device(\"cuda\")     print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\") elif torch.backends.mps.is_available():     device = torch.device(\"mps\")     print(\"MPS GPU is enabled.\") else:     raise EnvironmentError(         \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"     ) <pre>MPS GPU is enabled.\n</pre> <p>Here, we've collected 10 influential machine learning papers published as PDFs on arXiv. Because Docling does not yet have title extraction for PDFs, we manually add the titles in a corresponding list.</p> <p>Note: Converting all 10 papers should take around 8 minutes with a T4 GPU.</p> In\u00a0[3]: Copied! <pre># Influential machine learning papers\nsource_urls = [\n    \"https://arxiv.org/pdf/1706.03762\",\n    \"https://arxiv.org/pdf/1810.04805\",\n    \"https://arxiv.org/pdf/1406.2661\",\n    \"https://arxiv.org/pdf/1409.0473\",\n    \"https://arxiv.org/pdf/1412.6980\",\n    \"https://arxiv.org/pdf/1312.6114\",\n    \"https://arxiv.org/pdf/1312.5602\",\n    \"https://arxiv.org/pdf/1512.03385\",\n    \"https://arxiv.org/pdf/1409.3215\",\n    \"https://arxiv.org/pdf/1301.3781\",\n]\n\n# And their corresponding titles (because Docling doesn't have title extraction yet!)\nsource_titles = [\n    \"Attention Is All You Need\",\n    \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n    \"Generative Adversarial Nets\",\n    \"Neural Machine Translation by Jointly Learning to Align and Translate\",\n    \"Adam: A Method for Stochastic Optimization\",\n    \"Auto-Encoding Variational Bayes\",\n    \"Playing Atari with Deep Reinforcement Learning\",\n    \"Deep Residual Learning for Image Recognition\",\n    \"Sequence to Sequence Learning with Neural Networks\",\n    \"A Neural Probabilistic Language Model\",\n]\n</pre> # Influential machine learning papers source_urls = [     \"https://arxiv.org/pdf/1706.03762\",     \"https://arxiv.org/pdf/1810.04805\",     \"https://arxiv.org/pdf/1406.2661\",     \"https://arxiv.org/pdf/1409.0473\",     \"https://arxiv.org/pdf/1412.6980\",     \"https://arxiv.org/pdf/1312.6114\",     \"https://arxiv.org/pdf/1312.5602\",     \"https://arxiv.org/pdf/1512.03385\",     \"https://arxiv.org/pdf/1409.3215\",     \"https://arxiv.org/pdf/1301.3781\", ]  # And their corresponding titles (because Docling doesn't have title extraction yet!) source_titles = [     \"Attention Is All You Need\",     \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",     \"Generative Adversarial Nets\",     \"Neural Machine Translation by Jointly Learning to Align and Translate\",     \"Adam: A Method for Stochastic Optimization\",     \"Auto-Encoding Variational Bayes\",     \"Playing Atari with Deep Reinforcement Learning\",     \"Deep Residual Learning for Image Recognition\",     \"Sequence to Sequence Learning with Neural Networks\",     \"A Neural Probabilistic Language Model\", ] In\u00a0[4]: Copied! <pre>from docowling.datamodel.document import ConversionResult\nfrom docowling.document_converter import DocumentConverter\n\n# Instantiate the doc converter\ndoc_converter = DocumentConverter()\n\n# Directly pass list of files or streams to `convert_all`\nconv_results_iter = doc_converter.convert_all(source_urls)  # previously `convert`\n\n# Iterate over the generator to get a list of Docling documents\ndocs = [result.document for result in conv_results_iter]\n</pre> from docowling.datamodel.document import ConversionResult from docowling.document_converter import DocumentConverter  # Instantiate the doc converter doc_converter = DocumentConverter()  # Directly pass list of files or streams to `convert_all` conv_results_iter = doc_converter.convert_all(source_urls)  # previously `convert`  # Iterate over the generator to get a list of Docling documents docs = [result.document for result in conv_results_iter] <pre>Fetching 9 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 84072.91it/s]\n</pre> <pre>ERR#: COULD NOT CONVERT TO RS THIS TABLE TO COMPUTE SPANS\n</pre> In\u00a0[5]: Copied! <pre>from docling_core.transforms.chunker import HierarchicalChunker\n\n# Initialize lists for text, and titles\ntexts, titles = [], []\n\nchunker = HierarchicalChunker()\n\n# Process each document in the list\nfor doc, title in zip(docs, source_titles):  # Pair each document with its title\n    chunks = list(\n        chunker.chunk(doc)\n    )  # Perform hierarchical chunking and get text from chunks\n    for chunk in chunks:\n        texts.append(chunk.text)\n        titles.append(title)\n</pre> from docling_core.transforms.chunker import HierarchicalChunker  # Initialize lists for text, and titles texts, titles = [], []  chunker = HierarchicalChunker()  # Process each document in the list for doc, title in zip(docs, source_titles):  # Pair each document with its title     chunks = list(         chunker.chunk(doc)     )  # Perform hierarchical chunking and get text from chunks     for chunk in chunks:         texts.append(chunk.text)         titles.append(title) <p>Because we're splitting the documents into chunks, we'll concatenate the article title to the beginning of each chunk for additional context.</p> In\u00a0[6]: Copied! <pre># Concatenate title and text\nfor i in range(len(texts)):\n    texts[i] = f\"{titles[i]} {texts[i]}\"\n</pre> # Concatenate title and text for i in range(len(texts)):     texts[i] = f\"{titles[i]} {texts[i]}\" <p>We'll be using the OpenAI API for both generating the text embeddings and for the generative model in our RAG pipeline. The code below dynamically fetches your API key based on whether you're running this notebook in Google Colab and running it as a regular Jupyter notebook. All you need to do is replace <code>openai_api_key_var</code> with the name of your environmental variable name or Colab secret name for the API key.</p> <p>If you're running this notebook in Google Colab, make sure you add your API key as a secret.</p> In\u00a0[7]: Copied! <pre># OpenAI API key variable name\nopenai_api_key_var = \"OPENAI_API_KEY\"  # Replace with the name of your secret/env var\n\n# Fetch OpenAI API key\ntry:\n    # If running in Colab, fetch API key from Secrets\n    import google.colab\n    from google.colab import userdata\n\n    openai_api_key = userdata.get(openai_api_key_var)\n    if not openai_api_key:\n        raise ValueError(f\"Secret '{openai_api_key_var}' not found in Colab secrets.\")\nexcept ImportError:\n    # If not running in Colab, fetch API key from environment variable\n    import os\n\n    openai_api_key = os.getenv(openai_api_key_var)\n    if not openai_api_key:\n        raise EnvironmentError(\n            f\"Environment variable '{openai_api_key_var}' is not set. \"\n            \"Please define it before running this script.\"\n        )\n</pre> # OpenAI API key variable name openai_api_key_var = \"OPENAI_API_KEY\"  # Replace with the name of your secret/env var  # Fetch OpenAI API key try:     # If running in Colab, fetch API key from Secrets     import google.colab     from google.colab import userdata      openai_api_key = userdata.get(openai_api_key_var)     if not openai_api_key:         raise ValueError(f\"Secret '{openai_api_key_var}' not found in Colab secrets.\") except ImportError:     # If not running in Colab, fetch API key from environment variable     import os      openai_api_key = os.getenv(openai_api_key_var)     if not openai_api_key:         raise EnvironmentError(             f\"Environment variable '{openai_api_key_var}' is not set. \"             \"Please define it before running this script.\"         ) <p>Embedded Weaviate allows you to spin up a Weaviate instance directly from your application code, without having to use a Docker container. If you're interested in other deployment methods, like using Docker-Compose or Kubernetes, check out this page in the Weaviate docs.</p> In\u00a0[\u00a0]: Copied! <pre>import weaviate\n\n# Connect to Weaviate embedded\nclient = weaviate.connect_to_embedded(headers={\"X-OpenAI-Api-Key\": openai_api_key})\n</pre> import weaviate  # Connect to Weaviate embedded client = weaviate.connect_to_embedded(headers={\"X-OpenAI-Api-Key\": openai_api_key}) In\u00a0[\u00a0]: Copied! <pre>import weaviate.classes.config as wc\nfrom weaviate.classes.config import DataType, Property\n\n# Define the collection name\ncollection_name = \"docling\"\n\n# Delete the collection if it already exists\nif client.collections.exists(collection_name):\n    client.collections.delete(collection_name)\n\n# Create the collection\ncollection = client.collections.create(\n    name=collection_name,\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-large\",  # Specify your embedding model here\n    ),\n    # Enable generative model from Cohere\n    generative_config=wc.Configure.Generative.openai(\n        model=\"gpt-4o\"  # Specify your generative model for RAG here\n    ),\n    # Define properties of metadata\n    properties=[\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n    ],\n)\n</pre> import weaviate.classes.config as wc from weaviate.classes.config import DataType, Property  # Define the collection name collection_name = \"docling\"  # Delete the collection if it already exists if client.collections.exists(collection_name):     client.collections.delete(collection_name)  # Create the collection collection = client.collections.create(     name=collection_name,     vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(         model=\"text-embedding-3-large\",  # Specify your embedding model here     ),     # Enable generative model from Cohere     generative_config=wc.Configure.Generative.openai(         model=\"gpt-4o\"  # Specify your generative model for RAG here     ),     # Define properties of metadata     properties=[         wc.Property(name=\"text\", data_type=wc.DataType.TEXT),         wc.Property(name=\"title\", data_type=wc.DataType.TEXT, skip_vectorization=True),     ], ) In\u00a0[10]: Copied! <pre># Initialize the data object\ndata = []\n\n# Create a dictionary for each row by iterating through the corresponding lists\nfor text, title in zip(texts, titles):\n    data_point = {\n        \"text\": text,\n        \"title\": title,\n    }\n    data.append(data_point)\n</pre> # Initialize the data object data = []  # Create a dictionary for each row by iterating through the corresponding lists for text, title in zip(texts, titles):     data_point = {         \"text\": text,         \"title\": title,     }     data.append(data_point) In\u00a0[\u00a0]: Copied! <pre># Insert text chunks and metadata into vector DB collection\nresponse = collection.data.insert_many(data)\n\nif response.has_errors:\n    print(response.errors)\nelse:\n    print(\"Insert complete.\")\n</pre> # Insert text chunks and metadata into vector DB collection response = collection.data.insert_many(data)  if response.has_errors:     print(response.errors) else:     print(\"Insert complete.\") In\u00a0[12]: Copied! <pre>from weaviate.classes.query import MetadataQuery\n\nresponse = collection.query.near_text(\n    query=\"bert\",\n    limit=2,\n    return_metadata=MetadataQuery(distance=True),\n    return_properties=[\"text\", \"title\"],\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n</pre> from weaviate.classes.query import MetadataQuery  response = collection.query.near_text(     query=\"bert\",     limit=2,     return_metadata=MetadataQuery(distance=True),     return_properties=[\"text\", \"title\"], )  for o in response.objects:     print(o.properties)     print(o.metadata.distance) <pre>{'text': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding A distinctive feature of BERT is its unified architecture across different tasks. There is mini-', 'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'}\n0.6578550338745117\n{'text': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding We introduce a new language representation model called BERT , which stands for B idirectional E ncoder R epresentations from T ransformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications.', 'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'}\n0.6696287989616394\n</pre> In\u00a0[13]: Copied! <pre>from rich.console import Console\nfrom rich.panel import Panel\n\n# Create a prompt where context from the Weaviate collection will be injected\nprompt = \"Explain how {text} works, using only the retrieved context.\"\nquery = \"bert\"\n\nresponse = collection.generate.near_text(\n    query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"]\n)\n\n# Prettify the output using Rich\nconsole = Console()\n\nconsole.print(\n    Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\")\n)\nconsole.print(\n    Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\")\n)\n</pre> from rich.console import Console from rich.panel import Panel  # Create a prompt where context from the Weaviate collection will be injected prompt = \"Explain how {text} works, using only the retrieved context.\" query = \"bert\"  response = collection.generate.near_text(     query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"] )  # Prettify the output using Rich console = Console()  console.print(     Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\") ) console.print(     Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\") ) <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Prompt \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Explain how bert works, using only the retrieved context.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Generated Content \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 BERT, which stands for Bidirectional Encoder Representations from Transformers, is a language representation    \u2502\n\u2502 model designed to pretrain deep bidirectional representations from unlabeled text. It conditions on both left   \u2502\n\u2502 and right context in all layers, unlike traditional left-to-right or right-to-left language models. This        \u2502\n\u2502 pre-training involves two unsupervised tasks. The pre-trained BERT model can then be fine-tuned with just one   \u2502\n\u2502 additional output layer to create state-of-the-art models for various tasks, such as question answering and     \u2502\n\u2502 language inference, without needing substantial task-specific architecture modifications. A distinctive feature \u2502\n\u2502 of BERT is its unified architecture across different tasks.                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[14]: Copied! <pre># Create a prompt where context from the Weaviate collection will be injected\nprompt = \"Explain how {text} works, using only the retrieved context.\"\nquery = \"a generative adversarial net\"\n\nresponse = collection.generate.near_text(\n    query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"]\n)\n\n# Prettify the output using Rich\nconsole = Console()\n\nconsole.print(\n    Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\")\n)\nconsole.print(\n    Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\")\n)\n</pre> # Create a prompt where context from the Weaviate collection will be injected prompt = \"Explain how {text} works, using only the retrieved context.\" query = \"a generative adversarial net\"  response = collection.generate.near_text(     query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"] )  # Prettify the output using Rich console = Console()  console.print(     Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\") ) console.print(     Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\") ) <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Prompt \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Explain how a generative adversarial net works, using only the retrieved context.                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Generated Content \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Generative Adversarial Nets (GANs) operate within an adversarial framework where two models are trained         \u2502\n\u2502 simultaneously: a generative model (G) and a discriminative model (D). The generative model aims to capture the \u2502\n\u2502 data distribution and generate samples that mimic real data, while the discriminative model's task is to        \u2502\n\u2502 distinguish between samples from the real data and those generated by G. This setup is akin to a game where the \u2502\n\u2502 generative model acts like counterfeiters trying to produce indistinguishable fake currency, and the            \u2502\n\u2502 discriminative model acts like the police trying to detect these counterfeits.                                  \u2502\n\u2502                                                                                                                 \u2502\n\u2502 The training process involves a minimax two-player game where G tries to maximize the probability of D making a \u2502\n\u2502 mistake, while D tries to minimize it. When both models are defined by multilayer perceptrons, they can be      \u2502\n\u2502 trained using backpropagation without the need for Markov chains or approximate inference networks. The         \u2502\n\u2502 ultimate goal is for G to perfectly replicate the training data distribution, making D's output equal to 1/2    \u2502\n\u2502 everywhere, indicating it cannot distinguish between real and generated data. This framework allows for         \u2502\n\u2502 specific training algorithms and optimization techniques, such as backpropagation and dropout, to be            \u2502\n\u2502 effectively utilized.                                                                                           \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <p>We can see that our RAG pipeline performs relatively well for simple queries, especially given the small size of the dataset. Scaling this method for converting a larger sample of PDFs would require more compute (GPUs) and a more advanced deployment of Weaviate (like Docker, Kubernetes, or Weaviate Cloud). For more information on available Weaviate configurations, check out the documetation.</p>"},{"location":"examples/rag_weaviate/#performing-rag-over-pdfs-with-weaviate-and-docling","title":"Performing RAG over PDFs with Weaviate and Docling\u00b6","text":""},{"location":"examples/rag_weaviate/#a-recipe","title":"A recipe \ud83e\uddd1\u200d\ud83c\udf73 \ud83d\udc25 \ud83d\udc9a\u00b6","text":"<p>This is a code recipe that uses Weaviate to perform RAG over PDF documents parsed by Docling.</p> <p>In this notebook, we accomplish the following:</p> <ul> <li>Parse the top machine learning papers on arXiv using Docling</li> <li>Perform hierarchical chunking of the documents using Docling</li> <li>Generate text embeddings with OpenAI</li> <li>Perform RAG using Weaviate</li> </ul> <p>To run this notebook, you'll need:</p> <ul> <li>An OpenAI API key</li> <li>Access to GPU/s</li> </ul> <p>Note: For best results, please use GPU acceleration to run this notebook. Here are two options for running this notebook:</p> <ol> <li>Locally on a MacBook with an Apple Silicon chip. Converting all documents in the notebook takes ~2 minutes on a MacBook M2 due to Docling's usage of MPS accelerators.</li> <li>Run this notebook on Google Colab. Converting all documents in the notebook takes ~8 mintutes on a Google Colab T4 GPU.</li> </ol>"},{"location":"examples/rag_weaviate/#install-docling-and-weaviate-client","title":"Install Docling and Weaviate client\u00b6","text":"<p>Note: If Colab prompts you to restart the session after running the cell below, click \"restart\" and proceed with running the rest of the notebook.</p>"},{"location":"examples/rag_weaviate/#part-1-docling","title":"\ud83d\udc25 Part 1: Docling\u00b6","text":"<p>Part of what makes Docling so remarkable is the fact that it can run on commodity hardware. This means that this notebook can be run on a local machine with GPU acceleration. If you're using a MacBook with a silicon chip, Docling integrates seamlessly with Metal Performance Shaders (MPS). MPS provides out-of-the-box GPU acceleration for macOS, seamlessly integrating with PyTorch and TensorFlow, offering energy-efficient performance on Apple Silicon, and broad compatibility with all Metal-supported GPUs.</p> <p>The code below checks to see if a GPU is available, either via CUDA or MPS.</p>"},{"location":"examples/rag_weaviate/#convert-pdfs-to-docling-documents","title":"Convert PDFs to Docling documents\u00b6","text":"<p>Here we use Docling's <code>.convert_all()</code> to parse a batch of PDFs. The result is a list of Docling documents that we can use for text extraction.</p> <p>Note: Please ignore the <code>ERR#</code> message.</p>"},{"location":"examples/rag_weaviate/#post-process-extracted-document-data","title":"Post-process extracted document data\u00b6","text":""},{"location":"examples/rag_weaviate/#perform-hierarchical-chunking-on-documents","title":"Perform hierarchical chunking on documents\u00b6","text":"<p>We use Docling's <code>HierarchicalChunker()</code> to perform hierarchy-aware chunking of our list of documents. This is meant to preserve some of the structure and relationships within the document, which enables more accurate and relevant retrieval in our RAG pipeline.</p>"},{"location":"examples/rag_weaviate/#part-2-weaviate","title":"\ud83d\udc9a Part 2: Weaviate\u00b6","text":""},{"location":"examples/rag_weaviate/#create-and-configure-an-embedded-weaviate-collection","title":"Create and configure an embedded Weaviate collection\u00b6","text":""},{"location":"examples/rag_weaviate/#wrangle-data-into-an-acceptable-format-for-weaviate","title":"Wrangle data into an acceptable format for Weaviate\u00b6","text":"<p>Transform our data from lists to a list of dictionaries for insertion into our Weaviate collection.</p>"},{"location":"examples/rag_weaviate/#insert-data-into-weaviate-and-generate-embeddings","title":"Insert data into Weaviate and generate embeddings\u00b6","text":"<p>Embeddings will be generated upon insertion to our Weaviate collection.</p>"},{"location":"examples/rag_weaviate/#query-the-data","title":"Query the data\u00b6","text":"<p>Here, we perform a simple similarity search to return the most similar embedded chunks to our search query.</p>"},{"location":"examples/rag_weaviate/#perform-rag-on-parsed-articles","title":"Perform RAG on parsed articles\u00b6","text":"<p>Weaviate's <code>generate</code> module allows you to perform RAG over your embedded data without having to use a separate framework.</p> <p>We specify a prompt that includes the field we want to search through in the database (in this case it's <code>text</code>), a query that includes our search term, and the number of retrieved results to use in the generation.</p>"},{"location":"examples/run_md/","title":"Run md","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nimport os\nfrom pathlib import Path\n</pre> import json import logging import os from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import yaml\n</pre> import yaml In\u00a0[\u00a0]: Copied! <pre>from docowling.backend.md_backend import MarkdownDocumentBackend\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.document import InputDocument\n</pre> from docowling.backend.md_backend import MarkdownDocumentBackend from docowling.datamodel.base_models import InputFormat from docowling.datamodel.document import InputDocument In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def main():\n    input_paths = [Path(\"README.md\")]\n\n    for path in input_paths:\n        in_doc = InputDocument(\n            path_or_stream=path,\n            format=InputFormat.PDF,\n            backend=MarkdownDocumentBackend,\n        )\n        mdb = MarkdownDocumentBackend(in_doc=in_doc, path_or_stream=path)\n        document = mdb.convert()\n\n        out_path = Path(\"scratch\")\n        print(\n            f\"Document {path} converted.\" f\"\\nSaved markdown output to: {str(out_path)}\"\n        )\n\n        # Export Docling document format to markdowndoc:\n        fn = os.path.basename(path)\n\n        with (out_path / f\"{fn}.md\").open(\"w\") as fp:\n            fp.write(document.export_to_markdown())\n\n        with (out_path / f\"{fn}.json\").open(\"w\") as fp:\n            fp.write(json.dumps(document.export_to_dict()))\n\n        with (out_path / f\"{fn}.yaml\").open(\"w\") as fp:\n            fp.write(yaml.safe_dump(document.export_to_dict()))\n</pre> def main():     input_paths = [Path(\"README.md\")]      for path in input_paths:         in_doc = InputDocument(             path_or_stream=path,             format=InputFormat.PDF,             backend=MarkdownDocumentBackend,         )         mdb = MarkdownDocumentBackend(in_doc=in_doc, path_or_stream=path)         document = mdb.convert()          out_path = Path(\"scratch\")         print(             f\"Document {path} converted.\" f\"\\nSaved markdown output to: {str(out_path)}\"         )          # Export Docling document format to markdowndoc:         fn = os.path.basename(path)          with (out_path / f\"{fn}.md\").open(\"w\") as fp:             fp.write(document.export_to_markdown())          with (out_path / f\"{fn}.json\").open(\"w\") as fp:             fp.write(json.dumps(document.export_to_dict()))          with (out_path / f\"{fn}.yaml\").open(\"w\") as fp:             fp.write(yaml.safe_dump(document.export_to_dict())) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/run_with_accelerator/","title":"Accelerator options","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>from docowling.backend.docling_parse_backend import DoclingParseDocumentBackend\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.datamodel.pipeline_options import (\n    AcceleratorDevice,\n    AcceleratorOptions,\n    PdfPipelineOptions,\n    TesseractCliOcrOptions,\n    TesseractOcrOptions,\n)\nfrom docowling.datamodel.settings import settings\nfrom docowling.document_converter import DocumentConverter, PdfFormatOption\n</pre> from docowling.backend.docling_parse_backend import DoclingParseDocumentBackend from docowling.datamodel.base_models import InputFormat from docowling.datamodel.pipeline_options import (     AcceleratorDevice,     AcceleratorOptions,     PdfPipelineOptions,     TesseractCliOcrOptions,     TesseractOcrOptions, ) from docowling.datamodel.settings import settings from docowling.document_converter import DocumentConverter, PdfFormatOption In\u00a0[\u00a0]: Copied! <pre>def main():\n    input_doc = Path(\"./tests/data/2206.01062.pdf\")\n\n    # Explicitly set the accelerator\n    # accelerator_options = AcceleratorOptions(\n    #     num_threads=8, device=AcceleratorDevice.AUTO\n    # )\n    accelerator_options = AcceleratorOptions(\n        num_threads=8, device=AcceleratorDevice.CPU\n    )\n    # accelerator_options = AcceleratorOptions(\n    #     num_threads=8, device=AcceleratorDevice.MPS\n    # )\n    # accelerator_options = AcceleratorOptions(\n    #     num_threads=8, device=AcceleratorDevice.CUDA\n    # )\n\n    pipeline_options = PdfPipelineOptions()\n    pipeline_options.accelerator_options = accelerator_options\n    pipeline_options.do_ocr = True\n    pipeline_options.do_table_structure = True\n    pipeline_options.table_structure_options.do_cell_matching = True\n\n    converter = DocumentConverter(\n        format_options={\n            InputFormat.PDF: PdfFormatOption(\n                pipeline_options=pipeline_options,\n            )\n        }\n    )\n\n    # Enable the profiling to measure the time spent\n    settings.debug.profile_pipeline_timings = True\n\n    # Convert the document\n    conversion_result = converter.convert(input_doc)\n    doc = conversion_result.document\n\n    # List with total time per document\n    doc_conversion_secs = conversion_result.timings[\"pipeline_total\"].times\n\n    md = doc.export_to_markdown()\n    print(md)\n    print(f\"Conversion secs: {doc_conversion_secs}\")\n</pre> def main():     input_doc = Path(\"./tests/data/2206.01062.pdf\")      # Explicitly set the accelerator     # accelerator_options = AcceleratorOptions(     #     num_threads=8, device=AcceleratorDevice.AUTO     # )     accelerator_options = AcceleratorOptions(         num_threads=8, device=AcceleratorDevice.CPU     )     # accelerator_options = AcceleratorOptions(     #     num_threads=8, device=AcceleratorDevice.MPS     # )     # accelerator_options = AcceleratorOptions(     #     num_threads=8, device=AcceleratorDevice.CUDA     # )      pipeline_options = PdfPipelineOptions()     pipeline_options.accelerator_options = accelerator_options     pipeline_options.do_ocr = True     pipeline_options.do_table_structure = True     pipeline_options.table_structure_options.do_cell_matching = True      converter = DocumentConverter(         format_options={             InputFormat.PDF: PdfFormatOption(                 pipeline_options=pipeline_options,             )         }     )      # Enable the profiling to measure the time spent     settings.debug.profile_pipeline_timings = True      # Convert the document     conversion_result = converter.convert(input_doc)     doc = conversion_result.document      # List with total time per document     doc_conversion_secs = conversion_result.timings[\"pipeline_total\"].times      md = doc.export_to_markdown()     print(md)     print(f\"Conversion secs: {doc_conversion_secs}\") In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/run_with_formats/","title":"Multi-format conversion","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nfrom pathlib import Path\n</pre> import json import logging from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import yaml\n</pre> import yaml In\u00a0[\u00a0]: Copied! <pre>from docowling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\nfrom docowling.datamodel.base_models import InputFormat\nfrom docowling.document_converter import (\n    DocumentConverter,\n    PdfFormatOption,\n    WordFormatOption,\n)\nfrom docowling.pipeline.simple_pipeline import SimplePipeline\nfrom docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n</pre> from docowling.backend.pypdfium2_backend import PyPdfiumDocumentBackend from docowling.datamodel.base_models import InputFormat from docowling.document_converter import (     DocumentConverter,     PdfFormatOption,     WordFormatOption, ) from docowling.pipeline.simple_pipeline import SimplePipeline from docowling.pipeline.standard_pdf_pipeline import StandardPdfPipeline In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def main():\n    input_paths = [\n        Path(\"README.md\"),\n        Path(\"tests/data/html/wiki_duck.html\"),\n        Path(\"tests/data/docx/word_sample.docx\"),\n        Path(\"tests/data/docx/lorem_ipsum.docx\"),\n        Path(\"tests/data/pptx/powerpoint_sample.pptx\"),\n        Path(\"tests/data/2305.03393v1-pg9-img.png\"),\n        Path(\"tests/data/2206.01062.pdf\"),\n        Path(\"tests/data/test_01.asciidoc\"),\n        Path(\"tests/data/test_01.asciidoc\"),\n    ]\n\n    ## for defaults use:\n    # doc_converter = DocumentConverter()\n\n    ## to customize use:\n\n    doc_converter = (\n        DocumentConverter(  # all of the below is optional, has internal defaults.\n            allowed_formats=[\n                InputFormat.PDF,\n                InputFormat.IMAGE,\n                InputFormat.DOCX,\n                InputFormat.HTML,\n                InputFormat.PPTX,\n                InputFormat.ASCIIDOC,\n                InputFormat.MD,\n            ],  # whitelist formats, non-matching files are ignored.\n            format_options={\n                InputFormat.PDF: PdfFormatOption(\n                    pipeline_cls=StandardPdfPipeline, backend=PyPdfiumDocumentBackend\n                ),\n                InputFormat.DOCX: WordFormatOption(\n                    pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend\n                ),\n            },\n        )\n    )\n\n    conv_results = doc_converter.convert_all(input_paths)\n\n    for res in conv_results:\n        out_path = Path(\"scratch\")\n        print(\n            f\"Document {res.input.file.name} converted.\"\n            f\"\\nSaved markdown output to: {str(out_path)}\"\n        )\n        _log.debug(res.document._export_to_indented_text(max_text_len=16))\n        # Export Docling document format to markdowndoc:\n        with (out_path / f\"{res.input.file.stem}.md\").open(\"w\") as fp:\n            fp.write(res.document.export_to_markdown())\n\n        with (out_path / f\"{res.input.file.stem}.json\").open(\"w\") as fp:\n            fp.write(json.dumps(res.document.export_to_dict()))\n\n        with (out_path / f\"{res.input.file.stem}.yaml\").open(\"w\") as fp:\n            fp.write(yaml.safe_dump(res.document.export_to_dict()))\n</pre> def main():     input_paths = [         Path(\"README.md\"),         Path(\"tests/data/html/wiki_duck.html\"),         Path(\"tests/data/docx/word_sample.docx\"),         Path(\"tests/data/docx/lorem_ipsum.docx\"),         Path(\"tests/data/pptx/powerpoint_sample.pptx\"),         Path(\"tests/data/2305.03393v1-pg9-img.png\"),         Path(\"tests/data/2206.01062.pdf\"),         Path(\"tests/data/test_01.asciidoc\"),         Path(\"tests/data/test_01.asciidoc\"),     ]      ## for defaults use:     # doc_converter = DocumentConverter()      ## to customize use:      doc_converter = (         DocumentConverter(  # all of the below is optional, has internal defaults.             allowed_formats=[                 InputFormat.PDF,                 InputFormat.IMAGE,                 InputFormat.DOCX,                 InputFormat.HTML,                 InputFormat.PPTX,                 InputFormat.ASCIIDOC,                 InputFormat.MD,             ],  # whitelist formats, non-matching files are ignored.             format_options={                 InputFormat.PDF: PdfFormatOption(                     pipeline_cls=StandardPdfPipeline, backend=PyPdfiumDocumentBackend                 ),                 InputFormat.DOCX: WordFormatOption(                     pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend                 ),             },         )     )      conv_results = doc_converter.convert_all(input_paths)      for res in conv_results:         out_path = Path(\"scratch\")         print(             f\"Document {res.input.file.name} converted.\"             f\"\\nSaved markdown output to: {str(out_path)}\"         )         _log.debug(res.document._export_to_indented_text(max_text_len=16))         # Export Docling document format to markdowndoc:         with (out_path / f\"{res.input.file.stem}.md\").open(\"w\") as fp:             fp.write(res.document.export_to_markdown())          with (out_path / f\"{res.input.file.stem}.json\").open(\"w\") as fp:             fp.write(json.dumps(res.document.export_to_dict()))          with (out_path / f\"{res.input.file.stem}.yaml\").open(\"w\") as fp:             fp.write(yaml.safe_dump(res.document.export_to_dict())) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"integrations/","title":"Integrations","text":"<p>Use the navigation on the left to browse through Docling integrations with popular frameworks and tools.</p> <p> </p>"},{"location":"integrations/bee/","title":"\ud83d\udc1d Bee","text":"<p>Docling is available as an extraction backend in the Bee framework.</p> <ul> <li>\ud83d\udcbb Bee GitHub</li> <li>\ud83d\udcd6 Bee docs</li> <li>\ud83d\udce6 Bee NPM</li> </ul>"},{"location":"integrations/cloudera/","title":"Cloudera","text":"<p>Docling is available in Cloudera through the RAG Studio Accelerator for Machine Learning Projects (AMP).</p> <ul> <li>\ud83d\udcbb RAG Studio AMP GitHub</li> </ul>"},{"location":"integrations/data_prep_kit/","title":"Data Prep Kit","text":"<p>Docling is used by the Data Prep Kit open-source toolkit for preparing unstructured data for LLM application development ranging from laptop scale to datacenter scale.</p>"},{"location":"integrations/data_prep_kit/#components","title":"Components","text":""},{"location":"integrations/data_prep_kit/#pdf-ingestion-to-parquet","title":"PDF ingestion to Parquet","text":"<ul> <li>\ud83d\udcbb PDF-to-Parquet GitHub</li> <li>\ud83d\udcd6 PDF-to-Parquet docs</li> </ul>"},{"location":"integrations/data_prep_kit/#document-chunking","title":"Document chunking","text":"<ul> <li>\ud83d\udcbb Doc Chunking GitHub</li> <li>\ud83d\udcd6 Doc Chunking docs</li> </ul>"},{"location":"integrations/docetl/","title":"DocETL","text":"<p>Docling is available as a file conversion method in DocETL:</p> <ul> <li>\ud83d\udcbb DocETL GitHub</li> <li>\ud83d\udcd6 DocETL docs</li> <li>\ud83d\udce6 DocETL PyPI</li> </ul>"},{"location":"integrations/haystack/","title":"Haystack","text":"<p>Docling is available as a converter in Haystack:</p> <ul> <li>\ud83d\udcd6 Docling Haystack integration docs</li> <li>\ud83d\udcbb Docling Haystack integration GitHub</li> <li>\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf73 Docling Haystack integration example</li> <li>\ud83d\udce6 Docling Haystack integration PyPI</li> </ul>"},{"location":"integrations/instructlab/","title":"\ud83d\udc36 InstructLab","text":"<p>Docling is powering document processing in InstructLab, enabling users to unlock the knowledge hidden in documents and present it to InstructLab's fine-tuning for aligning AI models to the user's specific data.</p> <p>More details can be found in this blog post.</p> <ul> <li>\ud83c\udfe0 InstructLab home</li> <li>\ud83d\udcbb InstructLab GitHub</li> <li>\ud83e\uddd1\ud83c\udffb\u200d\ud83d\udcbb InstructLab UI</li> <li>\ud83d\udcd6 InstructLab docs</li> </ul>"},{"location":"integrations/kotaemon/","title":"Kotaemon","text":"<p>Docling is available in Kotaemon as the <code>DoclingReader</code> loader:</p> <ul> <li>\ud83d\udcbb Kotaemon GitHub</li> <li>\ud83d\udcd6 DoclingReader docs</li> <li>\u2699\ufe0f Docling setup in Kotaemon</li> </ul>"},{"location":"integrations/llamaindex/","title":"\ud83e\udd99 LlamaIndex","text":"<p>Docling is available as an official LlamaIndex extension.</p> <p>To get started, check out the step-by-step guide in LlamaIndex.</p>"},{"location":"integrations/llamaindex/#components","title":"Components","text":""},{"location":"integrations/llamaindex/#docling-reader","title":"Docling Reader","text":"<p>Reads document files and uses Docling to populate LlamaIndex <code>Document</code> objects \u2014 either serializing Docling's data model (losslessly, e.g. as JSON) or exporting to a simplified format (lossily, e.g. as Markdown).</p> <ul> <li>\ud83d\udcbb Docling Reader GitHub</li> <li>\ud83d\udcd6 Docling Reader docs</li> <li>\ud83d\udce6 Docling Reader PyPI</li> </ul>"},{"location":"integrations/llamaindex/#docling-node-parser","title":"Docling Node Parser","text":"<p>Reads LlamaIndex <code>Document</code> objects populated in Docling's format by Docling Reader and, using its knowledge of the Docling format, parses them to LlamaIndex <code>Node</code> objects for downstream usage in LlamaIndex applications, e.g. as chunks for embedding.</p> <ul> <li>\ud83d\udcbb Docling Node Parser GitHub</li> <li>\ud83d\udcd6 Docling Node Parser docs</li> <li>\ud83d\udce6 Docling Node Parser PyPI</li> </ul>"},{"location":"integrations/prodigy/","title":"Prodigy","text":"<p>Docling is available in Prodigy as a Prodigy-PDF plugin recipe.</p> <p>More details can be found in this blog post.</p> <ul> <li>\ud83c\udf10 Prodigy home</li> <li>\ud83d\udd0c Prodigy-PDF plugin</li> <li>\ud83e\uddd1\ud83c\udffd\u200d\ud83c\udf73 pdf-spans.manual recipe</li> </ul>"},{"location":"integrations/rhel_ai/","title":"RHEL AI","text":"<p>Docling is powering document processing in Red Hat Enterprise Linux AI (RHEL AI), enabling users to unlock the knowledge hidden in documents and present it to InstructLab's fine-tuning for aligning AI models to the user's specific data.</p> <ul> <li>\ud83d\udce3 RHEL AI 1.3 announcement</li> <li>\u270d\ufe0f RHEL blog posts:<ul> <li>RHEL AI 1.3 Docling context aware chunking: What you need to know</li> <li>Docling: The missing document processing companion for generative AI</li> </ul> </li> </ul>"},{"location":"integrations/spacy/","title":"spaCy","text":"<p>Docling is available in spaCy as the spaCy Layout plugin.</p> <p>More details can be found in this blog post.</p> <ul> <li>\ud83d\udcbb SpacyLayout GitHub</li> <li>\ud83d\udcd6 SpacyLayout docs</li> <li>\ud83d\udce6 SpacyLayout PyPI</li> </ul>"},{"location":"integrations/txtai/","title":"txtai","text":"<p>Docling is available as a text extraction backend for txtai.</p> <ul> <li>\ud83d\udcbb txtai GitHub</li> <li>\ud83d\udcd6 txtai docs</li> <li>\ud83d\udcd6 txtai Docling backend</li> </ul>"},{"location":"integrations/vectara/","title":"Vectara","text":"<p>Docling is available as a document parser in Vectara.</p> <ul> <li>\ud83d\udcbb Vectara GitHub org<ul> <li>vectara-ingest GitHub repo</li> </ul> </li> <li>\ud83d\udcd6 Vectara docs</li> </ul>"},{"location":"reference/cli/","title":"CLI reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"reference/cli/#docling","title":"docling","text":"<p>Usage:</p> <pre><code>docling [OPTIONS] source\n</code></pre> <p>Options:</p> Name Type Description Default <code>--from</code> choice (<code>docx</code> | <code>pptx</code> | <code>html</code> | <code>xml_pubmed</code> | <code>image</code> | <code>pdf</code> | <code>asciidoc</code> | <code>md</code> | <code>xlsx</code> | <code>csv</code> | <code>xml_uspto</code>) Specify input formats to convert from. Defaults to all formats. None <code>--to</code> choice (<code>md</code> | <code>json</code> | <code>html</code> | <code>text</code> | <code>doctags</code>) Specify output formats. Defaults to Markdown. None <code>--image-export-mode</code> choice (<code>placeholder</code> | <code>embedded</code> | <code>referenced</code>) Image export mode for the document (only in case of JSON, Markdown or HTML). With <code>placeholder</code>, only the position of the image is marked in the output. In <code>embedded</code> mode, the image is embedded as base64 encoded string. In <code>referenced</code> mode, the image is exported in PNG format and referenced from the main exported document. <code>ImageRefMode.EMBEDDED</code> <code>--ocr</code> / <code>--no-ocr</code> boolean If enabled, the bitmap content will be processed using OCR. <code>True</code> <code>--force-ocr</code> / <code>--no-force-ocr</code> boolean Replace any existing text with OCR generated text over the full content. <code>False</code> <code>--ocr-engine</code> choice (<code>easyocr</code> | <code>tesseract_cli</code> | <code>tesseract</code> | <code>ocrmac</code> | <code>rapidocr</code>) The OCR engine to use. <code>OcrEngine.EASYOCR</code> <code>--ocr-lang</code> text Provide a comma-separated list of languages used by the OCR engine. Note that each OCR engine has different values for the language names. None <code>--pdf-backend</code> choice (<code>pypdfium2</code> | <code>dlparse_v1</code> | <code>dlparse_v2</code>) The PDF backend to use. <code>PdfBackend.DLPARSE_V2</code> <code>--table-mode</code> choice (<code>fast</code> | <code>accurate</code>) The mode to use in the table structure model. <code>TableFormerMode.FAST</code> <code>--artifacts-path</code> path If provided, the location of the model artifacts. None <code>--abort-on-error</code> / <code>--no-abort-on-error</code> boolean If enabled, the bitmap content will be processed using OCR. <code>False</code> <code>--output</code> path Output directory where results are saved. <code>.</code> <code>--verbose</code>, <code>-v</code> integer Set the verbosity level. -v for info logging, -vv for debug logging. <code>0</code> <code>--debug-visualize-cells</code> / <code>--no-debug-visualize-cells</code> boolean Enable debug output which visualizes the PDF cells <code>False</code> <code>--debug-visualize-ocr</code> / <code>--no-debug-visualize-ocr</code> boolean Enable debug output which visualizes the OCR cells <code>False</code> <code>--debug-visualize-layout</code> / <code>--no-debug-visualize-layout</code> boolean Enable debug output which visualizes the layour clusters <code>False</code> <code>--debug-visualize-tables</code> / <code>--no-debug-visualize-tables</code> boolean Enable debug output which visualizes the table cells <code>False</code> <code>--version</code> boolean Show version information. None <code>--document-timeout</code> float The timeout for processing each document, in seconds. None <code>--num-threads</code> integer Number of threads <code>4</code> <code>--device</code> choice (<code>auto</code> | <code>cpu</code> | <code>cuda</code> | <code>mps</code>) Accelerator device <code>AcceleratorDevice.AUTO</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/docling_document/","title":"Docling Document","text":"<p>This is an automatic generated API reference of the DoclingDocument type.</p>"},{"location":"reference/docling_document/#docling_core.types.doc","title":"doc","text":"<p>Package for models defined by the Document type.</p> <p>Classes:</p> <ul> <li> <code>DoclingDocument</code>           \u2013            <p>DoclingDocument.</p> </li> <li> <code>DocumentOrigin</code>           \u2013            <p>FileSource.</p> </li> <li> <code>DocItem</code>           \u2013            <p>DocItem.</p> </li> <li> <code>DocItemLabel</code>           \u2013            <p>DocItemLabel.</p> </li> <li> <code>ProvenanceItem</code>           \u2013            <p>ProvenanceItem.</p> </li> <li> <code>GroupItem</code>           \u2013            <p>GroupItem.</p> </li> <li> <code>GroupLabel</code>           \u2013            <p>GroupLabel.</p> </li> <li> <code>NodeItem</code>           \u2013            <p>NodeItem.</p> </li> <li> <code>PageItem</code>           \u2013            <p>PageItem.</p> </li> <li> <code>FloatingItem</code>           \u2013            <p>FloatingItem.</p> </li> <li> <code>TextItem</code>           \u2013            <p>TextItem.</p> </li> <li> <code>TableItem</code>           \u2013            <p>TableItem.</p> </li> <li> <code>TableCell</code>           \u2013            <p>TableCell.</p> </li> <li> <code>TableData</code>           \u2013            <p>BaseTableData.</p> </li> <li> <code>TableCellLabel</code>           \u2013            <p>TableCellLabel.</p> </li> <li> <code>KeyValueItem</code>           \u2013            <p>KeyValueItem.</p> </li> <li> <code>SectionHeaderItem</code>           \u2013            <p>SectionItem.</p> </li> <li> <code>PictureItem</code>           \u2013            <p>PictureItem.</p> </li> <li> <code>ImageRef</code>           \u2013            <p>ImageRef.</p> </li> <li> <code>PictureClassificationClass</code>           \u2013            <p>PictureClassificationData.</p> </li> <li> <code>PictureClassificationData</code>           \u2013            <p>PictureClassificationData.</p> </li> <li> <code>RefItem</code>           \u2013            <p>RefItem.</p> </li> <li> <code>BoundingBox</code>           \u2013            <p>BoundingBox.</p> </li> <li> <code>CoordOrigin</code>           \u2013            <p>CoordOrigin.</p> </li> <li> <code>ImageRefMode</code>           \u2013            <p>ImageRefMode.</p> </li> <li> <code>Size</code>           \u2013            <p>Size.</p> </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument","title":"DoclingDocument","text":"<p>               Bases: <code>BaseModel</code></p> <p>DoclingDocument.</p> <p>Methods:</p> <ul> <li> <code>add_group</code>             \u2013              <p>add_group.</p> </li> <li> <code>add_heading</code>             \u2013              <p>add_heading.</p> </li> <li> <code>add_list_item</code>             \u2013              <p>add_list_item.</p> </li> <li> <code>add_page</code>             \u2013              <p>add_page.</p> </li> <li> <code>add_picture</code>             \u2013              <p>add_picture.</p> </li> <li> <code>add_table</code>             \u2013              <p>add_table.</p> </li> <li> <code>add_text</code>             \u2013              <p>add_text.</p> </li> <li> <code>add_title</code>             \u2013              <p>add_title.</p> </li> <li> <code>check_version_is_compatible</code>             \u2013              <p>Check if this document version is compatible with current version.</p> </li> <li> <code>export_to_dict</code>             \u2013              <p>Export to dict.</p> </li> <li> <code>export_to_document_tokens</code>             \u2013              <p>Exports the document content to a DocumentToken format.</p> </li> <li> <code>export_to_element_tree</code>             \u2013              <p>Export_to_element_tree.</p> </li> <li> <code>export_to_html</code>             \u2013              <p>Serialize to HTML.</p> </li> <li> <code>export_to_markdown</code>             \u2013              <p>Serialize to Markdown.</p> </li> <li> <code>export_to_text</code>             \u2013              <p>export_to_text.</p> </li> <li> <code>iterate_items</code>             \u2013              <p>iterate_elements.</p> </li> <li> <code>load_from_json</code>             \u2013              <p>load_from_json.</p> </li> <li> <code>num_pages</code>             \u2013              <p>num_pages.</p> </li> <li> <code>print_element_tree</code>             \u2013              <p>Print_element_tree.</p> </li> <li> <code>save_as_document_tokens</code>             \u2013              <p>Save the document content to a DocumentToken format.</p> </li> <li> <code>save_as_html</code>             \u2013              <p>Save to HTML.</p> </li> <li> <code>save_as_json</code>             \u2013              <p>Save as json.</p> </li> <li> <code>save_as_markdown</code>             \u2013              <p>Save to markdown.</p> </li> <li> <code>save_as_yaml</code>             \u2013              <p>Save as yaml.</p> </li> <li> <code>validate_document</code>             \u2013              <p>validate_document.</p> </li> <li> <code>validate_tree</code>             \u2013              <p>validate_tree.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>body</code>               (<code>GroupItem</code>)           \u2013            </li> <li> <code>furniture</code>               (<code>GroupItem</code>)           \u2013            </li> <li> <code>groups</code>               (<code>List[GroupItem]</code>)           \u2013            </li> <li> <code>key_value_items</code>               (<code>List[KeyValueItem]</code>)           \u2013            </li> <li> <code>name</code>               (<code>str</code>)           \u2013            </li> <li> <code>origin</code>               (<code>Optional[DocumentOrigin]</code>)           \u2013            </li> <li> <code>pages</code>               (<code>Dict[int, PageItem]</code>)           \u2013            </li> <li> <code>pictures</code>               (<code>List[PictureItem]</code>)           \u2013            </li> <li> <code>schema_name</code>               (<code>Literal['DoclingDocument']</code>)           \u2013            </li> <li> <code>tables</code>               (<code>List[TableItem]</code>)           \u2013            </li> <li> <code>texts</code>               (<code>List[Union[SectionHeaderItem, ListItem, TextItem]]</code>)           \u2013            </li> <li> <code>version</code>               (<code>Annotated[str, StringConstraints(pattern=VERSION_PATTERN, strict=True)]</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.body","title":"body","text":"<pre><code>body: GroupItem = GroupItem(\n    name=\"_root_\", self_ref=\"#/body\"\n)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.furniture","title":"furniture","text":"<pre><code>furniture: GroupItem = GroupItem(\n    name=\"_root_\", self_ref=\"#/furniture\"\n)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.groups","title":"groups","text":"<pre><code>groups: List[GroupItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.key_value_items","title":"key_value_items","text":"<pre><code>key_value_items: List[KeyValueItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.name","title":"name","text":"<pre><code>name: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.origin","title":"origin","text":"<pre><code>origin: Optional[DocumentOrigin] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.pages","title":"pages","text":"<pre><code>pages: Dict[int, PageItem] = {}\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.pictures","title":"pictures","text":"<pre><code>pictures: List[PictureItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.schema_name","title":"schema_name","text":"<pre><code>schema_name: Literal['DoclingDocument'] = 'DoclingDocument'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.tables","title":"tables","text":"<pre><code>tables: List[TableItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.texts","title":"texts","text":"<pre><code>texts: List[\n    Union[SectionHeaderItem, ListItem, TextItem]\n] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.version","title":"version","text":"<pre><code>version: Annotated[\n    str,\n    StringConstraints(pattern=VERSION_PATTERN, strict=True),\n] = CURRENT_VERSION\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_group","title":"add_group","text":"<pre><code>add_group(\n    label: Optional[GroupLabel] = None,\n    name: Optional[str] = None,\n    parent: Optional[NodeItem] = None,\n) -&gt; GroupItem\n</code></pre> <p>add_group.</p> <p>:param label: Optional[GroupLabel]:  (Default value = None) :param name: Optional[str]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_heading","title":"add_heading","text":"<pre><code>add_heading(\n    text: str,\n    orig: Optional[str] = None,\n    level: LevelNumber = 1,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n)\n</code></pre> <p>add_heading.</p> <p>:param label: DocItemLabel: :param text: str: :param orig: Optional[str]:  (Default value = None) :param level: LevelNumber:  (Default value = 1) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_list_item","title":"add_list_item","text":"<pre><code>add_list_item(\n    text: str,\n    enumerated: bool = False,\n    marker: Optional[str] = None,\n    orig: Optional[str] = None,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n)\n</code></pre> <p>add_list_item.</p> <p>:param label: str: :param text: str: :param orig: Optional[str]:  (Default value = None) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_page","title":"add_page","text":"<pre><code>add_page(\n    page_no: int,\n    size: Size,\n    image: Optional[ImageRef] = None,\n) -&gt; PageItem\n</code></pre> <p>add_page.</p> <p>:param page_no: int: :param size: Size:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_picture","title":"add_picture","text":"<pre><code>add_picture(\n    annotations: List[PictureDataType] = [],\n    image: Optional[ImageRef] = None,\n    caption: Optional[Union[TextItem, RefItem]] = None,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n)\n</code></pre> <p>add_picture.</p> <p>:param data: List[PictureData]: (Default value = []) :param caption: Optional[Union[TextItem: :param RefItem]]:  (Default value = None) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_table","title":"add_table","text":"<pre><code>add_table(\n    data: TableData,\n    caption: Optional[Union[TextItem, RefItem]] = None,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n    label: DocItemLabel = TABLE,\n)\n</code></pre> <p>add_table.</p> <p>:param data: TableData: :param caption: Optional[Union[TextItem, RefItem]]:  (Default value = None) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None) :param label: DocItemLabel:  (Default value = DocItemLabel.TABLE)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_text","title":"add_text","text":"<pre><code>add_text(\n    label: DocItemLabel,\n    text: str,\n    orig: Optional[str] = None,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n)\n</code></pre> <p>add_text.</p> <p>:param label: str: :param text: str: :param orig: Optional[str]:  (Default value = None) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.add_title","title":"add_title","text":"<pre><code>add_title(\n    text: str,\n    orig: Optional[str] = None,\n    prov: Optional[ProvenanceItem] = None,\n    parent: Optional[NodeItem] = None,\n)\n</code></pre> <p>add_title.</p> <p>:param text: str: :param orig: Optional[str]:  (Default value = None) :param prov: Optional[ProvenanceItem]:  (Default value = None) :param parent: Optional[NodeItem]:  (Default value = None)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.check_version_is_compatible","title":"check_version_is_compatible","text":"<pre><code>check_version_is_compatible(v: str) -&gt; str\n</code></pre> <p>Check if this document version is compatible with current version.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_dict","title":"export_to_dict","text":"<pre><code>export_to_dict(\n    mode: str = \"json\",\n    by_alias: bool = True,\n    exclude_none: bool = True,\n) -&gt; Dict\n</code></pre> <p>Export to dict.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_document_tokens","title":"export_to_document_tokens","text":"<pre><code>export_to_document_tokens(\n    delim: str = \"\\n\",\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_content: bool = True,\n    add_page_index: bool = True,\n    add_table_cell_location: bool = False,\n    add_table_cell_label: bool = True,\n    add_table_cell_text: bool = True,\n    page_no: Optional[int] = None,\n    with_groups: bool = True,\n    newline: bool = True,\n) -&gt; str\n</code></pre> <p>Exports the document content to a DocumentToken format.</p> <p>Operates on a slice of the document's body as defined through arguments from_element and to_element; defaulting to the whole main_text.</p> <p>:param delim: str:  (Default value = \"\\n\\n\") :param from_element: int:  (Default value = 0) :param to_element: Optional[int]:  (Default value = None) :param labels: set[DocItemLabel] :param xsize: int:  (Default value = 100) :param ysize: int:  (Default value = 100) :param add_location: bool:  (Default value = True) :param add_content: bool:  (Default value = True) :param add_page_index: bool:  (Default value = True) :param # table specific flagsadd_table_cell_location: bool :param add_table_cell_label: bool:  (Default value = True) :param add_table_cell_text: bool:  (Default value = True) :returns: The content of the document formatted as a DocTags string. :rtype: str</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_element_tree","title":"export_to_element_tree","text":"<pre><code>export_to_element_tree() -&gt; str\n</code></pre> <p>Export_to_element_tree.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_html","title":"export_to_html","text":"<pre><code>export_to_html(\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    image_mode: ImageRefMode = PLACEHOLDER,\n    page_no: Optional[int] = None,\n    html_lang: str = \"en\",\n    html_head: str = _HTML_DEFAULT_HEAD,\n) -&gt; str\n</code></pre> <p>Serialize to HTML.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_markdown","title":"export_to_markdown","text":"<pre><code>export_to_markdown(\n    delim: str = \"\\n\",\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    strict_text: bool = False,\n    image_placeholder: str = \"&lt;!-- image --&gt;\",\n    image_mode: ImageRefMode = PLACEHOLDER,\n    indent: int = 4,\n    text_width: int = -1,\n    page_no: Optional[int] = None,\n) -&gt; str\n</code></pre> <p>Serialize to Markdown.</p> <p>Operates on a slice of the document's body as defined through arguments from_element and to_element; defaulting to the whole document.</p> <p>:param delim: Delimiter to use when concatenating the various         Markdown parts. (Default value = \"\\n\"). :type delim: str = \"\\n\" :param from_element: Body slicing start index (inclusive).         (Default value = 0). :type from_element: int = 0 :param to_element: Body slicing stop index         (exclusive). (Default value = maxint). :type to_element: int = sys.maxsize :param labels: The set of document labels to include in the export. :type labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS :param strict_text: bool: Whether to only include the text content     of the document. (Default value = False). :type strict_text: bool = False :param image_placeholder: The placeholder to include to position     images in the markdown. (Default value = \"\\&lt;!-- image --&gt;\"). :type image_placeholder: str = \"\" :param image_mode: The mode to use for including images in the     markdown. (Default value = ImageRefMode.PLACEHOLDER). :type image_mode: ImageRefMode = ImageRefMode.PLACEHOLDER :param indent: The indent in spaces of the nested lists.     (Default value = 4). :type indent: int = 4 :returns: The exported Markdown representation. :rtype: str</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.export_to_text","title":"export_to_text","text":"<pre><code>export_to_text(\n    delim: str = \"\\n\\n\",\n    from_element: int = 0,\n    to_element: int = 1000000,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n) -&gt; str\n</code></pre> <p>export_to_text.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.iterate_items","title":"iterate_items","text":"<pre><code>iterate_items(\n    root: Optional[NodeItem] = None,\n    with_groups: bool = False,\n    traverse_pictures: bool = False,\n    page_no: Optional[int] = None,\n    _level: int = 0,\n) -&gt; Iterable[Tuple[NodeItem, int]]\n</code></pre> <p>iterate_elements.</p> <p>:param root: Optional[NodeItem]:  (Default value = None) :param with_groups: bool:  (Default value = False) :param traverse_pictures: bool:  (Default value = True) :param page_no: Optional[int]:  (Default value = None) :param _level:  (Default value = 0) :param # fixed parameter: :param carries through the node nesting level:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.load_from_json","title":"load_from_json","text":"<pre><code>load_from_json(filename: Path) -&gt; DoclingDocument\n</code></pre> <p>load_from_json.</p> <p>:param filename: The filename to load a saved DoclingDocument from a .json. :type filename: Path</p> <p>:returns: The loaded DoclingDocument. :rtype: DoclingDocument</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.num_pages","title":"num_pages","text":"<pre><code>num_pages()\n</code></pre> <p>num_pages.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.print_element_tree","title":"print_element_tree","text":"<pre><code>print_element_tree()\n</code></pre> <p>Print_element_tree.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.save_as_document_tokens","title":"save_as_document_tokens","text":"<pre><code>save_as_document_tokens(\n    filename: Path,\n    delim: str = \"\\n\\n\",\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_content: bool = True,\n    add_page_index: bool = True,\n    add_table_cell_location: bool = False,\n    add_table_cell_label: bool = True,\n    add_table_cell_text: bool = True,\n    page_no: Optional[int] = None,\n    with_groups: bool = True,\n)\n</code></pre> <p>Save the document content to a DocumentToken format.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.save_as_html","title":"save_as_html","text":"<pre><code>save_as_html(\n    filename: Path,\n    artifacts_dir: Optional[Path] = None,\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    image_mode: ImageRefMode = PLACEHOLDER,\n    page_no: Optional[int] = None,\n    html_lang: str = \"en\",\n    html_head: str = _HTML_DEFAULT_HEAD,\n)\n</code></pre> <p>Save to HTML.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.save_as_json","title":"save_as_json","text":"<pre><code>save_as_json(\n    filename: Path,\n    artifacts_dir: Optional[Path] = None,\n    image_mode: ImageRefMode = EMBEDDED,\n    indent: int = 2,\n)\n</code></pre> <p>Save as json.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.save_as_markdown","title":"save_as_markdown","text":"<pre><code>save_as_markdown(\n    filename: Path,\n    artifacts_dir: Optional[Path] = None,\n    delim: str = \"\\n\",\n    from_element: int = 0,\n    to_element: int = maxsize,\n    labels: set[DocItemLabel] = DEFAULT_EXPORT_LABELS,\n    strict_text: bool = False,\n    image_placeholder: str = \"&lt;!-- image --&gt;\",\n    image_mode: ImageRefMode = PLACEHOLDER,\n    indent: int = 4,\n    text_width: int = -1,\n    page_no: Optional[int] = None,\n)\n</code></pre> <p>Save to markdown.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.save_as_yaml","title":"save_as_yaml","text":"<pre><code>save_as_yaml(\n    filename: Path,\n    artifacts_dir: Optional[Path] = None,\n    image_mode: ImageRefMode = EMBEDDED,\n    default_flow_style: bool = False,\n)\n</code></pre> <p>Save as yaml.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.validate_document","title":"validate_document","text":"<pre><code>validate_document(d: DoclingDocument)\n</code></pre> <p>validate_document.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DoclingDocument.validate_tree","title":"validate_tree","text":"<pre><code>validate_tree(root) -&gt; bool\n</code></pre> <p>validate_tree.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin","title":"DocumentOrigin","text":"<p>               Bases: <code>BaseModel</code></p> <p>FileSource.</p> <p>Methods:</p> <ul> <li> <code>parse_hex_string</code>             \u2013              <p>parse_hex_string.</p> </li> <li> <code>validate_mimetype</code>             \u2013              <p>validate_mimetype.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>binary_hash</code>               (<code>Uint64</code>)           \u2013            </li> <li> <code>filename</code>               (<code>str</code>)           \u2013            </li> <li> <code>mimetype</code>               (<code>str</code>)           \u2013            </li> <li> <code>uri</code>               (<code>Optional[AnyUrl]</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.binary_hash","title":"binary_hash","text":"<pre><code>binary_hash: Uint64\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.filename","title":"filename","text":"<pre><code>filename: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.mimetype","title":"mimetype","text":"<pre><code>mimetype: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.uri","title":"uri","text":"<pre><code>uri: Optional[AnyUrl] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.parse_hex_string","title":"parse_hex_string","text":"<pre><code>parse_hex_string(value)\n</code></pre> <p>parse_hex_string.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocumentOrigin.validate_mimetype","title":"validate_mimetype","text":"<pre><code>validate_mimetype(v)\n</code></pre> <p>validate_mimetype.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem","title":"DocItem","text":"<p>               Bases: <code>NodeItem</code></p> <p>DocItem.</p> <p>Methods:</p> <ul> <li> <code>get_image</code>             \u2013              <p>Returns the image of this DocItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>label</code>               (<code>DocItemLabel</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.label","title":"label","text":"<pre><code>label: DocItemLabel\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image of this DocItem.</p> <p>The function returns None if this DocItem has no valid provenance or if a valid image of the page containing this DocItem is not available in doc.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel","title":"DocItemLabel","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>DocItemLabel.</p> <p>Attributes:</p> <ul> <li> <code>CAPTION</code>           \u2013            </li> <li> <code>CHECKBOX_SELECTED</code>           \u2013            </li> <li> <code>CHECKBOX_UNSELECTED</code>           \u2013            </li> <li> <code>CODE</code>           \u2013            </li> <li> <code>DOCUMENT_INDEX</code>           \u2013            </li> <li> <code>FOOTNOTE</code>           \u2013            </li> <li> <code>FORM</code>           \u2013            </li> <li> <code>FORMULA</code>           \u2013            </li> <li> <code>KEY_VALUE_REGION</code>           \u2013            </li> <li> <code>LIST_ITEM</code>           \u2013            </li> <li> <code>PAGE_FOOTER</code>           \u2013            </li> <li> <code>PAGE_HEADER</code>           \u2013            </li> <li> <code>PARAGRAPH</code>           \u2013            </li> <li> <code>PICTURE</code>           \u2013            </li> <li> <code>REFERENCE</code>           \u2013            </li> <li> <code>SECTION_HEADER</code>           \u2013            </li> <li> <code>TABLE</code>           \u2013            </li> <li> <code>TEXT</code>           \u2013            </li> <li> <code>TITLE</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.CAPTION","title":"CAPTION","text":"<pre><code>CAPTION = 'caption'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.CHECKBOX_SELECTED","title":"CHECKBOX_SELECTED","text":"<pre><code>CHECKBOX_SELECTED = 'checkbox_selected'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.CHECKBOX_UNSELECTED","title":"CHECKBOX_UNSELECTED","text":"<pre><code>CHECKBOX_UNSELECTED = 'checkbox_unselected'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.CODE","title":"CODE","text":"<pre><code>CODE = 'code'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.DOCUMENT_INDEX","title":"DOCUMENT_INDEX","text":"<pre><code>DOCUMENT_INDEX = 'document_index'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.FOOTNOTE","title":"FOOTNOTE","text":"<pre><code>FOOTNOTE = 'footnote'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.FORM","title":"FORM","text":"<pre><code>FORM = 'form'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.FORMULA","title":"FORMULA","text":"<pre><code>FORMULA = 'formula'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.KEY_VALUE_REGION","title":"KEY_VALUE_REGION","text":"<pre><code>KEY_VALUE_REGION = 'key_value_region'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.LIST_ITEM","title":"LIST_ITEM","text":"<pre><code>LIST_ITEM = 'list_item'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.PAGE_FOOTER","title":"PAGE_FOOTER","text":"<pre><code>PAGE_FOOTER = 'page_footer'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.PAGE_HEADER","title":"PAGE_HEADER","text":"<pre><code>PAGE_HEADER = 'page_header'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.PARAGRAPH","title":"PARAGRAPH","text":"<pre><code>PARAGRAPH = 'paragraph'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.PICTURE","title":"PICTURE","text":"<pre><code>PICTURE = 'picture'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.REFERENCE","title":"REFERENCE","text":"<pre><code>REFERENCE = 'reference'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.SECTION_HEADER","title":"SECTION_HEADER","text":"<pre><code>SECTION_HEADER = 'section_header'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.TABLE","title":"TABLE","text":"<pre><code>TABLE = 'table'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.TEXT","title":"TEXT","text":"<pre><code>TEXT = 'text'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.DocItemLabel.TITLE","title":"TITLE","text":"<pre><code>TITLE = 'title'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ProvenanceItem","title":"ProvenanceItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>ProvenanceItem.</p> <p>Attributes:</p> <ul> <li> <code>bbox</code>               (<code>BoundingBox</code>)           \u2013            </li> <li> <code>charspan</code>               (<code>Tuple[int, int]</code>)           \u2013            </li> <li> <code>page_no</code>               (<code>int</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.ProvenanceItem.bbox","title":"bbox","text":"<pre><code>bbox: BoundingBox\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ProvenanceItem.charspan","title":"charspan","text":"<pre><code>charspan: Tuple[int, int]\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ProvenanceItem.page_no","title":"page_no","text":"<pre><code>page_no: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem","title":"GroupItem","text":"<p>               Bases: <code>NodeItem</code></p> <p>GroupItem.</p> <p>Methods:</p> <ul> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>label</code>               (<code>GroupLabel</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>name</code>               (<code>str</code>)           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.label","title":"label","text":"<pre><code>label: GroupLabel = UNSPECIFIED\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.name","title":"name","text":"<pre><code>name: str = 'group'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel","title":"GroupLabel","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>GroupLabel.</p> <p>Attributes:</p> <ul> <li> <code>CHAPTER</code>           \u2013            </li> <li> <code>COMMENT_SECTION</code>           \u2013            </li> <li> <code>FORM_AREA</code>           \u2013            </li> <li> <code>KEY_VALUE_AREA</code>           \u2013            </li> <li> <code>LIST</code>           \u2013            </li> <li> <code>ORDERED_LIST</code>           \u2013            </li> <li> <code>SECTION</code>           \u2013            </li> <li> <code>SHEET</code>           \u2013            </li> <li> <code>SLIDE</code>           \u2013            </li> <li> <code>UNSPECIFIED</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.CHAPTER","title":"CHAPTER","text":"<pre><code>CHAPTER = 'chapter'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.COMMENT_SECTION","title":"COMMENT_SECTION","text":"<pre><code>COMMENT_SECTION = 'comment_section'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.FORM_AREA","title":"FORM_AREA","text":"<pre><code>FORM_AREA = 'form_area'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.KEY_VALUE_AREA","title":"KEY_VALUE_AREA","text":"<pre><code>KEY_VALUE_AREA = 'key_value_area'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.LIST","title":"LIST","text":"<pre><code>LIST = 'list'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.ORDERED_LIST","title":"ORDERED_LIST","text":"<pre><code>ORDERED_LIST = 'ordered_list'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.SECTION","title":"SECTION","text":"<pre><code>SECTION = 'section'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.SHEET","title":"SHEET","text":"<pre><code>SHEET = 'sheet'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.SLIDE","title":"SLIDE","text":"<pre><code>SLIDE = 'slide'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.GroupLabel.UNSPECIFIED","title":"UNSPECIFIED","text":"<pre><code>UNSPECIFIED = 'unspecified'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem","title":"NodeItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>NodeItem.</p> <p>Methods:</p> <ul> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.NodeItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PageItem","title":"PageItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>PageItem.</p> <p>Attributes:</p> <ul> <li> <code>image</code>               (<code>Optional[ImageRef]</code>)           \u2013            </li> <li> <code>page_no</code>               (<code>int</code>)           \u2013            </li> <li> <code>size</code>               (<code>Size</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.PageItem.image","title":"image","text":"<pre><code>image: Optional[ImageRef] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PageItem.page_no","title":"page_no","text":"<pre><code>page_no: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PageItem.size","title":"size","text":"<pre><code>size: Size\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem","title":"FloatingItem","text":"<p>               Bases: <code>DocItem</code></p> <p>FloatingItem.</p> <p>Methods:</p> <ul> <li> <code>caption_text</code>             \u2013              <p>Computes the caption as a single text.</p> </li> <li> <code>get_image</code>             \u2013              <p>Returns the image corresponding to this FloatingItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>captions</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>footnotes</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>image</code>               (<code>Optional[ImageRef]</code>)           \u2013            </li> <li> <code>label</code>               (<code>DocItemLabel</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>references</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.captions","title":"captions","text":"<pre><code>captions: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.footnotes","title":"footnotes","text":"<pre><code>footnotes: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.image","title":"image","text":"<pre><code>image: Optional[ImageRef] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.label","title":"label","text":"<pre><code>label: DocItemLabel\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.references","title":"references","text":"<pre><code>references: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.caption_text","title":"caption_text","text":"<pre><code>caption_text(doc: DoclingDocument) -&gt; str\n</code></pre> <p>Computes the caption as a single text.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image corresponding to this FloatingItem.</p> <p>This function returns the PIL image from self.image if one is available. Otherwise, it uses DocItem.get_image to get an image of this FloatingItem.</p> <p>In particular, when self.image is None, the function returns None if this FloatingItem has no valid provenance or the doc does not contain a valid image for the required page.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.FloatingItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem","title":"TextItem","text":"<p>               Bases: <code>DocItem</code></p> <p>TextItem.</p> <p>Methods:</p> <ul> <li> <code>export_to_document_tokens</code>             \u2013              <p>Export text element to document tokens format.</p> </li> <li> <code>get_image</code>             \u2013              <p>Returns the image of this DocItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>label</code>               (<code>Literal[CAPTION, CHECKBOX_SELECTED, CHECKBOX_UNSELECTED, CODE, FOOTNOTE, FORMULA, PAGE_FOOTER, PAGE_HEADER, PARAGRAPH, REFERENCE, TEXT, TITLE]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>orig</code>               (<code>str</code>)           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> <li> <code>text</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.label","title":"label","text":"<pre><code>label: Literal[\n    CAPTION,\n    CHECKBOX_SELECTED,\n    CHECKBOX_UNSELECTED,\n    CODE,\n    FOOTNOTE,\n    FORMULA,\n    PAGE_FOOTER,\n    PAGE_HEADER,\n    PARAGRAPH,\n    REFERENCE,\n    TEXT,\n    TITLE,\n]\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.orig","title":"orig","text":"<pre><code>orig: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.text","title":"text","text":"<pre><code>text: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.export_to_document_tokens","title":"export_to_document_tokens","text":"<pre><code>export_to_document_tokens(\n    doc: DoclingDocument,\n    new_line: str = \"\\n\",\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_content: bool = True,\n    add_page_index: bool = True,\n)\n</code></pre> <p>Export text element to document tokens format.</p> <p>:param doc: \"DoclingDocument\": :param new_line: str:  (Default value = \"\\n\") :param xsize: int:  (Default value = 100) :param ysize: int:  (Default value = 100) :param add_location: bool:  (Default value = True) :param add_content: bool:  (Default value = True) :param add_page_index: bool:  (Default value = True)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image of this DocItem.</p> <p>The function returns None if this DocItem has no valid provenance or if a valid image of the page containing this DocItem is not available in doc.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TextItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem","title":"TableItem","text":"<p>               Bases: <code>FloatingItem</code></p> <p>TableItem.</p> <p>Methods:</p> <ul> <li> <code>caption_text</code>             \u2013              <p>Computes the caption as a single text.</p> </li> <li> <code>export_to_dataframe</code>             \u2013              <p>Export the table as a Pandas DataFrame.</p> </li> <li> <code>export_to_document_tokens</code>             \u2013              <p>Export table to document tokens format.</p> </li> <li> <code>export_to_html</code>             \u2013              <p>Export the table as html.</p> </li> <li> <code>export_to_markdown</code>             \u2013              <p>Export the table as markdown.</p> </li> <li> <code>export_to_otsl</code>             \u2013              <p>Export the table as OTSL.</p> </li> <li> <code>get_image</code>             \u2013              <p>Returns the image corresponding to this FloatingItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>captions</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>data</code>               (<code>TableData</code>)           \u2013            </li> <li> <code>footnotes</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>image</code>               (<code>Optional[ImageRef]</code>)           \u2013            </li> <li> <code>label</code>               (<code>Literal[DOCUMENT_INDEX, TABLE]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>references</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.captions","title":"captions","text":"<pre><code>captions: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.data","title":"data","text":"<pre><code>data: TableData\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.footnotes","title":"footnotes","text":"<pre><code>footnotes: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.image","title":"image","text":"<pre><code>image: Optional[ImageRef] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.label","title":"label","text":"<pre><code>label: Literal[DOCUMENT_INDEX, TABLE] = TABLE\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.references","title":"references","text":"<pre><code>references: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.caption_text","title":"caption_text","text":"<pre><code>caption_text(doc: DoclingDocument) -&gt; str\n</code></pre> <p>Computes the caption as a single text.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.export_to_dataframe","title":"export_to_dataframe","text":"<pre><code>export_to_dataframe() -&gt; DataFrame\n</code></pre> <p>Export the table as a Pandas DataFrame.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.export_to_document_tokens","title":"export_to_document_tokens","text":"<pre><code>export_to_document_tokens(\n    doc: DoclingDocument,\n    new_line: str = \"\\n\",\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_caption: bool = True,\n    add_content: bool = True,\n    add_cell_location: bool = True,\n    add_cell_label: bool = True,\n    add_cell_text: bool = True,\n    add_page_index: bool = True,\n)\n</code></pre> <p>Export table to document tokens format.</p> <p>:param doc: \"DoclingDocument\": :param new_line: str:  (Default value = \"\\n\") :param xsize: int:  (Default value = 100) :param ysize: int:  (Default value = 100) :param add_location: bool:  (Default value = True) :param add_caption: bool:  (Default value = True) :param add_content: bool:  (Default value = True) :param add_cell_location: bool:  (Default value = True) :param add_cell_label: bool:  (Default value = True) :param add_cell_text: bool:  (Default value = True) :param add_page_index: bool:  (Default value = True)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.export_to_html","title":"export_to_html","text":"<pre><code>export_to_html(\n    doc: Optional[DoclingDocument] = None,\n    add_caption: bool = True,\n) -&gt; str\n</code></pre> <p>Export the table as html.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.export_to_markdown","title":"export_to_markdown","text":"<pre><code>export_to_markdown() -&gt; str\n</code></pre> <p>Export the table as markdown.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.export_to_otsl","title":"export_to_otsl","text":"<pre><code>export_to_otsl(\n    doc: DoclingDocument,\n    add_cell_location: bool = True,\n    add_cell_text: bool = True,\n    xsize: int = 100,\n    ysize: int = 100,\n) -&gt; str\n</code></pre> <p>Export the table as OTSL.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image corresponding to this FloatingItem.</p> <p>This function returns the PIL image from self.image if one is available. Otherwise, it uses DocItem.get_image to get an image of this FloatingItem.</p> <p>In particular, when self.image is None, the function returns None if this FloatingItem has no valid provenance or the doc does not contain a valid image for the required page.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell","title":"TableCell","text":"<p>               Bases: <code>BaseModel</code></p> <p>TableCell.</p> <p>Methods:</p> <ul> <li> <code>from_dict_format</code>             \u2013              <p>from_dict_format.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>bbox</code>               (<code>Optional[BoundingBox]</code>)           \u2013            </li> <li> <code>col_span</code>               (<code>int</code>)           \u2013            </li> <li> <code>column_header</code>               (<code>bool</code>)           \u2013            </li> <li> <code>end_col_offset_idx</code>               (<code>int</code>)           \u2013            </li> <li> <code>end_row_offset_idx</code>               (<code>int</code>)           \u2013            </li> <li> <code>row_header</code>               (<code>bool</code>)           \u2013            </li> <li> <code>row_section</code>               (<code>bool</code>)           \u2013            </li> <li> <code>row_span</code>               (<code>int</code>)           \u2013            </li> <li> <code>start_col_offset_idx</code>               (<code>int</code>)           \u2013            </li> <li> <code>start_row_offset_idx</code>               (<code>int</code>)           \u2013            </li> <li> <code>text</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.bbox","title":"bbox","text":"<pre><code>bbox: Optional[BoundingBox] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.col_span","title":"col_span","text":"<pre><code>col_span: int = 1\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.column_header","title":"column_header","text":"<pre><code>column_header: bool = False\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.end_col_offset_idx","title":"end_col_offset_idx","text":"<pre><code>end_col_offset_idx: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.end_row_offset_idx","title":"end_row_offset_idx","text":"<pre><code>end_row_offset_idx: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.row_header","title":"row_header","text":"<pre><code>row_header: bool = False\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.row_section","title":"row_section","text":"<pre><code>row_section: bool = False\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.row_span","title":"row_span","text":"<pre><code>row_span: int = 1\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.start_col_offset_idx","title":"start_col_offset_idx","text":"<pre><code>start_col_offset_idx: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.start_row_offset_idx","title":"start_row_offset_idx","text":"<pre><code>start_row_offset_idx: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.text","title":"text","text":"<pre><code>text: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCell.from_dict_format","title":"from_dict_format","text":"<pre><code>from_dict_format(data: Any) -&gt; Any\n</code></pre> <p>from_dict_format.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableData","title":"TableData","text":"<p>               Bases: <code>BaseModel</code></p> <p>BaseTableData.</p> <p>Attributes:</p> <ul> <li> <code>grid</code>               (<code>List[List[TableCell]]</code>)           \u2013            <p>grid.</p> </li> <li> <code>num_cols</code>               (<code>int</code>)           \u2013            </li> <li> <code>num_rows</code>               (<code>int</code>)           \u2013            </li> <li> <code>table_cells</code>               (<code>List[TableCell]</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.TableData.grid","title":"grid","text":"<pre><code>grid: List[List[TableCell]]\n</code></pre> <p>grid.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.TableData.num_cols","title":"num_cols","text":"<pre><code>num_cols: int = 0\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableData.num_rows","title":"num_rows","text":"<pre><code>num_rows: int = 0\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableData.table_cells","title":"table_cells","text":"<pre><code>table_cells: List[TableCell] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCellLabel","title":"TableCellLabel","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>TableCellLabel.</p> <p>Attributes:</p> <ul> <li> <code>BODY</code>           \u2013            </li> <li> <code>COLUMN_HEADER</code>           \u2013            </li> <li> <code>ROW_HEADER</code>           \u2013            </li> <li> <code>ROW_SECTION</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCellLabel.BODY","title":"BODY","text":"<pre><code>BODY = 'body'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCellLabel.COLUMN_HEADER","title":"COLUMN_HEADER","text":"<pre><code>COLUMN_HEADER = 'col_header'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCellLabel.ROW_HEADER","title":"ROW_HEADER","text":"<pre><code>ROW_HEADER = 'row_header'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.TableCellLabel.ROW_SECTION","title":"ROW_SECTION","text":"<pre><code>ROW_SECTION = 'row_section'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem","title":"KeyValueItem","text":"<p>               Bases: <code>DocItem</code></p> <p>KeyValueItem.</p> <p>Methods:</p> <ul> <li> <code>get_image</code>             \u2013              <p>Returns the image of this DocItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>label</code>               (<code>Literal[KEY_VALUE_REGION]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.label","title":"label","text":"<pre><code>label: Literal[KEY_VALUE_REGION] = KEY_VALUE_REGION\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image of this DocItem.</p> <p>The function returns None if this DocItem has no valid provenance or if a valid image of the page containing this DocItem is not available in doc.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.KeyValueItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem","title":"SectionHeaderItem","text":"<p>               Bases: <code>TextItem</code></p> <p>SectionItem.</p> <p>Methods:</p> <ul> <li> <code>export_to_document_tokens</code>             \u2013              <p>Export text element to document tokens format.</p> </li> <li> <code>get_image</code>             \u2013              <p>Returns the image of this DocItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>label</code>               (<code>Literal[SECTION_HEADER]</code>)           \u2013            </li> <li> <code>level</code>               (<code>LevelNumber</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>orig</code>               (<code>str</code>)           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> <li> <code>text</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.label","title":"label","text":"<pre><code>label: Literal[SECTION_HEADER] = SECTION_HEADER\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.level","title":"level","text":"<pre><code>level: LevelNumber = 1\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.orig","title":"orig","text":"<pre><code>orig: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.text","title":"text","text":"<pre><code>text: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.export_to_document_tokens","title":"export_to_document_tokens","text":"<pre><code>export_to_document_tokens(\n    doc: DoclingDocument,\n    new_line: str = \"\\n\",\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_content: bool = True,\n    add_page_index: bool = True,\n)\n</code></pre> <p>Export text element to document tokens format.</p> <p>:param doc: \"DoclingDocument\": :param new_line: str:  (Default value = \"\\n\") :param xsize: int:  (Default value = 100) :param ysize: int:  (Default value = 100) :param add_location: bool:  (Default value = True) :param add_content: bool:  (Default value = True) :param add_page_index: bool:  (Default value = True)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image of this DocItem.</p> <p>The function returns None if this DocItem has no valid provenance or if a valid image of the page containing this DocItem is not available in doc.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.SectionHeaderItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem","title":"PictureItem","text":"<p>               Bases: <code>FloatingItem</code></p> <p>PictureItem.</p> <p>Methods:</p> <ul> <li> <code>caption_text</code>             \u2013              <p>Computes the caption as a single text.</p> </li> <li> <code>export_to_document_tokens</code>             \u2013              <p>Export picture to document tokens format.</p> </li> <li> <code>export_to_html</code>             \u2013              <p>Export picture to HTML format.</p> </li> <li> <code>export_to_markdown</code>             \u2013              <p>Export picture to Markdown format.</p> </li> <li> <code>get_image</code>             \u2013              <p>Returns the image corresponding to this FloatingItem.</p> </li> <li> <code>get_location_tokens</code>             \u2013              <p>Get the location string for the BaseCell.</p> </li> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>annotations</code>               (<code>List[PictureDataType]</code>)           \u2013            </li> <li> <code>captions</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>children</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>footnotes</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>image</code>               (<code>Optional[ImageRef]</code>)           \u2013            </li> <li> <code>label</code>               (<code>Literal[PICTURE]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>parent</code>               (<code>Optional[RefItem]</code>)           \u2013            </li> <li> <code>prov</code>               (<code>List[ProvenanceItem]</code>)           \u2013            </li> <li> <code>references</code>               (<code>List[RefItem]</code>)           \u2013            </li> <li> <code>self_ref</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.annotations","title":"annotations","text":"<pre><code>annotations: List[PictureDataType] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.captions","title":"captions","text":"<pre><code>captions: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.children","title":"children","text":"<pre><code>children: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.footnotes","title":"footnotes","text":"<pre><code>footnotes: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.image","title":"image","text":"<pre><code>image: Optional[ImageRef] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.label","title":"label","text":"<pre><code>label: Literal[PICTURE] = PICTURE\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.parent","title":"parent","text":"<pre><code>parent: Optional[RefItem] = None\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.prov","title":"prov","text":"<pre><code>prov: List[ProvenanceItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.references","title":"references","text":"<pre><code>references: List[RefItem] = []\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.self_ref","title":"self_ref","text":"<pre><code>self_ref: str = Field(pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.caption_text","title":"caption_text","text":"<pre><code>caption_text(doc: DoclingDocument) -&gt; str\n</code></pre> <p>Computes the caption as a single text.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.export_to_document_tokens","title":"export_to_document_tokens","text":"<pre><code>export_to_document_tokens(\n    doc: DoclingDocument,\n    new_line: str = \"\\n\",\n    xsize: int = 100,\n    ysize: int = 100,\n    add_location: bool = True,\n    add_caption: bool = True,\n    add_content: bool = True,\n    add_page_index: bool = True,\n)\n</code></pre> <p>Export picture to document tokens format.</p> <p>:param doc: \"DoclingDocument\": :param new_line: str:  (Default value = \"\\n\") :param xsize: int:  (Default value = 100) :param ysize: int:  (Default value = 100) :param add_location: bool:  (Default value = True) :param add_caption: bool:  (Default value = True) :param add_content: bool:  (Default value = True) :param # not used at the momentadd_page_index: bool:  (Default value = True)</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.export_to_html","title":"export_to_html","text":"<pre><code>export_to_html(\n    doc: DoclingDocument,\n    add_caption: bool = True,\n    image_mode: ImageRefMode = PLACEHOLDER,\n) -&gt; str\n</code></pre> <p>Export picture to HTML format.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.export_to_markdown","title":"export_to_markdown","text":"<pre><code>export_to_markdown(\n    doc: DoclingDocument,\n    add_caption: bool = True,\n    image_mode: ImageRefMode = EMBEDDED,\n    image_placeholder: str = \"&lt;!-- image --&gt;\",\n) -&gt; str\n</code></pre> <p>Export picture to Markdown format.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.get_image","title":"get_image","text":"<pre><code>get_image(doc: DoclingDocument) -&gt; Optional[Image]\n</code></pre> <p>Returns the image corresponding to this FloatingItem.</p> <p>This function returns the PIL image from self.image if one is available. Otherwise, it uses DocItem.get_image to get an image of this FloatingItem.</p> <p>In particular, when self.image is None, the function returns None if this FloatingItem has no valid provenance or the doc does not contain a valid image for the required page.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.get_location_tokens","title":"get_location_tokens","text":"<pre><code>get_location_tokens(\n    doc: DoclingDocument,\n    new_line: str,\n    xsize: int = 100,\n    ysize: int = 100,\n    add_page_index: bool = True,\n) -&gt; str\n</code></pre> <p>Get the location string for the BaseCell.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef","title":"ImageRef","text":"<p>               Bases: <code>BaseModel</code></p> <p>ImageRef.</p> <p>Methods:</p> <ul> <li> <code>from_pil</code>             \u2013              <p>Construct ImageRef from a PIL Image.</p> </li> <li> <code>validate_mimetype</code>             \u2013              <p>validate_mimetype.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>dpi</code>               (<code>int</code>)           \u2013            </li> <li> <code>mimetype</code>               (<code>str</code>)           \u2013            </li> <li> <code>pil_image</code>               (<code>Optional[Image]</code>)           \u2013            <p>Return the PIL Image.</p> </li> <li> <code>size</code>               (<code>Size</code>)           \u2013            </li> <li> <code>uri</code>               (<code>Union[AnyUrl, Path]</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.dpi","title":"dpi","text":"<pre><code>dpi: int\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.mimetype","title":"mimetype","text":"<pre><code>mimetype: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.pil_image","title":"pil_image","text":"<pre><code>pil_image: Optional[Image]\n</code></pre> <p>Return the PIL Image.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.size","title":"size","text":"<pre><code>size: Size\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.uri","title":"uri","text":"<pre><code>uri: Union[AnyUrl, Path] = Field(union_mode=\"left_to_right\")\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.from_pil","title":"from_pil","text":"<pre><code>from_pil(image: Image, dpi: int) -&gt; Self\n</code></pre> <p>Construct ImageRef from a PIL Image.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRef.validate_mimetype","title":"validate_mimetype","text":"<pre><code>validate_mimetype(v)\n</code></pre> <p>validate_mimetype.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationClass","title":"PictureClassificationClass","text":"<p>               Bases: <code>BaseModel</code></p> <p>PictureClassificationData.</p> <p>Attributes:</p> <ul> <li> <code>class_name</code>               (<code>str</code>)           \u2013            </li> <li> <code>confidence</code>               (<code>float</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationClass.class_name","title":"class_name","text":"<pre><code>class_name: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationClass.confidence","title":"confidence","text":"<pre><code>confidence: float\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationData","title":"PictureClassificationData","text":"<p>               Bases: <code>BasePictureData</code></p> <p>PictureClassificationData.</p> <p>Attributes:</p> <ul> <li> <code>kind</code>               (<code>Literal['classification']</code>)           \u2013            </li> <li> <code>predicted_classes</code>               (<code>List[PictureClassificationClass]</code>)           \u2013            </li> <li> <code>provenance</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationData.kind","title":"kind","text":"<pre><code>kind: Literal['classification'] = 'classification'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationData.predicted_classes","title":"predicted_classes","text":"<pre><code>predicted_classes: List[PictureClassificationClass]\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.PictureClassificationData.provenance","title":"provenance","text":"<pre><code>provenance: str\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.RefItem","title":"RefItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>RefItem.</p> <p>Methods:</p> <ul> <li> <code>get_ref</code>             \u2013              <p>get_ref.</p> </li> <li> <code>resolve</code>             \u2013              <p>resolve.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>cref</code>               (<code>str</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.RefItem.cref","title":"cref","text":"<pre><code>cref: str = Field(alias=\"$ref\", pattern=_JSON_POINTER_REGEX)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.RefItem.model_config","title":"model_config","text":"<pre><code>model_config = ConfigDict(populate_by_name=True)\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.RefItem.get_ref","title":"get_ref","text":"<pre><code>get_ref()\n</code></pre> <p>get_ref.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.RefItem.resolve","title":"resolve","text":"<pre><code>resolve(doc: DoclingDocument)\n</code></pre> <p>resolve.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox","title":"BoundingBox","text":"<p>               Bases: <code>BaseModel</code></p> <p>BoundingBox.</p> <p>Methods:</p> <ul> <li> <code>area</code>             \u2013              <p>area.</p> </li> <li> <code>as_tuple</code>             \u2013              <p>as_tuple.</p> </li> <li> <code>from_tuple</code>             \u2013              <p>from_tuple.</p> </li> <li> <code>intersection_area_with</code>             \u2013              <p>intersection_area_with.</p> </li> <li> <code>normalized</code>             \u2013              <p>normalized.</p> </li> <li> <code>scaled</code>             \u2013              <p>scaled.</p> </li> <li> <code>to_bottom_left_origin</code>             \u2013              <p>to_bottom_left_origin.</p> </li> <li> <code>to_top_left_origin</code>             \u2013              <p>to_top_left_origin.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>b</code>               (<code>float</code>)           \u2013            </li> <li> <code>coord_origin</code>               (<code>CoordOrigin</code>)           \u2013            </li> <li> <code>height</code>           \u2013            <p>height.</p> </li> <li> <code>l</code>               (<code>float</code>)           \u2013            </li> <li> <code>r</code>               (<code>float</code>)           \u2013            </li> <li> <code>t</code>               (<code>float</code>)           \u2013            </li> <li> <code>width</code>           \u2013            <p>width.</p> </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.b","title":"b","text":"<pre><code>b: float\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.coord_origin","title":"coord_origin","text":"<pre><code>coord_origin: CoordOrigin = TOPLEFT\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.height","title":"height","text":"<pre><code>height\n</code></pre> <p>height.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.l","title":"l","text":"<pre><code>l: float\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.r","title":"r","text":"<pre><code>r: float\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.t","title":"t","text":"<pre><code>t: float\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.width","title":"width","text":"<pre><code>width\n</code></pre> <p>width.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.area","title":"area","text":"<pre><code>area() -&gt; float\n</code></pre> <p>area.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.as_tuple","title":"as_tuple","text":"<pre><code>as_tuple()\n</code></pre> <p>as_tuple.</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.from_tuple","title":"from_tuple","text":"<pre><code>from_tuple(coord: Tuple[float, ...], origin: CoordOrigin)\n</code></pre> <p>from_tuple.</p> <p>:param coord: Tuple[float: :param ...]: :param origin: CoordOrigin:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.intersection_area_with","title":"intersection_area_with","text":"<pre><code>intersection_area_with(other: BoundingBox) -&gt; float\n</code></pre> <p>intersection_area_with.</p> <p>:param other: \"BoundingBox\":</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.normalized","title":"normalized","text":"<pre><code>normalized(page_size: Size) -&gt; BoundingBox\n</code></pre> <p>normalized.</p> <p>:param page_size: Size:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.scaled","title":"scaled","text":"<pre><code>scaled(scale: float) -&gt; BoundingBox\n</code></pre> <p>scaled.</p> <p>:param scale: float:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.to_bottom_left_origin","title":"to_bottom_left_origin","text":"<pre><code>to_bottom_left_origin(page_height) -&gt; BoundingBox\n</code></pre> <p>to_bottom_left_origin.</p> <p>:param page_height:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.BoundingBox.to_top_left_origin","title":"to_top_left_origin","text":"<pre><code>to_top_left_origin(page_height)\n</code></pre> <p>to_top_left_origin.</p> <p>:param page_height:</p>"},{"location":"reference/docling_document/#docling_core.types.doc.CoordOrigin","title":"CoordOrigin","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>CoordOrigin.</p> <p>Attributes:</p> <ul> <li> <code>BOTTOMLEFT</code>           \u2013            </li> <li> <code>TOPLEFT</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.CoordOrigin.BOTTOMLEFT","title":"BOTTOMLEFT","text":"<pre><code>BOTTOMLEFT = 'BOTTOMLEFT'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.CoordOrigin.TOPLEFT","title":"TOPLEFT","text":"<pre><code>TOPLEFT = 'TOPLEFT'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRefMode","title":"ImageRefMode","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>ImageRefMode.</p> <p>Attributes:</p> <ul> <li> <code>EMBEDDED</code>           \u2013            </li> <li> <code>PLACEHOLDER</code>           \u2013            </li> <li> <code>REFERENCED</code>           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRefMode.EMBEDDED","title":"EMBEDDED","text":"<pre><code>EMBEDDED = 'embedded'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRefMode.PLACEHOLDER","title":"PLACEHOLDER","text":"<pre><code>PLACEHOLDER = 'placeholder'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.ImageRefMode.REFERENCED","title":"REFERENCED","text":"<pre><code>REFERENCED = 'referenced'\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.Size","title":"Size","text":"<p>               Bases: <code>BaseModel</code></p> <p>Size.</p> <p>Methods:</p> <ul> <li> <code>as_tuple</code>             \u2013              <p>as_tuple.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>height</code>               (<code>float</code>)           \u2013            </li> <li> <code>width</code>               (<code>float</code>)           \u2013            </li> </ul>"},{"location":"reference/docling_document/#docling_core.types.doc.Size.height","title":"height","text":"<pre><code>height: float = 0.0\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.Size.width","title":"width","text":"<pre><code>width: float = 0.0\n</code></pre>"},{"location":"reference/docling_document/#docling_core.types.doc.Size.as_tuple","title":"as_tuple","text":"<pre><code>as_tuple()\n</code></pre> <p>as_tuple.</p>"},{"location":"reference/document_converter/","title":"Document converter","text":"<p>This is an automatic generated API reference of the main components of Docling.</p>"},{"location":"reference/document_converter/#docowling.document_converter","title":"document_converter","text":"<p>Classes:</p> <ul> <li> <code>DocumentConverter</code>           \u2013            </li> <li> <code>ConversionResult</code>           \u2013            </li> <li> <code>ConversionStatus</code>           \u2013            </li> <li> <code>FormatOption</code>           \u2013            </li> <li> <code>InputFormat</code>           \u2013            <p>A document format supported by document backend parsers.</p> </li> <li> <code>PdfFormatOption</code>           \u2013            </li> <li> <code>ImageFormatOption</code>           \u2013            </li> <li> <code>StandardPdfPipeline</code>           \u2013            </li> <li> <code>WordFormatOption</code>           \u2013            </li> <li> <code>PowerpointFormatOption</code>           \u2013            </li> <li> <code>MarkdownFormatOption</code>           \u2013            </li> <li> <code>AsciiDocFormatOption</code>           \u2013            </li> <li> <code>HTMLFormatOption</code>           \u2013            </li> <li> <code>SimplePipeline</code>           \u2013            <p>SimpleModelPipeline.</p> </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter","title":"DocumentConverter","text":"<pre><code>DocumentConverter(\n    allowed_formats: Optional[List[InputFormat]] = None,\n    format_options: Optional[\n        Dict[InputFormat, FormatOption]\n    ] = None,\n)\n</code></pre> <p>Methods:</p> <ul> <li> <code>convert</code>             \u2013              </li> <li> <code>convert_all</code>             \u2013              </li> <li> <code>initialize_pipeline</code>             \u2013              <p>Initialize the conversion pipeline for the selected format.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>allowed_formats</code>           \u2013            </li> <li> <code>format_to_options</code>           \u2013            </li> <li> <code>initialized_pipelines</code>               (<code>Dict[Type[BasePipeline], BasePipeline]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.allowed_formats","title":"allowed_formats  <code>instance-attribute</code>","text":"<pre><code>allowed_formats = (\n    allowed_formats\n    if allowed_formats is not None\n    else [e for e in InputFormat]\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.format_to_options","title":"format_to_options  <code>instance-attribute</code>","text":"<pre><code>format_to_options = {format: _get_default_option(format=format) if (custom_option := get(format)) is None else _hG2m5hLRDgBmfor format in allowed_formats}\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.initialized_pipelines","title":"initialized_pipelines  <code>instance-attribute</code>","text":"<pre><code>initialized_pipelines: Dict[\n    Type[BasePipeline], BasePipeline\n] = {}\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.convert","title":"convert","text":"<pre><code>convert(\n    source: Union[Path, str, DocumentStream],\n    raises_on_error: bool = True,\n    max_num_pages: int = maxsize,\n    max_file_size: int = maxsize,\n) -&gt; ConversionResult\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.convert_all","title":"convert_all","text":"<pre><code>convert_all(\n    source: Iterable[Union[Path, str, DocumentStream]],\n    raises_on_error: bool = True,\n    max_num_pages: int = maxsize,\n    max_file_size: int = maxsize,\n) -&gt; Iterator[ConversionResult]\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.DocumentConverter.initialize_pipeline","title":"initialize_pipeline","text":"<pre><code>initialize_pipeline(format: InputFormat)\n</code></pre> <p>Initialize the conversion pipeline for the selected format.</p>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult","title":"ConversionResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> <ul> <li> <code>assembled</code>               (<code>AssembledUnit</code>)           \u2013            </li> <li> <code>document</code>               (<code>DoclingDocument</code>)           \u2013            </li> <li> <code>errors</code>               (<code>List[ErrorItem]</code>)           \u2013            </li> <li> <code>input</code>               (<code>InputDocument</code>)           \u2013            </li> <li> <code>legacy_document</code>           \u2013            </li> <li> <code>pages</code>               (<code>List[Page]</code>)           \u2013            </li> <li> <code>status</code>               (<code>ConversionStatus</code>)           \u2013            </li> <li> <code>timings</code>               (<code>Dict[str, ProfilingItem]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.assembled","title":"assembled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>assembled: AssembledUnit = AssembledUnit()\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.document","title":"document  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>document: DoclingDocument = _EMPTY_DOCLING_DOC\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.errors","title":"errors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>errors: List[ErrorItem] = []\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: InputDocument\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.legacy_document","title":"legacy_document  <code>property</code>","text":"<pre><code>legacy_document\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.pages","title":"pages  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pages: List[Page] = []\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status: ConversionStatus = PENDING\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionResult.timings","title":"timings  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timings: Dict[str, ProfilingItem] = {}\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus","title":"ConversionStatus","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Attributes:</p> <ul> <li> <code>FAILURE</code>           \u2013            </li> <li> <code>PARTIAL_SUCCESS</code>           \u2013            </li> <li> <code>PENDING</code>           \u2013            </li> <li> <code>SKIPPED</code>           \u2013            </li> <li> <code>STARTED</code>           \u2013            </li> <li> <code>SUCCESS</code>           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.FAILURE","title":"FAILURE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILURE = 'failure'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.PARTIAL_SUCCESS","title":"PARTIAL_SUCCESS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PARTIAL_SUCCESS = 'partial_success'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.PENDING","title":"PENDING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PENDING = 'pending'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.SKIPPED","title":"SKIPPED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIPPED = 'skipped'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.STARTED","title":"STARTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STARTED = 'started'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ConversionStatus.SUCCESS","title":"SUCCESS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SUCCESS = 'success'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption","title":"FormatOption","text":"<p>               Bases: <code>BaseModel</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type[BasePipeline]</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption.backend","title":"backend  <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend]\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption.pipeline_cls","title":"pipeline_cls  <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type[BasePipeline]\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.FormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat","title":"InputFormat","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>A document format supported by document backend parsers.</p> <p>Attributes:</p> <ul> <li> <code>ASCIIDOC</code>           \u2013            </li> <li> <code>CSV</code>           \u2013            </li> <li> <code>DOCX</code>           \u2013            </li> <li> <code>HTML</code>           \u2013            </li> <li> <code>IMAGE</code>           \u2013            </li> <li> <code>MD</code>           \u2013            </li> <li> <code>PDF</code>           \u2013            </li> <li> <code>PPTX</code>           \u2013            </li> <li> <code>XLSX</code>           \u2013            </li> <li> <code>XML_PUBMED</code>           \u2013            </li> <li> <code>XML_USPTO</code>           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.ASCIIDOC","title":"ASCIIDOC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ASCIIDOC = 'asciidoc'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.CSV","title":"CSV  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CSV = 'csv'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.DOCX","title":"DOCX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOCX = 'docx'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.HTML","title":"HTML  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HTML = 'html'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.IMAGE","title":"IMAGE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IMAGE = 'image'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.MD","title":"MD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MD = 'md'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.PDF","title":"PDF  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PDF = 'pdf'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.PPTX","title":"PPTX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PPTX = 'pptx'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.XLSX","title":"XLSX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XLSX = 'xlsx'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.XML_PUBMED","title":"XML_PUBMED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XML_PUBMED = 'xml_pubmed'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.InputFormat.XML_USPTO","title":"XML_USPTO  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XML_USPTO = 'xml_uspto'\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption","title":"PdfFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = (\n    DoclingParseV2DocumentBackend\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = StandardPdfPipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PdfFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption","title":"ImageFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = (\n    DoclingParseV2DocumentBackend\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = StandardPdfPipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.ImageFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline","title":"StandardPdfPipeline","text":"<pre><code>StandardPdfPipeline(pipeline_options: PdfPipelineOptions)\n</code></pre> <p>               Bases: <code>PaginatedPipeline</code></p> <p>Methods:</p> <ul> <li> <code>download_models_hf</code>             \u2013              </li> <li> <code>execute</code>             \u2013              </li> <li> <code>get_default_options</code>             \u2013              </li> <li> <code>get_ocr_model</code>             \u2013              </li> <li> <code>initialize_page</code>             \u2013              </li> <li> <code>is_backend_supported</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>artifacts_path</code>           \u2013            </li> <li> <code>build_pipe</code>           \u2013            </li> <li> <code>enrichment_pipe</code>           \u2013            </li> <li> <code>glm_model</code>           \u2013            </li> <li> <code>pipeline_options</code>               (<code>PdfPipelineOptions</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.artifacts_path","title":"artifacts_path  <code>instance-attribute</code>","text":"<pre><code>artifacts_path = download_models_hf()\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.build_pipe","title":"build_pipe  <code>instance-attribute</code>","text":"<pre><code>build_pipe = [\n    PagePreprocessingModel(\n        options=PagePreprocessingOptions(\n            images_scale=images_scale\n        )\n    ),\n    ocr_model,\n    LayoutModel(\n        artifacts_path=artifacts_path / _layout_model_path,\n        accelerator_options=accelerator_options,\n    ),\n    TableStructureModel(\n        enabled=do_table_structure,\n        artifacts_path=artifacts_path / _table_model_path,\n        options=table_structure_options,\n        accelerator_options=accelerator_options,\n    ),\n    PageAssembleModel(\n        options=PageAssembleOptions(keep_images=keep_images)\n    ),\n]\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.enrichment_pipe","title":"enrichment_pipe  <code>instance-attribute</code>","text":"<pre><code>enrichment_pipe = []\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.glm_model","title":"glm_model  <code>instance-attribute</code>","text":"<pre><code>glm_model = GlmModel(options=GlmOptions())\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.pipeline_options","title":"pipeline_options  <code>instance-attribute</code>","text":"<pre><code>pipeline_options: PdfPipelineOptions\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.download_models_hf","title":"download_models_hf  <code>staticmethod</code>","text":"<pre><code>download_models_hf(\n    local_dir: Optional[Path] = None, force: bool = False\n) -&gt; Path\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.execute","title":"execute","text":"<pre><code>execute(\n    in_doc: InputDocument, raises_on_error: bool\n) -&gt; ConversionResult\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.get_default_options","title":"get_default_options  <code>classmethod</code>","text":"<pre><code>get_default_options() -&gt; PdfPipelineOptions\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.get_ocr_model","title":"get_ocr_model","text":"<pre><code>get_ocr_model() -&gt; Optional[BaseOcrModel]\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.initialize_page","title":"initialize_page","text":"<pre><code>initialize_page(\n    conv_res: ConversionResult, page: Page\n) -&gt; Page\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.StandardPdfPipeline.is_backend_supported","title":"is_backend_supported  <code>classmethod</code>","text":"<pre><code>is_backend_supported(backend: AbstractDocumentBackend)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption","title":"WordFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = (\n    MsWordDocumentBackend\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = SimplePipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.WordFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption","title":"PowerpointFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = (\n    MsPowerpointDocumentBackend\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = SimplePipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.PowerpointFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption","title":"MarkdownFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = (\n    MarkdownDocumentBackend\n)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = SimplePipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.MarkdownFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption","title":"AsciiDocFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = AsciiDocBackend\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = SimplePipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.AsciiDocFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption","title":"HTMLFormatOption","text":"<p>               Bases: <code>FormatOption</code></p> <p>Methods:</p> <ul> <li> <code>set_optional_field_default</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>backend</code>               (<code>Type[AbstractDocumentBackend]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>pipeline_cls</code>               (<code>Type</code>)           \u2013            </li> <li> <code>pipeline_options</code>               (<code>Optional[PipelineOptions]</code>)           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption.backend","title":"backend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backend: Type[AbstractDocumentBackend] = HTMLDocumentBackend\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption.pipeline_cls","title":"pipeline_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_cls: Type = SimplePipeline\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption.pipeline_options","title":"pipeline_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline_options: Optional[PipelineOptions] = None\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.HTMLFormatOption.set_optional_field_default","title":"set_optional_field_default","text":"<pre><code>set_optional_field_default() -&gt; FormatOption\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline","title":"SimplePipeline","text":"<pre><code>SimplePipeline(pipeline_options: PipelineOptions)\n</code></pre> <p>               Bases: <code>BasePipeline</code></p> <p>SimpleModelPipeline.</p> <p>This class is used at the moment for formats / backends which produce straight DoclingDocument output.</p> <p>Methods:</p> <ul> <li> <code>execute</code>             \u2013              </li> <li> <code>get_default_options</code>             \u2013              </li> <li> <code>is_backend_supported</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>build_pipe</code>               (<code>List[Callable]</code>)           \u2013            </li> <li> <code>enrichment_pipe</code>               (<code>List[BaseEnrichmentModel]</code>)           \u2013            </li> <li> <code>pipeline_options</code>           \u2013            </li> </ul>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.build_pipe","title":"build_pipe  <code>instance-attribute</code>","text":"<pre><code>build_pipe: List[Callable] = []\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.enrichment_pipe","title":"enrichment_pipe  <code>instance-attribute</code>","text":"<pre><code>enrichment_pipe: List[BaseEnrichmentModel] = []\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.pipeline_options","title":"pipeline_options  <code>instance-attribute</code>","text":"<pre><code>pipeline_options = pipeline_options\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.execute","title":"execute","text":"<pre><code>execute(\n    in_doc: InputDocument, raises_on_error: bool\n) -&gt; ConversionResult\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.get_default_options","title":"get_default_options  <code>classmethod</code>","text":"<pre><code>get_default_options() -&gt; PipelineOptions\n</code></pre>"},{"location":"reference/document_converter/#docowling.document_converter.SimplePipeline.is_backend_supported","title":"is_backend_supported  <code>classmethod</code>","text":"<pre><code>is_backend_supported(backend: AbstractDocumentBackend)\n</code></pre>"},{"location":"reference/pipeline_options/","title":"Pipeline options","text":"<p>Pipeline options allow to customize the execution of the models during the conversion pipeline. This includes options for the OCR engines, the table model as well as enrichment options which can be enabled with <code>do_xyz = True</code>.</p> <p>This is an automatic generated API reference of the all the pipeline options available in Docling.</p>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options","title":"pipeline_options","text":"<p>Classes:</p> <ul> <li> <code>AcceleratorDevice</code>           \u2013            <p>Devices to run model inference</p> </li> <li> <code>AcceleratorOptions</code>           \u2013            </li> <li> <code>EasyOcrOptions</code>           \u2013            <p>Options for the EasyOCR engine.</p> </li> <li> <code>OcrEngine</code>           \u2013            <p>Enum of valid OCR engines.</p> </li> <li> <code>OcrMacOptions</code>           \u2013            <p>Options for the Mac OCR engine.</p> </li> <li> <code>OcrOptions</code>           \u2013            <p>OCR options.</p> </li> <li> <code>PdfBackend</code>           \u2013            <p>Enum of valid PDF backends.</p> </li> <li> <code>PdfPipelineOptions</code>           \u2013            <p>Options for the PDF pipeline.</p> </li> <li> <code>PipelineOptions</code>           \u2013            <p>Base pipeline options.</p> </li> <li> <code>RapidOcrOptions</code>           \u2013            <p>Options for the RapidOCR engine.</p> </li> <li> <code>TableFormerMode</code>           \u2013            <p>Modes for the TableFormer model.</p> </li> <li> <code>TableStructureOptions</code>           \u2013            <p>Options for the table structure.</p> </li> <li> <code>TesseractCliOcrOptions</code>           \u2013            <p>Options for the TesseractCli engine.</p> </li> <li> <code>TesseractOcrOptions</code>           \u2013            <p>Options for the Tesseract engine.</p> </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorDevice","title":"AcceleratorDevice","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Devices to run model inference</p> <p>Attributes:</p> <ul> <li> <code>AUTO</code>           \u2013            </li> <li> <code>CPU</code>           \u2013            </li> <li> <code>CUDA</code>           \u2013            </li> <li> <code>MPS</code>           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorDevice.AUTO","title":"AUTO  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>AUTO = 'auto'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorDevice.CPU","title":"CPU  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CPU = 'cpu'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorDevice.CUDA","title":"CUDA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CUDA = 'cuda'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorDevice.MPS","title":"MPS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MPS = 'mps'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorOptions","title":"AcceleratorOptions","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Methods:</p> <ul> <li> <code>check_alternative_envvars</code>             \u2013              <p>Set num_threads from the \"alternative\" envvar OMP_NUM_THREADS.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>device</code>               (<code>AcceleratorDevice</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>num_threads</code>               (<code>int</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorOptions.device","title":"device  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>device: AcceleratorDevice = AUTO\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = SettingsConfigDict(\n    env_prefix=\"DOCLING_\",\n    env_nested_delimiter=\"_\",\n    populate_by_name=True,\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorOptions.num_threads","title":"num_threads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>num_threads: int = 4\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.AcceleratorOptions.check_alternative_envvars","title":"check_alternative_envvars  <code>classmethod</code>","text":"<pre><code>check_alternative_envvars(data: Any) -&gt; Any\n</code></pre> <p>Set num_threads from the \"alternative\" envvar OMP_NUM_THREADS. The alternative envvar is used only if it is valid and the regular envvar is not set.</p> <p>Notice: The standard pydantic settings mechanism with parameter \"aliases\" does not provide the same functionality. In case the alias envvar is set and the user tries to override the parameter in settings initialization, Pydantic treats the parameter provided in init() as an extra input instead of simply overwriting the evvar value for that parameter.</p>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions","title":"EasyOcrOptions","text":"<p>               Bases: <code>OcrOptions</code></p> <p>Options for the EasyOCR engine.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>confidence_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>download_enabled</code>               (<code>bool</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>kind</code>               (<code>Literal['easyocr']</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>model_storage_directory</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>recog_network</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>use_gpu</code>               (<code>Optional[bool]</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.confidence_threshold","title":"confidence_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>confidence_threshold: float = 0.65\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.download_enabled","title":"download_enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>download_enabled: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind: Literal['easyocr'] = 'easyocr'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.lang","title":"lang  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lang: List[str] = ['fr', 'de', 'es', 'en']\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    extra=\"forbid\", protected_namespaces=()\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.model_storage_directory","title":"model_storage_directory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_storage_directory: Optional[str] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.recog_network","title":"recog_network  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>recog_network: Optional[str] = 'standard'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.EasyOcrOptions.use_gpu","title":"use_gpu  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_gpu: Optional[bool] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine","title":"OcrEngine","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum of valid OCR engines.</p> <p>Attributes:</p> <ul> <li> <code>EASYOCR</code>           \u2013            </li> <li> <code>OCRMAC</code>           \u2013            </li> <li> <code>RAPIDOCR</code>           \u2013            </li> <li> <code>TESSERACT</code>           \u2013            </li> <li> <code>TESSERACT_CLI</code>           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine.EASYOCR","title":"EASYOCR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EASYOCR = 'easyocr'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine.OCRMAC","title":"OCRMAC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OCRMAC = 'ocrmac'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine.RAPIDOCR","title":"RAPIDOCR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RAPIDOCR = 'rapidocr'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine.TESSERACT","title":"TESSERACT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TESSERACT = 'tesseract'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrEngine.TESSERACT_CLI","title":"TESSERACT_CLI  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TESSERACT_CLI = 'tesseract_cli'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions","title":"OcrMacOptions","text":"<p>               Bases: <code>OcrOptions</code></p> <p>Options for the Mac OCR engine.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>framework</code>               (<code>str</code>)           \u2013            </li> <li> <code>kind</code>               (<code>Literal['ocrmac']</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>recognition</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.framework","title":"framework  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>framework: str = 'vision'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind: Literal['ocrmac'] = 'ocrmac'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.lang","title":"lang  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lang: List[str] = ['fr-FR', 'de-DE', 'es-ES', 'en-US']\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrMacOptions.recognition","title":"recognition  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>recognition: str = 'accurate'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrOptions","title":"OcrOptions","text":"<p>               Bases: <code>BaseModel</code></p> <p>OCR options.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>kind</code>               (<code>str</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrOptions.kind","title":"kind  <code>instance-attribute</code>","text":"<pre><code>kind: str\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.OcrOptions.lang","title":"lang  <code>instance-attribute</code>","text":"<pre><code>lang: List[str]\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfBackend","title":"PdfBackend","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum of valid PDF backends.</p> <p>Attributes:</p> <ul> <li> <code>DLPARSE_V1</code>           \u2013            </li> <li> <code>DLPARSE_V2</code>           \u2013            </li> <li> <code>PYPDFIUM2</code>           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfBackend.DLPARSE_V1","title":"DLPARSE_V1  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DLPARSE_V1 = 'dlparse_v1'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfBackend.DLPARSE_V2","title":"DLPARSE_V2  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DLPARSE_V2 = 'dlparse_v2'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfBackend.PYPDFIUM2","title":"PYPDFIUM2  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PYPDFIUM2 = 'pypdfium2'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions","title":"PdfPipelineOptions","text":"<p>               Bases: <code>PipelineOptions</code></p> <p>Options for the PDF pipeline.</p> <p>Attributes:</p> <ul> <li> <code>accelerator_options</code>               (<code>AcceleratorOptions</code>)           \u2013            </li> <li> <code>artifacts_path</code>               (<code>Optional[Union[Path, str]]</code>)           \u2013            </li> <li> <code>create_legacy_output</code>               (<code>bool</code>)           \u2013            </li> <li> <code>do_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>do_table_structure</code>               (<code>bool</code>)           \u2013            </li> <li> <code>document_timeout</code>               (<code>Optional[float]</code>)           \u2013            </li> <li> <code>generate_page_images</code>               (<code>bool</code>)           \u2013            </li> <li> <code>generate_picture_images</code>               (<code>bool</code>)           \u2013            </li> <li> <code>generate_table_images</code>               (<code>bool</code>)           \u2013            </li> <li> <code>images_scale</code>               (<code>float</code>)           \u2013            </li> <li> <code>ocr_options</code>               (<code>Union[EasyOcrOptions, TesseractCliOcrOptions, TesseractOcrOptions, OcrMacOptions, RapidOcrOptions]</code>)           \u2013            </li> <li> <code>table_structure_options</code>               (<code>TableStructureOptions</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.accelerator_options","title":"accelerator_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accelerator_options: AcceleratorOptions = (\n    AcceleratorOptions()\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.artifacts_path","title":"artifacts_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>artifacts_path: Optional[Union[Path, str]] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.create_legacy_output","title":"create_legacy_output  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>create_legacy_output: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.do_ocr","title":"do_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>do_ocr: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.do_table_structure","title":"do_table_structure  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>do_table_structure: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.document_timeout","title":"document_timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>document_timeout: Optional[float] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.generate_page_images","title":"generate_page_images  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>generate_page_images: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.generate_picture_images","title":"generate_picture_images  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>generate_picture_images: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.generate_table_images","title":"generate_table_images  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>generate_table_images: bool = Field(\n    default=False,\n    deprecated=\"Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\",\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.images_scale","title":"images_scale  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>images_scale: float = 1.0\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.ocr_options","title":"ocr_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ocr_options: Union[\n    EasyOcrOptions,\n    TesseractCliOcrOptions,\n    TesseractOcrOptions,\n    OcrMacOptions,\n    RapidOcrOptions,\n] = Field(EasyOcrOptions(), discriminator=\"kind\")\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PdfPipelineOptions.table_structure_options","title":"table_structure_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>table_structure_options: TableStructureOptions = (\n    TableStructureOptions()\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PipelineOptions","title":"PipelineOptions","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base pipeline options.</p> <p>Attributes:</p> <ul> <li> <code>accelerator_options</code>               (<code>AcceleratorOptions</code>)           \u2013            </li> <li> <code>create_legacy_output</code>               (<code>bool</code>)           \u2013            </li> <li> <code>document_timeout</code>               (<code>Optional[float]</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PipelineOptions.accelerator_options","title":"accelerator_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accelerator_options: AcceleratorOptions = (\n    AcceleratorOptions()\n)\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PipelineOptions.create_legacy_output","title":"create_legacy_output  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>create_legacy_output: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.PipelineOptions.document_timeout","title":"document_timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>document_timeout: Optional[float] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions","title":"RapidOcrOptions","text":"<p>               Bases: <code>OcrOptions</code></p> <p>Options for the RapidOCR engine.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>cls_model_path</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>det_model_path</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>kind</code>               (<code>Literal['rapidocr']</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>print_verbose</code>               (<code>bool</code>)           \u2013            </li> <li> <code>rec_model_path</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>text_score</code>               (<code>float</code>)           \u2013            </li> <li> <code>use_cls</code>               (<code>Optional[bool]</code>)           \u2013            </li> <li> <code>use_det</code>               (<code>Optional[bool]</code>)           \u2013            </li> <li> <code>use_rec</code>               (<code>Optional[bool]</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.cls_model_path","title":"cls_model_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cls_model_path: Optional[str] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.det_model_path","title":"det_model_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>det_model_path: Optional[str] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind: Literal['rapidocr'] = 'rapidocr'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.lang","title":"lang  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lang: List[str] = ['english', 'chinese']\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.print_verbose","title":"print_verbose  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>print_verbose: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.rec_model_path","title":"rec_model_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rec_model_path: Optional[str] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.text_score","title":"text_score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>text_score: float = 0.5\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.use_cls","title":"use_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_cls: Optional[bool] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.use_det","title":"use_det  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_det: Optional[bool] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.RapidOcrOptions.use_rec","title":"use_rec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_rec: Optional[bool] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableFormerMode","title":"TableFormerMode","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Modes for the TableFormer model.</p> <p>Attributes:</p> <ul> <li> <code>ACCURATE</code>           \u2013            </li> <li> <code>FAST</code>           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableFormerMode.ACCURATE","title":"ACCURATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACCURATE = 'accurate'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableFormerMode.FAST","title":"FAST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAST = 'fast'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableStructureOptions","title":"TableStructureOptions","text":"<p>               Bases: <code>BaseModel</code></p> <p>Options for the table structure.</p> <p>Attributes:</p> <ul> <li> <code>do_cell_matching</code>               (<code>bool</code>)           \u2013            </li> <li> <code>mode</code>               (<code>TableFormerMode</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableStructureOptions.do_cell_matching","title":"do_cell_matching  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>do_cell_matching: bool = True\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TableStructureOptions.mode","title":"mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mode: TableFormerMode = FAST\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions","title":"TesseractCliOcrOptions","text":"<p>               Bases: <code>OcrOptions</code></p> <p>Options for the TesseractCli engine.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>kind</code>               (<code>Literal['tesseract']</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>path</code>               (<code>Optional[str]</code>)           \u2013            </li> <li> <code>tesseract_cmd</code>               (<code>str</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind: Literal['tesseract'] = 'tesseract'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.lang","title":"lang  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lang: List[str] = ['fra', 'deu', 'spa', 'eng']\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.path","title":"path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>path: Optional[str] = None\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractCliOcrOptions.tesseract_cmd","title":"tesseract_cmd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tesseract_cmd: str = 'tesseract'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions","title":"TesseractOcrOptions","text":"<p>               Bases: <code>OcrOptions</code></p> <p>Options for the Tesseract engine.</p> <p>Attributes:</p> <ul> <li> <code>bitmap_area_threshold</code>               (<code>float</code>)           \u2013            </li> <li> <code>force_full_page_ocr</code>               (<code>bool</code>)           \u2013            </li> <li> <code>kind</code>               (<code>Literal['tesserocr']</code>)           \u2013            </li> <li> <code>lang</code>               (<code>List[str]</code>)           \u2013            </li> <li> <code>model_config</code>           \u2013            </li> <li> <code>path</code>               (<code>Optional[str]</code>)           \u2013            </li> </ul>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.bitmap_area_threshold","title":"bitmap_area_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitmap_area_threshold: float = 0.05\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.force_full_page_ocr","title":"force_full_page_ocr  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_full_page_ocr: bool = False\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind: Literal['tesserocr'] = 'tesserocr'\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.lang","title":"lang  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lang: List[str] = ['fra', 'deu', 'spa', 'eng']\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"reference/pipeline_options/#docowling.datamodel.pipeline_options.TesseractOcrOptions.path","title":"path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>path: Optional[str] = None\n</code></pre>"}]}